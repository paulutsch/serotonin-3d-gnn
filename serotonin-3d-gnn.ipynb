{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jiKdt3EYQ6d"
   },
   "source": [
    "# Serotonin 3D GNN Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gswc-LH5YWga"
   },
   "source": [
    "This project builds upon research done by Łapińska et al. (2024): https://doi.org/10.3390/pharmaceutics16030349\n",
    "\n",
    "Data used: https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_35/\n",
    "\n",
    "Move the unpacked chembl_35_sqlite.tar.gz file into the data/ dir.\n",
    "\n",
    "The research linked above presents two Quantitative Structure-Activity Relationship (QSAR) models to predict serotonergic binding affinity and selectivity, respectively, using Mordred molecular 2D descriptors. Specifically, one model classifies compounds binarily as \"active\" or \"inactive\", with a cutoff of pKi = 7. Another model does multiclass classification to predict the serotonergic selectivity of compounds previously classified as \"active\".\n",
    "\n",
    "I am following a similar approach, but using 3D molecular graph representations instead of 2D molecular descriptors as input modality and using only the ChEMBL database, not ZINC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGK0LMuRYC6g"
   },
   "source": [
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugvkdqJgYMum"
   },
   "source": [
    "### Configuration & Google Drive/Colab Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2361,
     "status": "ok",
     "timestamp": 1741097641972,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "q2XchrWsWuIk",
    "outputId": "a697f026-f628-4d87-ac39-c976d2f90337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'Running in Colab' if IN_COLAB else 'Running locally'}\")\n",
    "\n",
    "PATH_NOTEBOOK = (\n",
    "    Path(\"/content/drive/MyDrive/Colab Notebooks/serotonin-3d-gnn.ipynb\")\n",
    "    if IN_COLAB\n",
    "    else Path(\n",
    "        \"/Users/paul/Library/CloudStorage/GoogleDrive-unoutsch@gmail.com/My Drive/Colab Notebooks/serotonin-3d-gnn.ipynb\"\n",
    "    )\n",
    ")\n",
    "PATH_REPO = (\n",
    "    Path(\"/content/drive/MyDrive/Repositories/serotonin-3d-gnn\")\n",
    "    if IN_COLAB\n",
    "    else Path.cwd()\n",
    ")\n",
    "PATH_DATA = PATH_REPO / \"data_fixed\"\n",
    "PATH_WEIGHTS = PATH_REPO / \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko5Es7NyYw7W"
   },
   "source": [
    "### Installing Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5133,
     "status": "ok",
     "timestamp": 1741097649448,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "sPtfbBFEYwKR",
    "outputId": "9f2f267e-da1b-4785-8c4a-baae27590345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 4)) (2024.9.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2.5.1+cu124)\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.11.13)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (5.9.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "%pip install --requirement \"$PATH_REPO/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpNxNxd3UG04"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741097649464,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "6qaxG6KzSQbs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdchem, Descriptors, rdMolDescriptors, rdMolTransforms\n",
    "import shutil\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyOFFWimQtGD"
   },
   "source": [
    "### Syncing this file between Colab and local Git repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7qVn7CnR7FK"
   },
   "source": [
    "Make sure the paths exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1349,
     "status": "ok",
     "timestamp": 1741098456120,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "-AEKpQQaQ5U4",
    "outputId": "5eb6960d-c40a-4150-a5a6-2f97e467a266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied notebook to repo.\n"
     ]
    }
   ],
   "source": [
    "def copy_notebook():\n",
    "    if IN_COLAB:\n",
    "        shutil.copyfile(PATH_NOTEBOOK, PATH_REPO / \"serotonin-3d-gnn.ipynb\")\n",
    "        print(\"Copied notebook to repo.\")\n",
    "    else:\n",
    "        shutil.copyfile(PATH_REPO / \"serotonin-3d-gnn.ipynb\", PATH_NOTEBOOK)\n",
    "        print(\"Copied notebook to Google Drive.\")\n",
    "\n",
    "\n",
    "copy_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxQZohBJhQoT"
   },
   "source": [
    "### Setting Torch Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741097649480,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "YXkqUkBKhQoT",
    "outputId": "0f8ab30d-d3e4-42a5-8ea2-3da99aa682d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7iFshPsYhff"
   },
   "source": [
    "---\n",
    "\n",
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEEdENl6NzpP"
   },
   "source": [
    "### Loading and Preprocessing Serotonin Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-wRU6qqhQoU"
   },
   "source": [
    "If the pickled torch_data_list already exists, load it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1741097651600,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "1yBrNIjphQoU",
    "outputId": "dc67357a-486a-43b2-c041-19eea8fe32e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_6_2799.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1d_481.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_4_338.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_7_2317.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1b_466.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2b_833.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1a_3086.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2a_2353.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2c_1385.csv']\n",
      "{'Serotonin 1a (5-HT1a) receptor': 0, 'Serotonin 1b (5-HT1b) receptor': 1, 'Serotonin 1d (5-HT1d) receptor': 2, 'Serotonin 2a (5-HT2a) receptor': 3, 'Serotonin 2b (5-HT2b) receptor': 4, 'Serotonin 2c (5-HT2c) receptor': 5, 'Serotonin 4 (5-HT4) receptor': 6, 'Serotonin 6 (5-HT6) receptor': 7, 'Serotonin 7 (5-HT7) receptor': 8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>target_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14058.000000</td>\n",
       "      <td>14058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.319273</td>\n",
       "      <td>4.189856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.167407</td>\n",
       "      <td>2.950111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.470000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.150000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.850000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pchembl_value     target_id\n",
       "count   14058.000000  14058.000000\n",
       "mean        7.319273      4.189856\n",
       "std         1.167407      2.950111\n",
       "min         4.000000      0.000000\n",
       "25%         6.470000      1.000000\n",
       "50%         7.300000      4.000000\n",
       "75%         8.150000      7.000000\n",
       "max        10.850000      8.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob(os.path.join(PATH_DATA / \"targets\" / \"*.csv\"))\n",
    "print(csv_files)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(\n",
    "        file, delimiter=\";\", usecols=[\"Smiles\", \"pChEMBL Value\", \"Target Name\"]\n",
    "    )\n",
    "    df.columns = [\"smiles\", \"pchembl_value\", \"target_name\"]\n",
    "    data_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(data_list, ignore_index=True)\n",
    "merged_df[\"target_name\"] = merged_df[\"target_name\"].astype(\"category\")\n",
    "merged_df[\"target_id\"] = merged_df[\"target_name\"].cat.codes\n",
    "\n",
    "target_name_to_id = dict(\n",
    "    zip(\n",
    "        merged_df[\"target_name\"].cat.categories,\n",
    "        range(len(merged_df[\"target_name\"].cat.categories)),\n",
    "    )\n",
    ")\n",
    "target_id_to_name = {v: k for k, v in target_name_to_id.items()}\n",
    "print(target_name_to_id)\n",
    "\n",
    "merged_df.to_csv(os.path.join(PATH_DATA, \"merged_serotonin_data.csv\"), index=False)\n",
    "\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21748,
     "status": "ok",
     "timestamp": 1741097675577,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "6sUonIb3wM1I",
    "outputId": "eda83332-b5b2-4c52-f764-bfa7d0d7ba3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = os.path.join(PATH_DATA, \"merged_serotonin_data_processed.pkl\")\n",
    "\n",
    "if os.path.exists(pickle_file_path):\n",
    "    print(\"Loading processed data...\")\n",
    "    with open(pickle_file_path, \"rb\") as f:\n",
    "        merged_serotonin_data_processed = pickle.load(f)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    merged_serotonin_data_processed = None\n",
    "    print(\"Will create new processed data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQlehqYVhQoU"
   },
   "source": [
    "### Creating 3D Molecular Graph Data from Serotonin Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63VicadqVXW3"
   },
   "outputs": [],
   "source": [
    "periodic_table = rdchem.GetPeriodicTable()\n",
    "\n",
    "ATOM_PROPERTIES = {\n",
    "    atomic_num: [\n",
    "        periodic_table.GetAtomicWeight(atomic_num),\n",
    "        periodic_table.GetRvdw(atomic_num),\n",
    "        periodic_table.GetDefaultValence(atomic_num),\n",
    "    ]\n",
    "    for atomic_num in range(1, 119)  # all elements in periodic table\n",
    "}\n",
    "\n",
    "BOND_TYPES = [\n",
    "    Chem.rdchem.BondType.SINGLE,\n",
    "    Chem.rdchem.BondType.AROMATIC,\n",
    "    Chem.rdchem.BondType.DOUBLE,\n",
    "    Chem.rdchem.BondType.TRIPLE,\n",
    "]\n",
    "\n",
    "\n",
    "def create_torch_data(smiles: str, target_value: torch.Tensor, target_id) -> Data:\n",
    "    # getting RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # add explicit hydrogen atoms to the molecule (are not included in the SMILES string) so that its 3D structure is complete\n",
    "    mol = Chem.AddHs(mol)\n",
    "    Chem.SanitizeMol(mol)\n",
    "\n",
    "    # EmbedMolecule positions atoms of mol in 3D space stochastically; if it fails (returning -1) return None\n",
    "    if AllChem.EmbedMolecule(mol, randomSeed=42) == -1:\n",
    "        return None\n",
    "\n",
    "    # optimize the 3D structure using Universal Force Field (UFF) to lower mol's energy\n",
    "    status = AllChem.UFFOptimizeMolecule(mol)\n",
    "    if status == -1:\n",
    "        print(f\"UFF optimization failed for molecule: {smiles}\")\n",
    "        return None\n",
    "    AllChem.UFFOptimizeMolecule(mol)\n",
    "\n",
    "    # conformer contains 3D coordinates for mol's atoms\n",
    "    conformer = mol.GetConformer()\n",
    "\n",
    "    # molecule-level features\n",
    "    mol_features = [\n",
    "        Descriptors.ExactMolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        rdMolDescriptors.CalcNumAromaticRings(mol),\n",
    "        rdMolDescriptors.CalcNumBridgeheadAtoms(mol),\n",
    "        rdMolDescriptors.CalcNumRotatableBonds(mol),\n",
    "        rdMolDescriptors.CalcNumHBD(mol),\n",
    "        rdMolDescriptors.CalcNumHBA(mol),\n",
    "    ]\n",
    "\n",
    "    # atom-level features and 3D positions\n",
    "    atom_features, positions = [], []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        atomic_mass, vdw_radius, valence = ATOM_PROPERTIES.get(\n",
    "            atomic_num, [0.0, 0.0, 0]\n",
    "        )\n",
    "\n",
    "        features = [\n",
    "            atomic_mass,\n",
    "            vdw_radius,\n",
    "            valence,\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetDegree(),\n",
    "            int(atom.IsInRing()),\n",
    "        ] + [\n",
    "            1.0 if atom.GetHybridization() == h else 0.0\n",
    "            for h in (\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        atom_features.append(features)\n",
    "\n",
    "        pos = conformer.GetAtomPosition(atom.GetIdx())\n",
    "        positions.append([pos.x, pos.y, pos.z])\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    pos = torch.tensor(positions, dtype=torch.float)\n",
    "\n",
    "    # bonds between atoms – indices of connected atoms as well as types and conjugation\n",
    "    edge_index, edge_attr = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        # indices of bonded atoms\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "\n",
    "        # one-hot encode bond type\n",
    "        bond_type = bond.GetBondType()\n",
    "        bond_type_one_hot = [1.0 if bond_type == b else 0.0 for b in BOND_TYPES]\n",
    "\n",
    "        # is_conjugated = 1.0 if bond.GetIsConjugated() else 0.0\n",
    "        bond_length = rdMolTransforms.GetBondLength(conformer, i, j)\n",
    "\n",
    "        bond_feat = bond_type_one_hot + [bond_length]\n",
    "\n",
    "        # adding bond to both nodes\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "        edge_attr += [bond_feat, bond_feat]\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    # edge_index tensor is transposed to fit torch_geometric's expected shape (2, number_of_edges).\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    mol_features = torch.tensor(mol_features, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    # graph as PyTorch Geometric Data object\n",
    "    # x: atom features, [atomic number, degree, formal charge, hybridization]\n",
    "    # pos: 3D positions of atoms, [x, y, z]\n",
    "    # edge_index: connectivity indices between atoms, [[i, j], [j, i]]\n",
    "    # edge_attr: features per bond, [[bond type, conjugation], [bond type, conjugation]]\n",
    "    return Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=target_value,\n",
    "        target_id=target_id,\n",
    "        smiles=smiles,\n",
    "        mol_features=mol_features,\n",
    "    )\n",
    "\n",
    "\n",
    "if not merged_serotonin_data_processed:\n",
    "    merged_serotonin_data_processed = []\n",
    "    for i, row in enumerate(merged_df.itertuples()):\n",
    "        pct_complete = 100 * i / len(merged_df)\n",
    "        sys.stdout.write(f\"\\r{pct_complete:.2f}% complete\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        data_obj = create_torch_data(\n",
    "            row.smiles,\n",
    "            torch.tensor(row.pchembl_value, dtype=torch.float),\n",
    "            row.target_id,\n",
    "        )\n",
    "\n",
    "        if data_obj:\n",
    "            merged_serotonin_data_processed.append(data_obj)\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"merged_serotonin_data_processed.pkl\"\n",
    "\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(merged_serotonin_data_processed, f)\n",
    "\n",
    "    print(f\"Saved merged_serotonin_data_processed to {pickle_file_path}\")\n",
    "    print(f\"merged_serotonin_data_processed[0] {merged_serotonin_data_processed[1100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8Lr_Fpc5NOa"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVDv1khB5ONd"
   },
   "source": [
    "### Normalizing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7889,
     "status": "ok",
     "timestamp": 1741097683465,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "qdOBAG6b5Tgx",
    "outputId": "3df4044a-3709-412d-945c-c17f7ad70d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-normalization done\n",
      "example normalized target: 0.07213611900806427\n",
      "example original target: 7.46999979019165\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "x_sum, x_sq_sum, x_count = 0, 0, 0\n",
    "edge_attr_sum, edge_attr_sq_sum, edge_count = 0, 0, 0\n",
    "mol_features_sum, mol_features_sq_sum, mol_count = 0, 0, 0\n",
    "\n",
    "pchembl_sum, pchembl_sq_sum, pchembl_count = {}, {}, {}\n",
    "\n",
    "for d in merged_serotonin_data_processed:\n",
    "    x_sum += d.x.sum(dim=0)\n",
    "    x_sq_sum += (d.x**2).sum(dim=0)\n",
    "    x_count += d.x.shape[0]\n",
    "\n",
    "    edge_attr_sum += d.edge_attr.sum(dim=0)\n",
    "    edge_attr_sq_sum += (d.edge_attr**2).sum(dim=0)\n",
    "    edge_count += d.edge_attr.shape[0]\n",
    "\n",
    "    mol_features_sum += d.mol_features.sum(dim=0)\n",
    "    mol_features_sq_sum += (d.mol_features**2).sum(dim=0)\n",
    "    mol_count += d.mol_features.shape[0]\n",
    "\n",
    "    target_id = d.target_id\n",
    "    if target_id not in pchembl_sum:\n",
    "        pchembl_sum[target_id], pchembl_sq_sum[target_id], pchembl_count[target_id] = (\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        )\n",
    "\n",
    "    pchembl_sum[target_id] += d.y.sum()\n",
    "    pchembl_sq_sum[target_id] += (d.y**2).sum()\n",
    "    pchembl_count[target_id] += 1\n",
    "\n",
    "x_mean = x_sum / x_count\n",
    "x_std = ((x_sq_sum / x_count) - (x_mean**2)).sqrt()\n",
    "\n",
    "edge_attr_mean = edge_attr_sum / edge_count\n",
    "edge_attr_std = ((edge_attr_sq_sum / edge_count) - (edge_attr_mean**2)).sqrt()\n",
    "\n",
    "mol_features_mean = mol_features_sum / mol_count\n",
    "mol_features_std = ((mol_features_sq_sum / mol_count) - (mol_features_mean**2)).sqrt()\n",
    "\n",
    "pchembl_mean, pchembl_std = {}, {}\n",
    "for target_id in pchembl_sum.keys():\n",
    "    pchembl_mean[target_id] = pchembl_sum[target_id] / pchembl_count[target_id]\n",
    "    pchembl_std[target_id] = torch.sqrt(\n",
    "        (pchembl_sq_sum[target_id] / pchembl_count[target_id])\n",
    "        - (pchembl_mean[target_id] ** 2)\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    normalized_dataset = []\n",
    "\n",
    "    for d in dataset:\n",
    "        d_cloned = copy.deepcopy(d)  # no referenceto original\n",
    "        target_id = d.target_id\n",
    "\n",
    "        d_cloned.x = (d_cloned.x - x_mean) / x_std\n",
    "        d_cloned.edge_attr = (d_cloned.edge_attr - edge_attr_mean) / edge_attr_std\n",
    "        d_cloned.mol_features = (\n",
    "            d_cloned.mol_features - mol_features_mean\n",
    "        ) / mol_features_std\n",
    "        d_cloned.y = (d_cloned.y - pchembl_mean[target_id]) / pchembl_std[target_id]\n",
    "\n",
    "        normalized_dataset.append(d_cloned)\n",
    "\n",
    "    return normalized_dataset\n",
    "\n",
    "\n",
    "merged_serotonin_data_processed_normalized = normalize_dataset(\n",
    "    merged_serotonin_data_processed\n",
    ")\n",
    "\n",
    "print(\"z-normalization done\")\n",
    "print(f\"example normalized target: {merged_serotonin_data_processed_normalized[0].y}\")\n",
    "print(f\"example original target: {merged_serotonin_data_processed[0].y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HA3rlMSlwM1J"
   },
   "source": [
    "### Splitting Serotonin Data into Pretraining / Target Sets (5-HT2A / Other) & Train / Test Sets\n",
    "\n",
    "-   separate merged_serotonin_data_processed into 5-HT2A and other receptors\n",
    "-   create train/test splits for 5-HT2A data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1741097688619,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "7g3NG7QMwM1J",
    "outputId": "393e99dd-e071-4f97-8926-c5a5381b13f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-HT2a receptor data: 2351 samples\n",
      "Pretraining data: 11702 samples\n",
      "\n",
      "5-HT2a receptor training data: 2115 samples\n",
      "5-HT2a receptor test data: 236 samples\n",
      "\n",
      "Example 5-HT2a data object: Data(x=[65, 10], edge_index=[2, 140], edge_attr=[140, 5], y=-0.4740857183933258, pos=[65, 3], target_id=3, smiles='O=S(=O)(c1cncc2ccccc12)N1CCC[C@H]1CCN1CC=C(c2c[nH]c3ccc(Cl)cc23)CC1', mol_features=[1, 8])\n",
      "Example pretraining data object: Data(x=[41, 10], edge_index=[2, 84], edge_attr=[84, 5], y=0.07213611900806427, pos=[41, 3], target_id=7, smiles='CCN/C(=N\\S(=O)(=O)c1ccccc1)N1CC(CC)C=N1', mol_features=[1, 8])\n",
      "\n",
      "Standard deviation of z-normalized -log_10(Ki) in 5-HT2a train set: 1.0051084\n"
     ]
    }
   ],
   "source": [
    "target_id = target_name_to_id[\"Serotonin 2a (5-HT2a) receptor\"]\n",
    "\n",
    "merged_serotonin_data_processed_5ht2a = [\n",
    "    data\n",
    "    for data in merged_serotonin_data_processed_normalized\n",
    "    if data.target_id == target_id\n",
    "]\n",
    "merged_serotonin_data_processed_pretrain = [\n",
    "    data\n",
    "    for data in merged_serotonin_data_processed_normalized\n",
    "    if data.target_id != target_id\n",
    "]\n",
    "\n",
    "print(f\"5-HT2a receptor data: {len(merged_serotonin_data_processed_5ht2a)} samples\")\n",
    "print(f\"Pretraining data: {len(merged_serotonin_data_processed_pretrain)} samples\\n\")\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(merged_serotonin_data_processed_5ht2a)\n",
    "\n",
    "split_idx = int(0.9 * len(merged_serotonin_data_processed_5ht2a))\n",
    "\n",
    "merged_serotonin_data_processed_5ht2a_train = merged_serotonin_data_processed_5ht2a[\n",
    "    :split_idx\n",
    "]\n",
    "merged_serotonin_data_processed_5ht2a_test = merged_serotonin_data_processed_5ht2a[\n",
    "    split_idx:\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"5-HT2a receptor training data: {len(merged_serotonin_data_processed_5ht2a_train)} samples\"\n",
    ")\n",
    "print(\n",
    "    f\"5-HT2a receptor test data: {len(merged_serotonin_data_processed_5ht2a_test)} samples\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Example 5-HT2a data object: {merged_serotonin_data_processed_5ht2a_train[0]}\")\n",
    "print(\n",
    "    f\"Example pretraining data object: {merged_serotonin_data_processed_pretrain[0]}\\n\"\n",
    ")\n",
    "\n",
    "y_train = [\n",
    "    d.y.cpu().numpy()\n",
    "    for d in merged_serotonin_data_processed_5ht2a_train\n",
    "    if d.y.numel() > 0\n",
    "]\n",
    "sigma_train = np.nanstd(y_train)\n",
    "\n",
    "print(\n",
    "    \"Standard deviation of z-normalized -log_10(Ki) in 5-HT2a train set:\", sigma_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vDOpQmFhQoW"
   },
   "source": [
    "---\n",
    "\n",
    "## Model Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXYo_QiqhQoW"
   },
   "source": [
    "### Naive Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1741097691929,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "EzwGqdrhhQoW"
   },
   "outputs": [],
   "source": [
    "class MeanBaseline:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        self.mean_ = np.nanmean(y)\n",
    "\n",
    "    def predict(self, n):\n",
    "        return np.tile(self.mean_, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvehcFMGhQoW"
   },
   "source": [
    "### SeroGCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741097694266,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "f9C_6NOzhQoW",
    "outputId": "c740f0a8-ee61-4cbc-9bfd-4f46eeee675b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features: 10, targets: 1, edge attributes: 5\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_features = merged_serotonin_data_processed_5ht2a_train[0].x.shape[1]\n",
    "n_out = 1\n",
    "n_edge_attr = merged_serotonin_data_processed_5ht2a_train[0].edge_attr.shape[1]\n",
    "\n",
    "print(f\"Node features: {n_features}, targets: {n_out}, edge attributes: {n_edge_attr}\")\n",
    "\n",
    "\n",
    "class SeroGCN(torch.nn.Module):\n",
    "    def __init__(self, n_hidden, n_out=1):\n",
    "        super(SeroGCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(n_features, n_hidden)\n",
    "        self.conv2 = GCNConv(n_hidden, n_hidden)\n",
    "        self.fc = Linear(n_hidden + 8, n_out)  # add molecule-level features\n",
    "        self.sigma = 1.0  # distance weighting parameter\n",
    "\n",
    "    def forward(self, mol_batch) -> torch.Tensor:\n",
    "        x, pos, edge_index, edge_attr, mol_features = (\n",
    "            mol_batch.x,\n",
    "            mol_batch.pos,\n",
    "            mol_batch.edge_index,\n",
    "            mol_batch.edge_attr,\n",
    "            mol_batch.mol_features,\n",
    "        )\n",
    "\n",
    "        row, col = edge_index\n",
    "        eucl_edge_dist = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "        weight_distance = torch.exp(\n",
    "            -(eucl_edge_dist**2) / (2 * self.sigma**2)\n",
    "        )  # Gaussian distance weighting\n",
    "\n",
    "        # message passing with diustance weights\n",
    "        x = self.conv1(x, edge_index, edge_weight=weight_distance)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # global pooling for graph-level representation\n",
    "        x = global_max_pool(x, mol_batch.batch)\n",
    "        x = self.fc(torch.cat([x, mol_features], dim=1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiVYy5b9hQoX"
   },
   "source": [
    "---\n",
    "\n",
    "## Training Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741097711735,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "-epVrheQhQoX"
   },
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# def masked_mse_loss(predictions, targets, target_ids):\n",
    "#     \"\"\"\n",
    "#     predictions: Tensor [batch_size, num_targets]\n",
    "#     targets: Tensor [batch_size]\n",
    "#     target_ids: Tensor [batch_size]\n",
    "#     \"\"\"\n",
    "#     batch_size = predictions.shape[0]\n",
    "\n",
    "#     masked_predictions = predictions[torch.arange(batch_size), target_ids]\n",
    "\n",
    "#     return F.mse_loss(masked_predictions, targets, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741098430496,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "u-SuA9MehQoX"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    epochs: int,\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)  # (batch_size, n_out)\n",
    "\n",
    "            batch_size = out.shape[0]\n",
    "            target_values = data.y.view(batch_size)  # (batch_size)\n",
    "            # if all data.target_id are 3, make target_indices all 0\n",
    "\n",
    "            if torch.all(\n",
    "                data.target_id == 3\n",
    "            ):  # if all targets are 5-HT2a, set all indices to 0\n",
    "                target_indices = torch.zeros_like(data.target_id)\n",
    "            else:\n",
    "                target_indices = torch.where(\n",
    "                    data.target_id > 3, data.target_id - 1, data.target_id\n",
    "                )  # not the nicest approach, but the 5-HT2a receptor unfortunately has target_id 3\n",
    "            selected_outputs = out[\n",
    "                torch.arange(batch_size), target_indices\n",
    "            ]  # (batch_size)\n",
    "\n",
    "            loss = criterion(selected_outputs, target_values)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pct_complete = 100 * (i + 1) / len(train_loader)\n",
    "            sys.stdout.write(\n",
    "                f\"\\rEpoch {epoch+1}/{epochs} - {pct_complete:.2f}% complete\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        train_loss_avg = epoch_loss / len(train_loader)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_data = val_data.to(device)\n",
    "                val_out = model(val_data)\n",
    "\n",
    "                batch_size = val_out.shape[0]\n",
    "                val_target_values = val_data.y.view(batch_size)\n",
    "                if torch.all(val_data.target_id == 3):\n",
    "                    val_target_indices = torch.zeros_like(val_data.target_id)\n",
    "                else:\n",
    "                    val_target_indices = torch.where(\n",
    "                        val_data.target_id > 3,\n",
    "                        val_data.target_id - 1,\n",
    "                        val_data.target_id,\n",
    "                    )  # again – I know – not the nicest approach\n",
    "                val_selected_outputs = val_out[\n",
    "                    torch.arange(batch_size), val_target_indices\n",
    "                ]\n",
    "\n",
    "                val_loss = criterion(val_selected_outputs, val_target_values)\n",
    "\n",
    "                val_epoch_loss += val_loss.item()\n",
    "        val_loss_avg = val_epoch_loss / len(val_loader)\n",
    "        end_epoch = time.time()\n",
    "\n",
    "        print(\n",
    "            f\"\\nEpoch {epoch+1} completed. Train Loss = {train_loss_avg:.4f} | Val Loss = {val_loss_avg:.4f}. Time taken: {end_epoch - start_epoch:.2f}s\"\n",
    "        )\n",
    "        train_losses.append(train_loss_avg)\n",
    "        val_losses.append(val_loss_avg)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741097711853,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "k5vqfLNAhQoY"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "def k_fold_cv(\n",
    "    initialized_model,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    dataset,\n",
    "    k=5,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    "    fit_final_model=False,\n",
    "):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{k} ---\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model_tmp = copy.deepcopy(initialized_model)\n",
    "        optimizer_tmp = Optimizer(model_tmp.parameters(), lr=lr)\n",
    "\n",
    "        train_losses, val_losses = fit(\n",
    "            model_tmp, train_loader, val_loader, optimizer_tmp, criterion, epochs\n",
    "        )\n",
    "\n",
    "        fold_train_losses.append(train_losses)\n",
    "        fold_val_losses.append(val_losses)\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} completed. Final train loss: {train_losses[-1]:.4f} | Final val loss: {val_losses[-1]:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- K-Fold CV completed ---\")\n",
    "    print(\n",
    "        f\"Average final train loss: {sum([l[-1] for l in fold_train_losses]) / k:.4f}\"\n",
    "    )\n",
    "    print(f\"Average final val loss: {sum([l[-1] for l in fold_val_losses]) / k:.4f}\")\n",
    "\n",
    "    if fit_final_model:\n",
    "        print(\"\\nFitting final model on entire dataset\")\n",
    "        optimizer_final = Optimizer(initialized_model.parameters(), lr=lr)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        fit(\n",
    "            initialized_model,\n",
    "            data_loader,\n",
    "            data_loader,\n",
    "            optimizer_final,\n",
    "            criterion,\n",
    "            epochs,\n",
    "        )\n",
    "\n",
    "    return fold_train_losses, fold_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1741097711933,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "TouwAhcIhQoY"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def nested_cv(\n",
    "    Model,\n",
    "    n_out,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    hyperparam_grid,\n",
    "    dataset,\n",
    "    k_outer=5,\n",
    "    k_inner=5,\n",
    "):\n",
    "    # list of one dict per parameter combination\n",
    "    param_combinations = [\n",
    "        dict(zip(hyperparam_grid.keys(), values))\n",
    "        for values in product(*hyperparam_grid.values())\n",
    "    ]\n",
    "    n_combinations = len(param_combinations)\n",
    "\n",
    "    # risk estimate for each outer fold and each hyperparam combo\n",
    "    R_ests = np.zeros((k_outer, n_combinations))\n",
    "\n",
    "    if k_outer > 1:\n",
    "        outer_kf = KFold(n_splits=k_outer, shuffle=True, random_state=42)\n",
    "    else:  # for compute reasons\n",
    "\n",
    "        class DummyKFold:\n",
    "            def split(self, X):\n",
    "                yield X, X\n",
    "\n",
    "        outer_kf = DummyKFold()\n",
    "    dataset_indices = np.arange(len(dataset))\n",
    "\n",
    "    for i, (outer_train_idx, outer_val_idx) in enumerate(\n",
    "        outer_kf.split(dataset_indices)\n",
    "    ):\n",
    "        print(f\"\\n--- Outer Fold {i+1}/{k_outer} ---\")\n",
    "\n",
    "        outer_train_dataset = Subset(dataset, outer_train_idx)\n",
    "        outer_val_dataset = Subset(dataset, outer_val_idx)\n",
    "\n",
    "        # per hyperparam combo, perform inner k_fold_cv\n",
    "        for j, params in enumerate(param_combinations):\n",
    "            model = Model(params[\"n_hidden\"], n_out).to(device)\n",
    "\n",
    "            # Run k_fold_cv on the outer training dataset.\n",
    "            _, fold_val_losses = k_fold_cv(\n",
    "                initialized_model=model,\n",
    "                Optimizer=Optimizer,\n",
    "                criterion=criterion,\n",
    "                dataset=outer_train_dataset,\n",
    "                k=k_inner,\n",
    "                epochs=params[\"epochs\"],\n",
    "                # batch_size=params[\"batch_size\"],\n",
    "                batch_size=64,  # hard-coded for compute reasons\n",
    "                lr=params[\"lr\"],\n",
    "            )\n",
    "            # average val risk over inner folds\n",
    "            final_losses = [losses[-1] for losses in fold_val_losses]\n",
    "            R_est = np.mean(final_losses)\n",
    "            R_ests[i, j] = R_est\n",
    "            print(\n",
    "                f\"Outer fold {i+1}, param set {j+1}/{n_combinations}: Risk = {R_est:.4f}\"\n",
    "            )\n",
    "\n",
    "    # average risk per hyperparam combination over outer folds\n",
    "    R_ests_params = np.mean(R_ests, axis=0)\n",
    "    best_idx = np.argmin(R_ests_params)\n",
    "    best_params = param_combinations[best_idx]\n",
    "\n",
    "    print(\n",
    "        f\"\\nSelected best hyperparameters (avg risk {R_ests_params[best_idx]:.4f}): {best_params}\"\n",
    "    )\n",
    "\n",
    "    # train final model on full dataset\n",
    "    model_final = Model(best_params[\"n_hidden\"], n_out).to(device)\n",
    "    _, final_val_losses = k_fold_cv(\n",
    "        initialized_model=model_final,\n",
    "        Optimizer=Optimizer,\n",
    "        criterion=criterion,\n",
    "        dataset=dataset,\n",
    "        k=k_inner,\n",
    "        epochs=best_params[\"epochs\"],\n",
    "        # batch_size=params[\"batch_size\"],\n",
    "        batch_size=64,  # hard-coded for compute reasons\n",
    "        lr=best_params[\"lr\"],\n",
    "        fit_final_model=True,\n",
    "    )\n",
    "    final_R_est = np.mean([losses[-1] for losses in final_val_losses])\n",
    "    print(f\"Final model empirical risk estimate on full dataset: {final_R_est:.4f}\")\n",
    "\n",
    "    return model_final, best_params, final_R_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUKhw2PrhQoY"
   },
   "source": [
    "---\n",
    "\n",
    "## Training & Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBl2khqehQoY"
   },
   "source": [
    "### Naive Baseline: Average Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741097720053,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "HUIVMVd6hQoY",
    "outputId": "b7ddd182-526b-49cb-a135-0108b64340f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive baseline RMSE: 1.0487244129180908\n"
     ]
    }
   ],
   "source": [
    "split_idx_baseline = int(0.8 * len(merged_serotonin_data_processed_5ht2a_train))\n",
    "\n",
    "y_train_baseline = [\n",
    "    d.y.numpy()\n",
    "    for d in merged_serotonin_data_processed_5ht2a_train[:split_idx_baseline]\n",
    "]\n",
    "y_val_baseline = [\n",
    "    d.y.numpy()\n",
    "    for d in merged_serotonin_data_processed_5ht2a_train[split_idx_baseline:]\n",
    "]\n",
    "\n",
    "naive_baseline = MeanBaseline()\n",
    "naive_baseline.fit(y_train_baseline)\n",
    "naive_baseline_predictions = naive_baseline.predict(len(y_val_baseline))\n",
    "\n",
    "# compute mse\n",
    "mse = np.nanmean((y_val_baseline - naive_baseline_predictions) ** 2, axis=0)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Naive baseline RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvgld7xIhQoY"
   },
   "source": [
    "### Baseline: Random Forest with 2D/3D Descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6885,
     "status": "ok",
     "timestamp": 1741097731312,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "1nmBUWPuhQoY",
    "outputId": "839e0efd-ed79-4f8f-c26f-bbd40d4addab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.6332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# tried a bunch of descriptor functions from Descriptors._descList – these are the ones that did NOT crash the kernel ...\n",
    "safe_descriptors = [\n",
    "    \"MolWt\",\n",
    "    \"MolLogP\",\n",
    "    \"MolMR\",\n",
    "    \"NumValenceElectrons\",\n",
    "    \"NumRadicalElectrons\",\n",
    "    \"HeavyAtomCount\",\n",
    "    \"NHOHCount\",\n",
    "    \"NOCount\",\n",
    "    \"RingCount\",\n",
    "    \"FractionCSP3\",\n",
    "    \"TPSA\",\n",
    "    \"NumHDonors\",\n",
    "    \"NumHAcceptors\",\n",
    "    \"NumRotatableBonds\",\n",
    "    \"HallKierAlpha\",\n",
    "    \"Kappa1\",\n",
    "    \"Kappa2\",\n",
    "    \"Kappa3\",\n",
    "    \"Chi0\",\n",
    "    \"Chi1\",\n",
    "    \"fr_Al_COO\",\n",
    "    \"fr_Al_OH\",\n",
    "    \"fr_Ar_N\",\n",
    "    \"fr_C_O\",\n",
    "    \"fr_NH1\",\n",
    "    \"fr_NH2\",\n",
    "]\n",
    "\n",
    "descriptor_functions = {name: getattr(Descriptors, name) for name in safe_descriptors}\n",
    "\n",
    "\n",
    "# extract a fixed-length feature vector from the graph data, as input to RF model\n",
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    desc_values = []\n",
    "    for _, func in descriptor_functions.items():\n",
    "        try:\n",
    "            desc_values.append(func(mol))\n",
    "        except:\n",
    "            print(f\"Error computing descriptor {func}\")\n",
    "    return np.array(desc_values)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for data in merged_serotonin_data_processed_5ht2a_train:\n",
    "    features = compute_descriptors(data.smiles)\n",
    "    if features is None:\n",
    "        continue\n",
    "    X.append(features)\n",
    "    target_val = data.y.cpu().numpy() if data.y.numel() > 0 else np.nan\n",
    "    y.append(target_val)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "split_idx_rf = int(0.8 * len(merged_serotonin_data_processed_5ht2a_train))\n",
    "X_train, X_val = X[:split_idx_rf], X[split_idx_rf:]\n",
    "y_train, y_val = y[:split_idx_rf], y[split_idx_rf:]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Random Forest RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyInMxaihQoZ"
   },
   "source": [
    "### Approach 1: SeroGCN without Pretraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOo8Rdh9hQoZ"
   },
   "outputs": [],
   "source": [
    "n_out = 1\n",
    "\n",
    "hyperparam_grid = {\n",
    "    \"lr\": [0.1, 0.01, 0.001],\n",
    "    # \"lr\": [0.01],\n",
    "    # \"batch_size\": [16, 32, 64],\n",
    "    \"n_hidden\": [32, 64, 128],\n",
    "    # \"n_hidden\": [64],\n",
    "    \"epochs\": [10, 20, 30],\n",
    "    # \"epochs\": [30],\n",
    "}\n",
    "\n",
    "\n",
    "sero_gcn_final, best_params_sero_gcn, final_R_est_sero_gcn = nested_cv(\n",
    "    SeroGCN,\n",
    "    n_out,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    merged_serotonin_data_processed_5ht2a_train,\n",
    "    k_outer=1,  # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(sero_gcn_final.state_dict(), PATH_WEIGHTS / \"sero_gcn_final_weights.pth\")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_sero_gcn\": best_params_sero_gcn,\n",
    "            \"final_R_est_sero_gcn\": final_R_est_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqGa2vpxhQoZ"
   },
   "source": [
    "### Approach 2: SeroGCN with Pretraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqooqV7zhQoZ"
   },
   "source": [
    "#### Pretraining: Hyperparameter Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "error",
     "timestamp": 1741098443208,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "fepVtdrzhQoZ",
    "outputId": "4955bfa5-1f7b-482d-ccef-40b77b397346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets: 8\n",
      "\n",
      "--- Outer Fold 1/1 ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Training on 9361 samples, validating on 2341\n",
      "Epoch 1/5 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 1.3828 | Val Loss = 1.0643. Time taken: 99.84s\n",
      "Epoch 2/5 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 1.1057 | Val Loss = 1.1036. Time taken: 134.65s\n",
      "Epoch 3/5 - 5.44% complete"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(target_name_to_id\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# excluding 5-HT2a\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of targets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m (\n\u001b[1;32m     15\u001b[0m     pretrained_sero_gcn,\n\u001b[1;32m     16\u001b[0m     best_params_pretrained_sero_gcn,\n\u001b[1;32m     17\u001b[0m     final_R_est_pretrained_sero_gcn,\n\u001b[0;32m---> 18\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mnested_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSeroGCN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerged_serotonin_data_processed_pretrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_outer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# compute reasons\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_inner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m     30\u001b[0m     pretrained_sero_gcn\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     31\u001b[0m     PATH_WEIGHTS \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_sero_gcn_pretrained_weights.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(PATH_WEIGHTS \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_params_pretrained_sero.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[16], line 50\u001b[0m, in \u001b[0;36mnested_cv\u001b[0;34m(Model, n_out, Optimizer, criterion, hyperparam_grid, dataset, k_outer, k_inner)\u001b[0m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_hidden\u001b[39m\u001b[38;5;124m\"\u001b[39m], n_out)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Run k_fold_cv on the outer training dataset.\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m _, fold_val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mk_fold_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitialized_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_train_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_inner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch_size=params[\"batch_size\"],\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# hard-coded for compute reasons\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# average val risk over inner folds\u001b[39;00m\n\u001b[1;32m     62\u001b[0m final_losses \u001b[38;5;241m=\u001b[39m [losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m losses \u001b[38;5;129;01min\u001b[39;00m fold_val_losses]\n",
      "Cell \u001b[0;32mIn[25], line 39\u001b[0m, in \u001b[0;36mk_fold_cv\u001b[0;34m(initialized_model, Optimizer, criterion, dataset, k, epochs, batch_size, lr, fit_final_model)\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer_tmp \u001b[38;5;241m=\u001b[39m Optimizer(model_tmp\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_subset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, validating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_subset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m fold_train_losses\u001b[38;5;241m.\u001b[39mappend(train_losses)\n\u001b[1;32m     44\u001b[0m fold_val_losses\u001b[38;5;241m.\u001b[39mappend(val_losses)\n",
      "Cell \u001b[0;32mIn[35], line 21\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, n_out)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m target_values \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(batch_size)  \u001b[38;5;66;03m# (batch_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 37\u001b[0m, in \u001b[0;36mSeroGCN.forward\u001b[0;34m(self, mol_batch)\u001b[0m\n\u001b[1;32m     32\u001b[0m weight_distance \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m-\u001b[39m(eucl_edge_dist\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     34\u001b[0m )  \u001b[38;5;66;03m# Gaussian distance weighting\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# message passing with diustance weights\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch_geometric/nn/conv/gcn_conv.py:108\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m--> 108\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    110\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_grid = {\n",
    "    \"lr\": [0.1, 0.01, 0.001],\n",
    "    \"n_hidden\": [64],  # best param from previous 5-HT2a model\n",
    "    \"epochs\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "    ],  # reduction because pretraining data set is significantly larger\n",
    "}\n",
    "\n",
    "n_out = len(target_name_to_id.values()) - 1  # excluding 5-HT2a\n",
    "print(f\"Number of targets: {n_out}\")\n",
    "\n",
    "(\n",
    "    pretrained_sero_gcn,\n",
    "    best_params_pretrained_sero_gcn,\n",
    "    final_R_est_pretrained_sero_gcn,\n",
    ") = nested_cv(\n",
    "    SeroGCN,\n",
    "    n_out,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    merged_serotonin_data_processed_pretrain,\n",
    "    k_outer=1,  # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_R_est_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV86lS77hQoZ"
   },
   "source": [
    "#### Pretraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBTj2oQfhQoZ"
   },
   "source": [
    "#### Finetuning on Serotonine Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1740315773552,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "_3qGyoEMU09K",
    "outputId": "1039f17b-8a96-4c74-88e6-58209f77d4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeroGCN does not exist – train it first\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\"\n",
    "\n",
    "if os.path.exists(pickle_file_path) and not pretrained_sero_gcn:\n",
    "    print(\"Loading pretrained SeroGCN weights from file\")\n",
    "    pretrained_weights = torch.load(\n",
    "        PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\", map_location=device\n",
    "    )\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"No pretrained weights – pretrain first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX_8Qr17hQoZ"
   },
   "outputs": [],
   "source": [
    "n_out = 1\n",
    "\n",
    "sero_gcn_finetune = SeroGCN(best_params_pretrained_sero_gcn[\"n_hidden\"], n_out).to(\n",
    "    device\n",
    ")\n",
    "model_dict = sero_gcn_finetune.state_dict()  # including fc layer\n",
    "pretrained_weights = {\n",
    "    k: v for k, v in pretrained_weights.items() if \"fc\" not in k\n",
    "}  # excluding fc layer\n",
    "model_dict.update(pretrained_weights)  # load pretrained weights\n",
    "sero_gcn_finetune.load_state_dict(model_dict, strict=False)  # allow missing fc weights\n",
    "\n",
    "print(\"Loaded pretrained weights\")\n",
    "\n",
    "_, final_val_losses_pretrained_sero_gcn = k_fold_cv(\n",
    "    initialized_model=pretrained_sero_gcn,\n",
    "    Optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss(),\n",
    "    dataset=merged_serotonin_data_processed_5ht2a_train,\n",
    "    k=5,\n",
    "    epochs=best_params_pretrained_sero_gcn[\"epochs\"],\n",
    "    batch_size=best_params_pretrained_sero_gcn[\"batch_size\"],\n",
    "    lr=best_params_pretrained_sero_gcn[\"lr\"],\n",
    "    fit_final_model=True,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_final_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero_final.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_val_losses_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxB4ngu_hQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Test Set Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvTRLNdrhQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "q7iFshPsYhff",
    "WEEdENl6NzpP",
    "LQlehqYVhQoU",
    "XVDv1khB5ONd",
    "HA3rlMSlwM1J",
    "zXYo_QiqhQoW",
    "QvehcFMGhQoW",
    "YBl2khqehQoY",
    "kvgld7xIhQoY",
    "nyInMxaihQoZ"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
