{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jiKdt3EYQ6d"
      },
      "source": [
        "# Serotonin 3D GNN Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gswc-LH5YWga"
      },
      "source": [
        "This project builds upon research done by Łapińska et al. (2024): https://doi.org/10.3390/pharmaceutics16030349\n",
        "\n",
        "Data used: https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_35/\n",
        "\n",
        "Move the unpacked chembl_35_sqlite.tar.gz file into the data/ dir.\n",
        "\n",
        "The research linked above presents two Quantitative Structure-Activity Relationship (QSAR) models to predict serotonergic binding affinity and selectivity, respectively, using Mordred molecular 2D descriptors. Specifically, one model classifies compounds binarily as \"active\" or \"inactive\", with a cutoff of pKi = 7. Another model does multiclass classification to predict the serotonergic selectivity of compounds previously classified as \"active\".\n",
        "\n",
        "I am following a similar approach, but using 3D molecular graph representations instead of 2D molecular descriptors as input modality and using only the ChEMBL database, not ZINC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGK0LMuRYC6g"
      },
      "source": [
        "## Google Colab Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugvkdqJgYMum"
      },
      "source": [
        "### Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q2XchrWsWuIk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running locally\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print(f\"{'Running in Colab' if IN_COLAB else 'Running locally'}\")\n",
        "\n",
        "PATH_NOTEBOOK = (\n",
        "    Path(\"/content/drive/MyDrive/Colab Notebooks/serotonin-3d-gnn.ipynb\")\n",
        "    if IN_COLAB\n",
        "    else Path(\n",
        "        \"/Users/paul/Library/CloudStorage/GoogleDrive-unoutsch@gmail.com/My Drive/Colab Notebooks/serotonin-3d-gnn.ipynb\"\n",
        "    )\n",
        ")\n",
        "PATH_REPO = (\n",
        "    Path(\"/content/drive/MyDrive/Repositories/serotonin-3d-gnn\")\n",
        "    if IN_COLAB\n",
        "    else Path.cwd()\n",
        ")\n",
        "PATH_DATA = PATH_REPO / \"data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUmzYXPCZYV1"
      },
      "source": [
        "### Syncing Google Drive with Google Colab Content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko5Es7NyYw7W"
      },
      "source": [
        "### Installing Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sPtfbBFEYwKR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aiohappyeyeballs==2.4.4 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiohttp==3.11.11 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 2)) (3.11.11)\n",
            "Requirement already satisfied: aiosignal==1.3.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 4)) (0.1.4)\n",
            "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: attrs==25.1.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (25.1.0)\n",
            "Requirement already satisfied: certifi==2025.1.31 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 9)) (0.2.2)\n",
            "Requirement already satisfied: contourpy==1.3.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: debugpy==1.8.12 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 12)) (1.8.12)\n",
            "Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 13)) (5.1.1)\n",
            "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 14)) (2.2.0)\n",
            "Requirement already satisfied: filelock==3.17.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 15)) (3.17.0)\n",
            "Requirement already satisfied: fonttools==4.55.8 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 16)) (4.55.8)\n",
            "Requirement already satisfied: frozenlist==1.5.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 17)) (1.5.0)\n",
            "Requirement already satisfied: fsspec==2025.2.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 18)) (2025.2.0)\n",
            "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 19)) (3.10)\n",
            "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 20)) (6.29.5)\n",
            "Requirement already satisfied: ipython==8.32.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 21)) (8.32.0)\n",
            "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 22)) (0.19.2)\n",
            "Requirement already satisfied: Jinja2==3.1.5 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 23)) (3.1.5)\n",
            "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 24)) (8.6.3)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 25)) (5.7.2)\n",
            "Requirement already satisfied: kiwisolver==1.4.8 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 26)) (1.4.8)\n",
            "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 27)) (3.0.2)\n",
            "Requirement already satisfied: matplotlib==3.10.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 28)) (3.10.0)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 29)) (0.1.7)\n",
            "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 30)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.1.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 31)) (6.1.0)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 32)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.4.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 33)) (3.4.2)\n",
            "Requirement already satisfied: numpy==2.2.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 34)) (2.2.2)\n",
            "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 35)) (24.2)\n",
            "Requirement already satisfied: pandas==2.2.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 36)) (2.2.3)\n",
            "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 37)) (0.8.4)\n",
            "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 38)) (4.9.0)\n",
            "Requirement already satisfied: pillow==11.1.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 39)) (11.1.0)\n",
            "Requirement already satisfied: platformdirs==4.3.6 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 40)) (4.3.6)\n",
            "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 41)) (3.0.50)\n",
            "Requirement already satisfied: propcache==0.2.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 42)) (0.2.1)\n",
            "Requirement already satisfied: psutil==6.1.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 43)) (6.1.1)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 44)) (0.7.0)\n",
            "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 45)) (0.2.3)\n",
            "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 46)) (2.19.1)\n",
            "Requirement already satisfied: pyparsing==3.2.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 47)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 48)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz==2025.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 49)) (2025.1)\n",
            "Requirement already satisfied: pyzmq==26.2.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 50)) (26.2.1)\n",
            "Requirement already satisfied: rdkit-pypi==2022.9.5 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 51)) (2022.9.5)\n",
            "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 52)) (2.32.3)\n",
            "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 53)) (1.17.0)\n",
            "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 54)) (0.6.3)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 55)) (1.13.1)\n",
            "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 56)) (2.6.0)\n",
            "Requirement already satisfied: torch-geometric==2.6.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 57)) (2.6.1)\n",
            "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 58)) (6.4.2)\n",
            "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 59)) (4.67.1)\n",
            "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 60)) (5.14.3)\n",
            "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 61)) (4.12.2)\n",
            "Requirement already satisfied: tzdata==2025.1 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 62)) (2025.1)\n",
            "Requirement already satisfied: urllib3==2.3.0 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 63)) (2.3.0)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 64)) (0.2.13)\n",
            "Requirement already satisfied: yarl==1.18.3 in ./.venv/lib/python3.11/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 65)) (1.18.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r \"$PATH_REPO/requirements.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpNxNxd3UG04"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "6qaxG6KzSQbs",
        "outputId": "9bd00a18-1e7b-4bff-88fe-3c2a797ec6f7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, rdchem, HybridizationType\n",
        "import shutil\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0AtFuskQrkU"
      },
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyOFFWimQtGD"
      },
      "source": [
        "### Syncing this file between Colab and local Git repo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7qVn7CnR7FK"
      },
      "source": [
        "Make sure the paths exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AEKpQQaQ5U4",
        "outputId": "3616a8c4-0786-48f3-a11e-8ffc77ea24a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied notebook to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    shutil.copyfile(PATH_NOTEBOOK, PATH_REPO / \"serotonin-3d-gnn.ipynb\")\n",
        "    print(\"Copied notebook to repo.\")\n",
        "else:\n",
        "    shutil.copyfile(PATH_REPO / \"serotonin-3d-gnn.ipynb\", PATH_NOTEBOOK)\n",
        "    print(\"Copied notebook to Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7iFshPsYhff"
      },
      "source": [
        "## Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDQ9MbtCNEAb"
      },
      "source": [
        "### Note on Data Aquisition from chembl_35.db\n",
        "\n",
        "In order to collect the desired data from the ChEMBL SQL database and transform it into a .csv file, I undertook the steps detailed in `data/README.md`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEEdENl6NzpP"
      },
      "source": [
        "### Loading the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the pickled torch_data_list already exists, load it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded torch_data_list from pickle file\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>molecule_id</th>\n",
              "      <th>Serotonin (5-HT) receptor</th>\n",
              "      <th>Serotonin 1 (5-HT1) receptor</th>\n",
              "      <th>Serotonin 1 receptors; 5-HT1B &amp; 5-HT1D</th>\n",
              "      <th>Serotonin 1a (5-HT1a) receptor</th>\n",
              "      <th>Serotonin 1b (5-HT1b) receptor</th>\n",
              "      <th>Serotonin 1d (5-HT1d) receptor</th>\n",
              "      <th>Serotonin 1e (5-HT1e) receptor</th>\n",
              "      <th>Serotonin 1f (5-HT1f) receptor</th>\n",
              "      <th>Serotonin 2 (5-HT2) receptor</th>\n",
              "      <th>...</th>\n",
              "      <th>Serotonin 2b (5-HT2b) receptor</th>\n",
              "      <th>Serotonin 2c (5-HT2c) receptor</th>\n",
              "      <th>Serotonin 3 (5-HT3) receptor</th>\n",
              "      <th>Serotonin 3a (5-HT3a) receptor</th>\n",
              "      <th>Serotonin 3b (5-HT3b) receptor</th>\n",
              "      <th>Serotonin 4 (5-HT4) receptor</th>\n",
              "      <th>Serotonin 5a (5-HT5a) receptor</th>\n",
              "      <th>Serotonin 5b (5-HT5b) receptor</th>\n",
              "      <th>Serotonin 6 (5-HT6) receptor</th>\n",
              "      <th>Serotonin 7 (5-HT7) receptor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.345600e+04</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9462.000000</td>\n",
              "      <td>1492.000000</td>\n",
              "      <td>1472.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>1469.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2337.000000</td>\n",
              "      <td>4343.000000</td>\n",
              "      <td>939.000000</td>\n",
              "      <td>1040.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1009.000000</td>\n",
              "      <td>422.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4221.000000</td>\n",
              "      <td>3100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.003325e+06</td>\n",
              "      <td>6.081759</td>\n",
              "      <td>6.683902</td>\n",
              "      <td>6.2</td>\n",
              "      <td>7.258523</td>\n",
              "      <td>6.952528</td>\n",
              "      <td>7.554968</td>\n",
              "      <td>5.791172</td>\n",
              "      <td>7.458423</td>\n",
              "      <td>7.053201</td>\n",
              "      <td>...</td>\n",
              "      <td>6.603829</td>\n",
              "      <td>6.810210</td>\n",
              "      <td>7.625768</td>\n",
              "      <td>7.047520</td>\n",
              "      <td>7.203500</td>\n",
              "      <td>7.645809</td>\n",
              "      <td>6.573801</td>\n",
              "      <td>7.17</td>\n",
              "      <td>7.311171</td>\n",
              "      <td>6.977487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.986583e+05</td>\n",
              "      <td>0.926906</td>\n",
              "      <td>1.104283</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.152004</td>\n",
              "      <td>1.226482</td>\n",
              "      <td>1.365880</td>\n",
              "      <td>0.652239</td>\n",
              "      <td>0.859240</td>\n",
              "      <td>1.159567</td>\n",
              "      <td>...</td>\n",
              "      <td>0.981462</td>\n",
              "      <td>1.032874</td>\n",
              "      <td>1.225942</td>\n",
              "      <td>1.535413</td>\n",
              "      <td>1.735342</td>\n",
              "      <td>1.179482</td>\n",
              "      <td>1.089819</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.143388</td>\n",
              "      <td>1.016128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.700000e+01</td>\n",
              "      <td>4.390000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>5.140000</td>\n",
              "      <td>4.030000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.190000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.460000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.070000</td>\n",
              "      <td>7.17</td>\n",
              "      <td>4.120000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.291570e+05</td>\n",
              "      <td>5.385000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>6.480000</td>\n",
              "      <td>6.050000</td>\n",
              "      <td>6.470000</td>\n",
              "      <td>5.360000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.240000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>6.050000</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>5.490000</td>\n",
              "      <td>6.810000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>7.17</td>\n",
              "      <td>6.470000</td>\n",
              "      <td>6.285000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.757615e+05</td>\n",
              "      <td>5.925000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>7.280000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>7.640000</td>\n",
              "      <td>5.730000</td>\n",
              "      <td>7.720000</td>\n",
              "      <td>6.920000</td>\n",
              "      <td>...</td>\n",
              "      <td>6.523333</td>\n",
              "      <td>6.740000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>7.185000</td>\n",
              "      <td>7.015000</td>\n",
              "      <td>7.640000</td>\n",
              "      <td>6.390000</td>\n",
              "      <td>7.17</td>\n",
              "      <td>7.360000</td>\n",
              "      <td>6.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.965967e+06</td>\n",
              "      <td>6.657500</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>8.060000</td>\n",
              "      <td>7.850000</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>6.175000</td>\n",
              "      <td>8.020000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.210000</td>\n",
              "      <td>7.512500</td>\n",
              "      <td>8.580000</td>\n",
              "      <td>8.410000</td>\n",
              "      <td>8.393500</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>7.068750</td>\n",
              "      <td>7.17</td>\n",
              "      <td>8.110000</td>\n",
              "      <td>7.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.881244e+06</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.100000</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>10.420000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>9.604000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>9.170000</td>\n",
              "      <td>7.17</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        molecule_id  Serotonin (5-HT) receptor  Serotonin 1 (5-HT1) receptor  \\\n",
              "count  2.345600e+04                  90.000000                    252.000000   \n",
              "mean   1.003325e+06                   6.081759                      6.683902   \n",
              "std    8.986583e+05                   0.926906                      1.104283   \n",
              "min    9.700000e+01                   4.390000                      4.100000   \n",
              "25%    2.291570e+05                   5.385000                      5.800000   \n",
              "50%    5.757615e+05                   5.925000                      6.600000   \n",
              "75%    1.965967e+06                   6.657500                      7.585000   \n",
              "max    2.881244e+06                   9.800000                      9.300000   \n",
              "\n",
              "       Serotonin 1 receptors; 5-HT1B & 5-HT1D  Serotonin 1a (5-HT1a) receptor  \\\n",
              "count                                     1.0                     9462.000000   \n",
              "mean                                      6.2                        7.258523   \n",
              "std                                       NaN                        1.152004   \n",
              "min                                       6.2                        4.000000   \n",
              "25%                                       6.2                        6.480000   \n",
              "50%                                       6.2                        7.280000   \n",
              "75%                                       6.2                        8.060000   \n",
              "max                                       6.2                       11.000000   \n",
              "\n",
              "       Serotonin 1b (5-HT1b) receptor  Serotonin 1d (5-HT1d) receptor  \\\n",
              "count                     1492.000000                     1472.000000   \n",
              "mean                         6.952528                        7.554968   \n",
              "std                          1.226482                        1.365880   \n",
              "min                          4.000000                        4.000000   \n",
              "25%                          6.050000                        6.470000   \n",
              "50%                          6.850000                        7.640000   \n",
              "75%                          7.850000                        8.700000   \n",
              "max                         10.000000                       10.700000   \n",
              "\n",
              "       Serotonin 1e (5-HT1e) receptor  Serotonin 1f (5-HT1f) receptor  \\\n",
              "count                       91.000000                      127.000000   \n",
              "mean                         5.791172                        7.458423   \n",
              "std                          0.652239                        0.859240   \n",
              "min                          4.800000                        5.140000   \n",
              "25%                          5.360000                        7.000000   \n",
              "50%                          5.730000                        7.720000   \n",
              "75%                          6.175000                        8.020000   \n",
              "max                          8.200000                        8.800000   \n",
              "\n",
              "       Serotonin 2 (5-HT2) receptor  ...  Serotonin 2b (5-HT2b) receptor  \\\n",
              "count                   1469.000000  ...                     2337.000000   \n",
              "mean                       7.053201  ...                        6.603829   \n",
              "std                        1.159567  ...                        0.981462   \n",
              "min                        4.030000  ...                        4.190000   \n",
              "25%                        6.240000  ...                        5.900000   \n",
              "50%                        6.920000  ...                        6.523333   \n",
              "75%                        8.000000  ...                        7.210000   \n",
              "max                       10.300000  ...                       10.100000   \n",
              "\n",
              "       Serotonin 2c (5-HT2c) receptor  Serotonin 3 (5-HT3) receptor  \\\n",
              "count                     4343.000000                    939.000000   \n",
              "mean                         6.810210                      7.625768   \n",
              "std                          1.032874                      1.225942   \n",
              "min                          4.000000                      4.010000   \n",
              "25%                          6.050000                      6.800000   \n",
              "50%                          6.740000                      7.700000   \n",
              "75%                          7.512500                      8.580000   \n",
              "max                         10.700000                     10.420000   \n",
              "\n",
              "       Serotonin 3a (5-HT3a) receptor  Serotonin 3b (5-HT3b) receptor  \\\n",
              "count                     1040.000000                        8.000000   \n",
              "mean                         7.047520                        7.203500   \n",
              "std                          1.535413                        1.735342   \n",
              "min                          4.000000                        5.460000   \n",
              "25%                          5.700000                        5.490000   \n",
              "50%                          7.185000                        7.015000   \n",
              "75%                          8.410000                        8.393500   \n",
              "max                         10.400000                        9.604000   \n",
              "\n",
              "       Serotonin 4 (5-HT4) receptor  Serotonin 5a (5-HT5a) receptor  \\\n",
              "count                   1009.000000                      422.000000   \n",
              "mean                       7.645809                        6.573801   \n",
              "std                        1.179482                        1.089819   \n",
              "min                        5.000000                        4.070000   \n",
              "25%                        6.810000                        5.800000   \n",
              "50%                        7.640000                        6.390000   \n",
              "75%                        8.400000                        7.068750   \n",
              "max                       10.800000                        9.170000   \n",
              "\n",
              "       Serotonin 5b (5-HT5b) receptor  Serotonin 6 (5-HT6) receptor  \\\n",
              "count                            1.00                   4221.000000   \n",
              "mean                             7.17                      7.311171   \n",
              "std                               NaN                      1.143388   \n",
              "min                              7.17                      4.120000   \n",
              "25%                              7.17                      6.470000   \n",
              "50%                              7.17                      7.360000   \n",
              "75%                              7.17                      8.110000   \n",
              "max                              7.17                     10.400000   \n",
              "\n",
              "       Serotonin 7 (5-HT7) receptor  \n",
              "count                   3100.000000  \n",
              "mean                       6.977487  \n",
              "std                        1.016128  \n",
              "min                        4.000000  \n",
              "25%                        6.285000  \n",
              "50%                        6.990000  \n",
              "75%                        7.700000  \n",
              "max                       10.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pickle_file_path = PATH_DATA / \"torch_data_list.pkl\"\n",
        "\n",
        "if os.path.exists(pickle_file_path):\n",
        "    torch_data_list = pickle.load(open(pickle_file_path, \"rb\"))\n",
        "    print(\"Loaded torch_data_list from pickle file\")\n",
        "else:\n",
        "    print(\"Creating torch_data_list from scratch\")\n",
        "\n",
        "df = pd.read_csv(PATH_DATA / \"serotonin_binding_summary.csv\")\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of targets: 21\n",
            "Boolean mask: tensor([False, False, False,  True,  True,  True, False, False,  True, False,\n",
            "         True,  True,  True, False,  True, False,  True, False, False,  True,\n",
            "         True])\n",
            "Included targets (11): tensor([ 3,  4,  5,  8, 10, 11, 12, 14, 16, 19, 20])\n"
          ]
        }
      ],
      "source": [
        "df_targets = df.drop(columns=[\"molecule_id\", \"canonical_smiles\"])\n",
        "print(f\"Number of targets: {len(df_targets.columns)}\")\n",
        "\n",
        "# compute non-nan counts per column and create a boolean mask to filter targets to contain at least n_threshold non-nan values\n",
        "n_threshold = 1000\n",
        "non_nan_counts = torch.tensor(df_targets.notna().sum().values, dtype=torch.long)\n",
        "mask = non_nan_counts >= n_threshold\n",
        "valid_column_indices = torch.nonzero(mask, as_tuple=True)[0]\n",
        "\n",
        "print(\"Boolean mask:\", mask)\n",
        "print(f\"Included targets ({len(valid_column_indices)}):\", valid_column_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "63VicadqVXW3",
        "outputId": "a2fdd631-c9ad-4974-faeb-59190376c726"
      },
      "outputs": [],
      "source": [
        "periodic_table = rdchem.GetPeriodicTable()\n",
        "\n",
        "ATOM_PROPERTIES = {\n",
        "    atomic_num: [\n",
        "        periodic_table.GetAtomicWeight(atomic_num),\n",
        "        periodic_table.GetRvdw(atomic_num),\n",
        "        periodic_table.GetDefaultValence(atomic_num),\n",
        "    ]\n",
        "    for atomic_num in range(1, 119)  # all elements in periodic table\n",
        "}\n",
        "\n",
        "BOND_TYPES = [\n",
        "    Chem.rdchem.BondType.SINGLE,\n",
        "    Chem.rdchem.BondType.AROMATIC,\n",
        "    Chem.rdchem.BondType.DOUBLE,\n",
        "    Chem.rdchem.BondType.TRIPLE,\n",
        "]\n",
        "\n",
        "\n",
        "def create_torch_data(smiles: str, targets: torch.Tensor) -> Data:\n",
        "    # getting RDKit molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    Chem.Molf\n",
        "\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    # add explicit hydrogen atoms to the molecule (are not included in the SMILES string) so that its 3D structure is complete\n",
        "    mol = Chem.AddHs(mol)\n",
        "\n",
        "    # EmbedMolecule positions atoms of mol in 3D space stochastically; if it fails (returning -1) return None\n",
        "    if AllChem.EmbedMolecule(mol, randomSeed=42) == -1:\n",
        "        return None\n",
        "\n",
        "    # optimize the 3D structure using Universal Force Field (UFF) to lower mol's energy\n",
        "    AllChem.UFFOptimizeMolecule(mol)\n",
        "\n",
        "    # conformer contains 3D coordinates for mol's atoms\n",
        "    conformer = mol.GetConformer()\n",
        "\n",
        "    # atom-level features and 3D positions\n",
        "    atom_features, positions = [], []\n",
        "    for atom in mol.GetAtoms():\n",
        "        atomic_num = atom.GetAtomicNum()\n",
        "        atomic_mass, vdw_radius, valence = ATOM_PROPERTIES.get(\n",
        "            atomic_num, [0.0, 0.0, 0]\n",
        "        )\n",
        "\n",
        "        features = [\n",
        "            atomic_mass,\n",
        "            vdw_radius,\n",
        "            valence,\n",
        "            atom.GetFormalCharge(),\n",
        "            int(atom.GetIsAromatic()),\n",
        "            atom.GetDegree(),\n",
        "        ] + [\n",
        "            1.0 if atom.GetHybridization() == h else 0.0\n",
        "            for h in (\n",
        "                Chem.rdchem.HybridizationType.SP,\n",
        "                Chem.rdchem.HybridizationType.SP2,\n",
        "                Chem.rdchem.HybridizationType.SP3,\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        atom_features.append(features)\n",
        "\n",
        "        pos = conformer.GetAtomPosition(atom.GetIdx())\n",
        "        positions.append([pos.x, pos.y, pos.z])\n",
        "\n",
        "    # transform to PyTorch tensors\n",
        "    x = torch.tensor(atom_features, dtype=torch.float)\n",
        "    pos = torch.tensor(positions, dtype=torch.float)\n",
        "\n",
        "    # bonds between atoms – indices of connected atoms as well as types and conjugation\n",
        "    edge_index, edge_attr = [], []\n",
        "    for bond in mol.GetBonds():\n",
        "        # indices of bonded atoms\n",
        "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "\n",
        "        # one-hot encode bond type\n",
        "        bond_type = bond.GetBondType()\n",
        "        bond_type_one_hot = [1.0 if bond_type == b else 0.0 for b in BOND_TYPES]\n",
        "\n",
        "        is_conjugated = 1.0 if bond.GetIsConjugated() else 0.0\n",
        "\n",
        "        bond_feat = bond_type_one_hot + [is_conjugated]\n",
        "\n",
        "        # adding bond to both nodes\n",
        "        edge_index += [[i, j], [j, i]]\n",
        "        edge_attr += [bond_feat, bond_feat]\n",
        "\n",
        "    # transform to PyTorch tensors\n",
        "    # edge_index tensor is transposed to fit torch_geometric's expected shape (2, number_of_edges).\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "    # graph as PyTorch Geometric Data object\n",
        "    # x: atom features, [atomic number, degree, formal charge, hybridization]\n",
        "    # pos: 3D positions of atoms, [x, y, z]\n",
        "    # edge_index: connectivity indices between atoms, [[i, j], [j, i]]\n",
        "    # edge_attr: features per bond, [[bond type, conjugation], [bond type, conjugation]]\n",
        "    return Data(\n",
        "        x=x,\n",
        "        pos=pos,\n",
        "        edge_index=edge_index,\n",
        "        edge_attr=edge_attr,\n",
        "        y=targets,\n",
        "        smiles=smiles,\n",
        "    )\n",
        "\n",
        "\n",
        "if not torch_data_list:\n",
        "    torch_data_list = [\n",
        "        create_torch_data(\n",
        "            row.canonical_smiles,\n",
        "            torch.tensor(df_targets.iloc[i].values, dtype=torch.float),\n",
        "        )\n",
        "        for i, row in enumerate(df.itertuples(index=False))\n",
        "    ]\n",
        "\n",
        "    pickle_file_path = PATH_DATA / \"torch_data_list.pkl\"\n",
        "\n",
        "    with open(pickle_file_path, \"wb\") as f:\n",
        "        pickle.dump(torch_data_list, f)\n",
        "\n",
        "    print(f\"Saved torch_data_list to {pickle_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create training and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of items in filtered_torch_data_list: 23439 / 23456\n",
            "filtered_torch_data_list[0]: Data(x=[49, 9], edge_index=[2, 104], edge_attr=[104, 5], y=[21], pos=[49, 3], smiles='COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC')\n",
            "Number of items in new_filtered_torch_data_list: 22467 / 23439\n",
            "Data(x=[49, 9], edge_index=[2, 104], edge_attr=[104, 5], y=[11], pos=[49, 3], smiles='COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC')\n"
          ]
        }
      ],
      "source": [
        "filtered_torch_data_list = [d.clone() for d in torch_data_list if d is not None]\n",
        "print(\n",
        "    f\"Number of items in filtered_torch_data_list: {len(filtered_torch_data_list)} / {len(torch_data_list)}\"\n",
        ")  # still retaining original torch_data_list for reference to df later\n",
        "print(f\"filtered_torch_data_list[0]: {filtered_torch_data_list[0]}\")\n",
        "\n",
        "new_filtered_torch_data_list = []\n",
        "\n",
        "# only include targets with at least n_threshold non-nan values\n",
        "for d in filtered_torch_data_list:\n",
        "    d.y = d.y[valid_column_indices]\n",
        "    if not torch.isnan(d.y).all():\n",
        "        new_filtered_torch_data_list.append(d)\n",
        "\n",
        "print(\n",
        "    f\"Number of items in new_filtered_torch_data_list: {len(new_filtered_torch_data_list)} / {len(filtered_torch_data_list)}\"\n",
        ")\n",
        "filtered_torch_data_list = new_filtered_torch_data_list\n",
        "\n",
        "split_idx = int(0.8 * len(filtered_torch_data_list))\n",
        "\n",
        "# data_graph_train = DataLoader(\n",
        "#     filtered_torch_data_list[:split_idx], batch_size=32, shuffle=True\n",
        "# )\n",
        "# data_graph_test = DataLoader(\n",
        "#     filtered_torch_data_list[split_idx:], batch_size=32, shuffle=False\n",
        "# )\n",
        "filtered_torch_data_list_train = filtered_torch_data_list[:split_idx]\n",
        "filtered_torch_data_list_test = filtered_torch_data_list[split_idx:]\n",
        "\n",
        "# print(\n",
        "#     f\"# training batches: {len(data_graph_train)}\\n# test batches: {len(data_graph_test)}\"\n",
        "# )\n",
        "print(filtered_torch_data_list_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using MPS\n",
            "Node features: 9, targets: 11, edge attributes: 5\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Using CUDA\")\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    print(\"Using MPS\")\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "epochs = 10\n",
        "n_hidden = 32\n",
        "\n",
        "n_in = filtered_torch_data_list_train[0].x.shape[1]\n",
        "n_out = len(valid_column_indices)\n",
        "n_edge_attr = filtered_torch_data_list_train[0].edge_attr.shape[1]\n",
        "\n",
        "print(f\"Node features: {n_in}, targets: {n_out}, edge attributes: {n_edge_attr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE per target: [1.0670071 1.0954461 2.252836  0.9090124 1.0494274 1.2034993 0.7353269\n",
            " 2.012234  1.5253873 1.5388899 0.9311896]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class MeanBaseline:\n",
        "    def __init__(self):\n",
        "        self.mean_ = None\n",
        "\n",
        "    def fit(self, y):\n",
        "        self.mean_ = np.nanmean(y, axis=0)\n",
        "\n",
        "    def predict(self, n):\n",
        "        return np.tile(self.mean_, (n, 1))\n",
        "\n",
        "\n",
        "split_idx_baseline = int(0.8 * len(filtered_torch_data_list_train))\n",
        "\n",
        "y_train_baseline = [\n",
        "    d.y.numpy() for d in filtered_torch_data_list_train[:split_idx_baseline]\n",
        "]\n",
        "y_val_baseline = [\n",
        "    d.y.numpy() for d in filtered_torch_data_list_train[split_idx_baseline:]\n",
        "]\n",
        "\n",
        "naive_baseline = MeanBaseline()\n",
        "naive_baseline.fit(y_train_baseline)\n",
        "naive_baseline_predictions = naive_baseline.predict(len(y_val_baseline))\n",
        "\n",
        "# compute mse\n",
        "mse_per_target = np.nanmean((y_val_baseline - naive_baseline_predictions) ** 2, axis=0)\n",
        "print(f\"MSE per target: {mse_per_target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline Model: Random Forest with 2D Descriptors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y[:split_idx_rf], y[split_idx_rf:]\n\u001b[1;32m     70\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     74\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, y_pred)\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1387\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1371\u001b[0m     X,\n\u001b[1;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[0;32m-> 1387\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1397\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1397\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "# tried a bunch of descriptor functions from Descriptors._descList – these are the ones that did NOT crash the kernel ...\n",
        "safe_descriptors = [\n",
        "    \"MolWt\",\n",
        "    \"MolLogP\",\n",
        "    \"MolMR\",\n",
        "    \"NumValenceElectrons\",\n",
        "    \"NumRadicalElectrons\",\n",
        "    \"HeavyAtomCount\",\n",
        "    \"NHOHCount\",\n",
        "    \"NOCount\",\n",
        "    \"RingCount\",\n",
        "    \"FractionCSP3\",\n",
        "    \"TPSA\",\n",
        "    \"NumHDonors\",\n",
        "    \"NumHAcceptors\",\n",
        "    \"NumRotatableBonds\",\n",
        "    \"HallKierAlpha\",\n",
        "    \"Kappa1\",\n",
        "    \"Kappa2\",\n",
        "    \"Kappa3\",\n",
        "    \"Chi0\",\n",
        "    \"Chi1\",\n",
        "    \"fr_Al_COO\",\n",
        "    \"fr_Al_OH\",\n",
        "    \"fr_Ar_N\",\n",
        "    \"fr_C_O\",\n",
        "    \"fr_NH1\",\n",
        "    \"fr_NH2\",\n",
        "]\n",
        "\n",
        "descriptor_functions = {name: getattr(Descriptors, name) for name in safe_descriptors}\n",
        "\n",
        "\n",
        "# extract a fixed-length feature vector from the graph data, as input to RF model\n",
        "def compute_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    desc_values = []\n",
        "    for _, func in descriptor_functions.items():\n",
        "        try:\n",
        "            desc_values.append(func(mol))\n",
        "        except:\n",
        "            print(f\"Error computing descriptor {func}\")\n",
        "    return np.array(desc_values)\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for data in filtered_torch_data_list_train:\n",
        "    features = compute_descriptors(data.smiles)\n",
        "    if features is None:\n",
        "        continue\n",
        "    X.append(features)\n",
        "    target_val = data.y.cpu().numpy() if data.y.numel() > 0 else np.nan\n",
        "    y.append(target_val)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "split_idx_rf = int(0.8 * len(filtered_torch_data_list_train))\n",
        "X_train, X_val = X[:split_idx_rf], X[split_idx_rf:]\n",
        "y_train, y_val = y[:split_idx_rf], y[split_idx_rf:]\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_val)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "print(\"Val MSE:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 1: PyTorch Implementation of a 3D GCN\n",
        "\n",
        "In this section, a 3D graph convolutional network is created using PyTorch. The model takes as input a 3D molecular graph and outputs predictions of the serotonergic binding affinity of the molecule.\n",
        "\n",
        "Information about the graph input the model will receive and process:\n",
        "\n",
        "-   The feature matrix H contains the node (atom) features. Each row corresponds to a node, and each column corresponds to a feature.\n",
        "-   The adjacency matrix A is built from the edge_index tensor, which contains the indices of the edges in the graph. The matrix A is built under the hood of the GCNConv class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.nn import NNConv, GCNConv, global_mean_pool\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SeroGCN(torch.nn.Module):\n",
        "    def __init__(self, n_in, n_hidden, n_out, n_edge_attr):\n",
        "        super(SeroGCN, self).__init__()\n",
        "\n",
        "        # edge_network = torch.nn.Sequential(\n",
        "        #     torch.nn.Linear(n_edge_attr, n_hidden * n_in),\n",
        "        #     torch.nn.ReLU(),\n",
        "        # )\n",
        "\n",
        "        self.pos_lin = Linear(3, n_in)  # simple positional encoding layer\n",
        "\n",
        "        # self.conv1 = NNConv(n_in, n_hidden, edge_network, aggr=\"mean\")\n",
        "        self.conv1 = GCNConv(n_in, n_hidden)\n",
        "        self.conv2 = GCNConv(n_hidden, n_hidden)\n",
        "\n",
        "        self.fc = Linear(n_hidden, n_out)\n",
        "\n",
        "    def forward(self, mol_batch) -> torch.Tensor:\n",
        "        x, pos, edge_index, edge_attr = (\n",
        "            mol_batch.x,\n",
        "            mol_batch.pos,\n",
        "            mol_batch.edge_index,\n",
        "            mol_batch.edge_attr,\n",
        "        )\n",
        "\n",
        "        pos_feat = self.pos_lin(pos)\n",
        "        x = x + pos_feat  # simple positional encoding\n",
        "\n",
        "        # x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = global_mean_pool(\n",
        "            x, mol_batch.batch\n",
        "        )  # global mean pooling aggregates node features, returning a single graph-level vectorial representation\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 2: Pretraining SeroGCN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Downloading the ZINC dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[29, 1], edge_index=[2, 64], edge_attr=[64], y=[1])\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import ZINC\n",
        "\n",
        "zinc_dataset = ZINC(root=PATH_DATA / \"ZINC\", subset=True)\n",
        "zinc_loader = DataLoader(zinc_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(zinc_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node features: 1, targets: 1, edge attributes: 1\n",
            "tensor([0.8350])\n"
          ]
        }
      ],
      "source": [
        "n_in_zinc = zinc_dataset.num_node_features\n",
        "n_edge_attr_zinc = zinc_dataset.num_edge_features\n",
        "n_out_zinc = zinc_dataset[0].y.shape[0]\n",
        "\n",
        "print(\n",
        "    f\"Node features: {n_in_zinc}, targets: {n_out_zinc}, edge attributes: {n_edge_attr_zinc}\"\n",
        ")\n",
        "\n",
        "print(zinc_dataset[0].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "pretrained_model = SeroGCN(\n",
        "    n_in=n_in_zinc,\n",
        "    n_hidden=n_hidden,\n",
        "    n_out=n_out_zinc,\n",
        "    n_edge_attr=n_edge_attr_zinc,\n",
        ")\n",
        "pretrained_model = pretrained_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def masked_mse_loss(pred, target):\n",
        "    # mask of non-nan targets\n",
        "    mask = ~torch.isnan(target)\n",
        "    if mask.sum() == 0:\n",
        "        # return 0 loss, so that it doesn't affect the gradient\n",
        "        return torch.tensor(0.0, requires_grad=True, device=target.device)\n",
        "    # squared error for entries that are valid\n",
        "    loss = (pred[mask] - target[mask]) ** 2\n",
        "    return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit(\n",
        "    model: torch.nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Training ---\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        start_epoch = time.time()\n",
        "\n",
        "        for i, data in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = masked_mse_loss(\n",
        "                out, data.y.view(-1, n_out)\n",
        "            )  # make sure that even if there's only one target var, it's still a 2D tensor\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            pct_complete = 100 * (i + 1) / len(train_loader)\n",
        "            sys.stdout.write(\n",
        "                f\"\\rEpoch {epoch+1}/{epochs} - {pct_complete:.2f}% complete\"\n",
        "            )\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        train_loss_avg = epoch_loss / len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_epoch_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_data = val_data.to(device)\n",
        "                val_out = model(val_data)\n",
        "                val_loss = masked_mse_loss(val_out, val_data.y.view(-1, n_out))\n",
        "                val_epoch_loss += val_loss.item()\n",
        "        val_loss_avg = val_epoch_loss / len(val_loader)\n",
        "        end_epoch = time.time()\n",
        "\n",
        "        print(\n",
        "            f\"\\nEpoch {epoch+1} complete. Train Loss = {train_loss_avg:.4f} | Val Loss = {val_loss_avg:.4f}. Time taken: {end_epoch - start_epoch:.2f}s\"\n",
        "        )\n",
        "        train_losses.append(train_loss_avg)\n",
        "        val_losses.append(val_loss_avg)\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "sero_gcn = SeroGCN(\n",
        "    n_in=n_in, n_hidden=n_hidden, n_out=n_out, n_edge_attr=n_edge_attr\n",
        ").to(device)\n",
        "sero_gcn_optimizer = torch.optim.Adam(sero_gcn.parameters(), lr=0.01)\n",
        "# sero_gcn_criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - 100.00% complete\n",
            "Epoch 1 complete. Train Loss = 1.4948 | Val Loss = 1.2075. Time taken: 105.51s\n",
            "Epoch 2/10 - 100.00% complete\n",
            "Epoch 2 complete. Train Loss = 1.3919 | Val Loss = 1.1191. Time taken: 83.97s\n",
            "Epoch 3/10 - 100.00% complete\n",
            "Epoch 3 complete. Train Loss = 1.4179 | Val Loss = 1.1003. Time taken: 70.52s\n",
            "Epoch 4/10 - 100.00% complete\n",
            "Epoch 4 complete. Train Loss = 1.3945 | Val Loss = 1.2143. Time taken: 91.50s\n",
            "Epoch 5/10 - 100.00% complete\n",
            "Epoch 5 complete. Train Loss = 1.3408 | Val Loss = 1.1105. Time taken: 114.29s\n",
            "Epoch 6/10 - 100.00% complete\n",
            "Epoch 6 complete. Train Loss = 1.3575 | Val Loss = 1.3576. Time taken: 98.64s\n",
            "Epoch 7/10 - 100.00% complete\n",
            "Epoch 7 complete. Train Loss = 1.3483 | Val Loss = 1.0863. Time taken: 88.23s\n",
            "Epoch 8/10 - 100.00% complete\n",
            "Epoch 8 complete. Train Loss = 1.3541 | Val Loss = 1.1224. Time taken: 120.38s\n",
            "Epoch 9/10 - 13.68% complete"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      3\u001b[0m     filtered_torch_data_list_train[:train_val_split], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      6\u001b[0m     filtered_torch_data_list_train[train_val_split:], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msero_gcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msero_gcn_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[105], line 24\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m masked_mse_loss(\n\u001b[1;32m     22\u001b[0m     out, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_out)\n\u001b[1;32m     23\u001b[0m )  \u001b[38;5;66;03m# make sure that even if there's only one target var, it's still a 2D tensor\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_val_split = int(0.8 * len(filtered_torch_data_list_train))\n",
        "train_loader = DataLoader(\n",
        "    filtered_torch_data_list_train[:train_val_split], batch_size=32, shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    filtered_torch_data_list_train[train_val_split:], batch_size=32, shuffle=False\n",
        ")\n",
        "\n",
        "train_losses, val_losses = fit(\n",
        "    sero_gcn, train_loader, val_loader, sero_gcn_optimizer, epochs\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
