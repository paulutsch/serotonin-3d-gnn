{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jiKdt3EYQ6d"
   },
   "source": [
    "# Serotonin 3D GNN Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gswc-LH5YWga"
   },
   "source": [
    "This project builds upon research done by Łapińska et al. (2024): https://doi.org/10.3390/pharmaceutics16030349\n",
    "\n",
    "Data used: https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_35/\n",
    "\n",
    "Move the unpacked chembl_35_sqlite.tar.gz file into the data/ dir.\n",
    "\n",
    "The research linked above presents two Quantitative Structure-Activity Relationship (QSAR) models to predict serotonergic binding affinity and selectivity, respectively, using Mordred molecular 2D descriptors. Specifically, one model classifies compounds binarily as \"active\" or \"inactive\", with a cutoff of pKi = 7. Another model does multiclass classification to predict the serotonergic selectivity of compounds previously classified as \"active\".\n",
    "\n",
    "I am following a similar approach, but using 3D molecular graph representations instead of 2D molecular descriptors as input modality and using only the ChEMBL database, not ZINC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGK0LMuRYC6g"
   },
   "source": [
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugvkdqJgYMum"
   },
   "source": [
    "### Configuration & Google Drive/Colab Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19313,
     "status": "ok",
     "timestamp": 1740304861091,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "q2XchrWsWuIk",
    "outputId": "87736f8b-1dbf-4f0e-d32d-d35396179af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'Running in Colab' if IN_COLAB else 'Running locally'}\")\n",
    "\n",
    "PATH_NOTEBOOK = (\n",
    "    Path(\"/content/drive/MyDrive/Colab Notebooks/serotonin-3d-gnn.ipynb\")\n",
    "    if IN_COLAB\n",
    "    else Path(\n",
    "        \"/Users/paul/Library/CloudStorage/GoogleDrive-unoutsch@gmail.com/My Drive/Colab Notebooks/serotonin-3d-gnn.ipynb\"\n",
    "    )\n",
    ")\n",
    "PATH_REPO = (\n",
    "    Path(\"/content/drive/MyDrive/Repositories/serotonin-3d-gnn\")\n",
    "    if IN_COLAB\n",
    "    else Path.cwd()\n",
    ")\n",
    "PATH_DATA = PATH_REPO / \"data\"\n",
    "PATH_WEIGHTS = PATH_REPO / \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko5Es7NyYw7W"
   },
   "source": [
    "### Installing Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97346,
     "status": "ok",
     "timestamp": 1740304958440,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "sPtfbBFEYwKR",
    "outputId": "70b28c16-b881-4f96-d7ff-00807bd07b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2.2.2)\n",
      "Collecting rdkit (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 4))\n",
      "  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2.5.1+cu124)\n",
      "Collecting torch-geometric (from -r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8))\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.11.12)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (5.9.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r /content/drive/MyDrive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2025.1.31)\n",
      "Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdkit-2024.9.5 torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "%pip install --requirement \"$PATH_REPO/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpNxNxd3UG04"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 22256,
     "status": "ok",
     "timestamp": 1740304980695,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "6qaxG6KzSQbs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdchem\n",
    "import shutil\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyOFFWimQtGD"
   },
   "source": [
    "### Syncing this file between Colab and local Git repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7qVn7CnR7FK"
   },
   "source": [
    "Make sure the paths exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-AEKpQQaQ5U4",
    "outputId": "3616a8c4-0786-48f3-a11e-8ffc77ea24a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied notebook to Google Drive.\n"
     ]
    }
   ],
   "source": [
    "def copy_notebook():\n",
    "    if IN_COLAB:\n",
    "        shutil.copyfile(PATH_NOTEBOOK, PATH_REPO / \"serotonin-3d-gnn.ipynb\")\n",
    "        print(\"Copied notebook to repo.\")\n",
    "    else:\n",
    "        shutil.copyfile(PATH_REPO / \"serotonin-3d-gnn.ipynb\", PATH_NOTEBOOK)\n",
    "        print(\"Copied notebook to Google Drive.\")\n",
    "\n",
    "\n",
    "copy_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxQZohBJhQoT"
   },
   "source": [
    "### Setting Torch Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740304980713,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "YXkqUkBKhQoT",
    "outputId": "da4c7dfa-ec25-487f-ec36-0cf805404757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7iFshPsYhff"
   },
   "source": [
    "---\n",
    "\n",
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDQ9MbtCNEAb"
   },
   "source": [
    "In order to collect the desired data from the ChEMBL SQL database and transform it into a .csv file, I undertook the steps detailed in `data/README.md`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEEdENl6NzpP"
   },
   "source": [
    "### Loading and Preprocessing Serotonin Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-wRU6qqhQoU"
   },
   "source": [
    "If the pickled torch_data_list already exists, load it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 25493,
     "status": "ok",
     "timestamp": 1740305006207,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "1yBrNIjphQoU",
    "outputId": "aad20f40-7d1f-45f1-9526-194257a37639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded torch_data_list from pickle file\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-563a30e5-b826-4649-a2b6-decf7d578e76\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_id</th>\n",
       "      <th>Serotonin (5-HT) receptor</th>\n",
       "      <th>Serotonin 1 (5-HT1) receptor</th>\n",
       "      <th>Serotonin 1 receptors; 5-HT1B &amp; 5-HT1D</th>\n",
       "      <th>Serotonin 1a (5-HT1a) receptor</th>\n",
       "      <th>Serotonin 1b (5-HT1b) receptor</th>\n",
       "      <th>Serotonin 1d (5-HT1d) receptor</th>\n",
       "      <th>Serotonin 1e (5-HT1e) receptor</th>\n",
       "      <th>Serotonin 1f (5-HT1f) receptor</th>\n",
       "      <th>Serotonin 2 (5-HT2) receptor</th>\n",
       "      <th>...</th>\n",
       "      <th>Serotonin 2b (5-HT2b) receptor</th>\n",
       "      <th>Serotonin 2c (5-HT2c) receptor</th>\n",
       "      <th>Serotonin 3 (5-HT3) receptor</th>\n",
       "      <th>Serotonin 3a (5-HT3a) receptor</th>\n",
       "      <th>Serotonin 3b (5-HT3b) receptor</th>\n",
       "      <th>Serotonin 4 (5-HT4) receptor</th>\n",
       "      <th>Serotonin 5a (5-HT5a) receptor</th>\n",
       "      <th>Serotonin 5b (5-HT5b) receptor</th>\n",
       "      <th>Serotonin 6 (5-HT6) receptor</th>\n",
       "      <th>Serotonin 7 (5-HT7) receptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.345600e+04</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9462.000000</td>\n",
       "      <td>1492.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>1469.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2337.000000</td>\n",
       "      <td>4343.000000</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4221.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.003325e+06</td>\n",
       "      <td>6.081759</td>\n",
       "      <td>6.683902</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.258523</td>\n",
       "      <td>6.952528</td>\n",
       "      <td>7.554968</td>\n",
       "      <td>5.791172</td>\n",
       "      <td>7.458423</td>\n",
       "      <td>7.053201</td>\n",
       "      <td>...</td>\n",
       "      <td>6.603829</td>\n",
       "      <td>6.810210</td>\n",
       "      <td>7.625768</td>\n",
       "      <td>7.047520</td>\n",
       "      <td>7.203500</td>\n",
       "      <td>7.645809</td>\n",
       "      <td>6.573801</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.311171</td>\n",
       "      <td>6.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.986583e+05</td>\n",
       "      <td>0.926906</td>\n",
       "      <td>1.104283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.152004</td>\n",
       "      <td>1.226482</td>\n",
       "      <td>1.365880</td>\n",
       "      <td>0.652239</td>\n",
       "      <td>0.859240</td>\n",
       "      <td>1.159567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981462</td>\n",
       "      <td>1.032874</td>\n",
       "      <td>1.225942</td>\n",
       "      <td>1.535413</td>\n",
       "      <td>1.735342</td>\n",
       "      <td>1.179482</td>\n",
       "      <td>1.089819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.143388</td>\n",
       "      <td>1.016128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>4.390000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5.140000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>7.17</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.291570e+05</td>\n",
       "      <td>5.385000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>6.470000</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>6.810000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.470000</td>\n",
       "      <td>6.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.757615e+05</td>\n",
       "      <td>5.925000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>5.730000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.523333</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.185000</td>\n",
       "      <td>7.015000</td>\n",
       "      <td>7.640000</td>\n",
       "      <td>6.390000</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.360000</td>\n",
       "      <td>6.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.965967e+06</td>\n",
       "      <td>6.657500</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>6.175000</td>\n",
       "      <td>8.020000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>7.512500</td>\n",
       "      <td>8.580000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>8.393500</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>7.068750</td>\n",
       "      <td>7.17</td>\n",
       "      <td>8.110000</td>\n",
       "      <td>7.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.881244e+06</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>10.420000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>9.604000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>9.170000</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-563a30e5-b826-4649-a2b6-decf7d578e76')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-563a30e5-b826-4649-a2b6-decf7d578e76 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-563a30e5-b826-4649-a2b6-decf7d578e76');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8bcc3c89-5abe-430a-ade6-650d73e63d91\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bcc3c89-5abe-430a-ade6-650d73e63d91')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8bcc3c89-5abe-430a-ade6-650d73e63d91 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        molecule_id  Serotonin (5-HT) receptor  Serotonin 1 (5-HT1) receptor  \\\n",
       "count  2.345600e+04                  90.000000                    252.000000   \n",
       "mean   1.003325e+06                   6.081759                      6.683902   \n",
       "std    8.986583e+05                   0.926906                      1.104283   \n",
       "min    9.700000e+01                   4.390000                      4.100000   \n",
       "25%    2.291570e+05                   5.385000                      5.800000   \n",
       "50%    5.757615e+05                   5.925000                      6.600000   \n",
       "75%    1.965967e+06                   6.657500                      7.585000   \n",
       "max    2.881244e+06                   9.800000                      9.300000   \n",
       "\n",
       "       Serotonin 1 receptors; 5-HT1B & 5-HT1D  Serotonin 1a (5-HT1a) receptor  \\\n",
       "count                                     1.0                     9462.000000   \n",
       "mean                                      6.2                        7.258523   \n",
       "std                                       NaN                        1.152004   \n",
       "min                                       6.2                        4.000000   \n",
       "25%                                       6.2                        6.480000   \n",
       "50%                                       6.2                        7.280000   \n",
       "75%                                       6.2                        8.060000   \n",
       "max                                       6.2                       11.000000   \n",
       "\n",
       "       Serotonin 1b (5-HT1b) receptor  Serotonin 1d (5-HT1d) receptor  \\\n",
       "count                     1492.000000                     1472.000000   \n",
       "mean                         6.952528                        7.554968   \n",
       "std                          1.226482                        1.365880   \n",
       "min                          4.000000                        4.000000   \n",
       "25%                          6.050000                        6.470000   \n",
       "50%                          6.850000                        7.640000   \n",
       "75%                          7.850000                        8.700000   \n",
       "max                         10.000000                       10.700000   \n",
       "\n",
       "       Serotonin 1e (5-HT1e) receptor  Serotonin 1f (5-HT1f) receptor  \\\n",
       "count                       91.000000                      127.000000   \n",
       "mean                         5.791172                        7.458423   \n",
       "std                          0.652239                        0.859240   \n",
       "min                          4.800000                        5.140000   \n",
       "25%                          5.360000                        7.000000   \n",
       "50%                          5.730000                        7.720000   \n",
       "75%                          6.175000                        8.020000   \n",
       "max                          8.200000                        8.800000   \n",
       "\n",
       "       Serotonin 2 (5-HT2) receptor  ...  Serotonin 2b (5-HT2b) receptor  \\\n",
       "count                   1469.000000  ...                     2337.000000   \n",
       "mean                       7.053201  ...                        6.603829   \n",
       "std                        1.159567  ...                        0.981462   \n",
       "min                        4.030000  ...                        4.190000   \n",
       "25%                        6.240000  ...                        5.900000   \n",
       "50%                        6.920000  ...                        6.523333   \n",
       "75%                        8.000000  ...                        7.210000   \n",
       "max                       10.300000  ...                       10.100000   \n",
       "\n",
       "       Serotonin 2c (5-HT2c) receptor  Serotonin 3 (5-HT3) receptor  \\\n",
       "count                     4343.000000                    939.000000   \n",
       "mean                         6.810210                      7.625768   \n",
       "std                          1.032874                      1.225942   \n",
       "min                          4.000000                      4.010000   \n",
       "25%                          6.050000                      6.800000   \n",
       "50%                          6.740000                      7.700000   \n",
       "75%                          7.512500                      8.580000   \n",
       "max                         10.700000                     10.420000   \n",
       "\n",
       "       Serotonin 3a (5-HT3a) receptor  Serotonin 3b (5-HT3b) receptor  \\\n",
       "count                     1040.000000                        8.000000   \n",
       "mean                         7.047520                        7.203500   \n",
       "std                          1.535413                        1.735342   \n",
       "min                          4.000000                        5.460000   \n",
       "25%                          5.700000                        5.490000   \n",
       "50%                          7.185000                        7.015000   \n",
       "75%                          8.410000                        8.393500   \n",
       "max                         10.400000                        9.604000   \n",
       "\n",
       "       Serotonin 4 (5-HT4) receptor  Serotonin 5a (5-HT5a) receptor  \\\n",
       "count                   1009.000000                      422.000000   \n",
       "mean                       7.645809                        6.573801   \n",
       "std                        1.179482                        1.089819   \n",
       "min                        5.000000                        4.070000   \n",
       "25%                        6.810000                        5.800000   \n",
       "50%                        7.640000                        6.390000   \n",
       "75%                        8.400000                        7.068750   \n",
       "max                       10.800000                        9.170000   \n",
       "\n",
       "       Serotonin 5b (5-HT5b) receptor  Serotonin 6 (5-HT6) receptor  \\\n",
       "count                            1.00                   4221.000000   \n",
       "mean                             7.17                      7.311171   \n",
       "std                               NaN                      1.143388   \n",
       "min                              7.17                      4.120000   \n",
       "25%                              7.17                      6.470000   \n",
       "50%                              7.17                      7.360000   \n",
       "75%                              7.17                      8.110000   \n",
       "max                              7.17                     10.400000   \n",
       "\n",
       "       Serotonin 7 (5-HT7) receptor  \n",
       "count                   3100.000000  \n",
       "mean                       6.977487  \n",
       "std                        1.016128  \n",
       "min                        4.000000  \n",
       "25%                        6.285000  \n",
       "50%                        6.990000  \n",
       "75%                        7.700000  \n",
       "max                       10.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_file_path = PATH_DATA / \"torch_data_list.pkl\"\n",
    "\n",
    "if os.path.exists(pickle_file_path):\n",
    "    torch_data_list = pickle.load(open(pickle_file_path, \"rb\"))\n",
    "    print(\"Loaded torch_data_list from pickle file\")\n",
    "else:\n",
    "    print(\"Creating torch_data_list from scratch\")\n",
    "\n",
    "df = pd.read_csv(PATH_DATA / \"serotonin_binding_summary.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "executionInfo": {
     "elapsed": 1763,
     "status": "ok",
     "timestamp": 1740305007971,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "TkTIP7hwhQoU",
    "outputId": "b0434ff6-47e8-4fe0-94d9-bd7ec3b0fcb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets: 21\n",
      "Boolean mask: tensor([False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False])\n",
      "Included targets (1): tensor([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_targets = df.drop(columns=[\"molecule_id\", \"canonical_smiles\"])\n",
    "print(f\"Number of targets: {len(df_targets.columns)}\")\n",
    "\n",
    "# compute non-nan counts per column and create a boolean mask to filter targets to contain at least n_threshold non-nan values\n",
    "n_threshold = 9000\n",
    "non_nan_counts = torch.tensor(df_targets.notna().sum().values, dtype=torch.long)\n",
    "mask = non_nan_counts >= n_threshold\n",
    "valid_column_indices = torch.nonzero(mask, as_tuple=True)[0]\n",
    "\n",
    "print(\"Boolean mask:\", mask)\n",
    "print(f\"Included targets ({len(valid_column_indices)}):\", valid_column_indices)\n",
    "\n",
    "# pdfs of targets\n",
    "plt.figure(figsize=(20, 10))\n",
    "df_targets.iloc[:, valid_column_indices.tolist()].plot.kde()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQlehqYVhQoU"
   },
   "source": [
    "### Creating 3D Molecular Graph Data from Serotonin Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740305007998,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "63VicadqVXW3"
   },
   "outputs": [],
   "source": [
    "periodic_table = rdchem.GetPeriodicTable()\n",
    "\n",
    "ATOM_PROPERTIES = {\n",
    "    atomic_num: [\n",
    "        periodic_table.GetAtomicWeight(atomic_num),\n",
    "        periodic_table.GetRvdw(atomic_num),\n",
    "        periodic_table.GetDefaultValence(atomic_num),\n",
    "    ]\n",
    "    for atomic_num in range(1, 119)  # all elements in periodic table\n",
    "}\n",
    "\n",
    "BOND_TYPES = [\n",
    "    Chem.rdchem.BondType.SINGLE,\n",
    "    Chem.rdchem.BondType.AROMATIC,\n",
    "    Chem.rdchem.BondType.DOUBLE,\n",
    "    Chem.rdchem.BondType.TRIPLE,\n",
    "]\n",
    "\n",
    "\n",
    "def create_torch_data(smiles: str, targets: torch.Tensor) -> Data:\n",
    "    # getting RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # add explicit hydrogen atoms to the molecule (are not included in the SMILES string) so that its 3D structure is complete\n",
    "    mol = Chem.AddHs(mol)\n",
    "\n",
    "    # EmbedMolecule positions atoms of mol in 3D space stochastically; if it fails (returning -1) return None\n",
    "    if AllChem.EmbedMolecule(mol, randomSeed=42) == -1:\n",
    "        return None\n",
    "\n",
    "    # optimize the 3D structure using Universal Force Field (UFF) to lower mol's energy\n",
    "    AllChem.UFFOptimizeMolecule(mol)\n",
    "\n",
    "    # conformer contains 3D coordinates for mol's atoms\n",
    "    conformer = mol.GetConformer()\n",
    "\n",
    "    # atom-level features and 3D positions\n",
    "    atom_features, positions = [], []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        atomic_mass, vdw_radius, valence = ATOM_PROPERTIES.get(\n",
    "            atomic_num, [0.0, 0.0, 0]\n",
    "        )\n",
    "\n",
    "        features = [\n",
    "            atomic_mass,\n",
    "            vdw_radius,\n",
    "            valence,\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetDegree(),\n",
    "        ] + [\n",
    "            1.0 if atom.GetHybridization() == h else 0.0\n",
    "            for h in (\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        atom_features.append(features)\n",
    "\n",
    "        pos = conformer.GetAtomPosition(atom.GetIdx())\n",
    "        positions.append([pos.x, pos.y, pos.z])\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    pos = torch.tensor(positions, dtype=torch.float)\n",
    "\n",
    "    # bonds between atoms – indices of connected atoms as well as types and conjugation\n",
    "    edge_index, edge_attr = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        # indices of bonded atoms\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "\n",
    "        # one-hot encode bond type\n",
    "        bond_type = bond.GetBondType()\n",
    "        bond_type_one_hot = [1.0 if bond_type == b else 0.0 for b in BOND_TYPES]\n",
    "\n",
    "        is_conjugated = 1.0 if bond.GetIsConjugated() else 0.0\n",
    "\n",
    "        bond_feat = bond_type_one_hot + [is_conjugated]\n",
    "\n",
    "        # adding bond to both nodes\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "        edge_attr += [bond_feat, bond_feat]\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    # edge_index tensor is transposed to fit torch_geometric's expected shape (2, number_of_edges).\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # graph as PyTorch Geometric Data object\n",
    "    # x: atom features, [atomic number, degree, formal charge, hybridization]\n",
    "    # pos: 3D positions of atoms, [x, y, z]\n",
    "    # edge_index: connectivity indices between atoms, [[i, j], [j, i]]\n",
    "    # edge_attr: features per bond, [[bond type, conjugation], [bond type, conjugation]]\n",
    "    return Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=targets,\n",
    "        smiles=smiles,\n",
    "    )\n",
    "\n",
    "\n",
    "if not torch_data_list:\n",
    "    torch_data_list = []\n",
    "\n",
    "    for i, row in enumerate(df.itertuples()):\n",
    "        pct_complete = 100 * i / len(df)\n",
    "        sys.stdout.write(f\"\\r{pct_complete:.2f}% complete\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        torch_data_list.append(\n",
    "            create_torch_data(\n",
    "                row.canonical_smiles,\n",
    "                torch.tensor(df_targets.iloc[i].values, dtype=torch.float),\n",
    "            )\n",
    "            for i, row in enumerate(df.itertuples(index=False))\n",
    "        )\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"torch_data_list.pkl\"\n",
    "\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(torch_data_list, f)\n",
    "\n",
    "    print(f\"Saved torch_data_list to {pickle_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW4epGYehQoV"
   },
   "source": [
    "### Splitting Serotonin Data into Train/Test (and Don't Touch the Test Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2008,
     "status": "ok",
     "timestamp": 1740305010007,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "W95-P-6whQoV",
    "outputId": "80193f95-2f8a-42bc-95e2-0a11dd6f8ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in filtered_torch_data_list: 23439 / 23456\n",
      "filtered_torch_data_list[0]: Data(x=[49, 9], edge_index=[2, 104], edge_attr=[104, 5], y=[21], pos=[49, 3], smiles='COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC')\n",
      "Number of items in new_filtered_torch_data_list: 9460 / 23439\n",
      "Data(x=[49, 9], edge_index=[2, 104], edge_attr=[104, 5], y=[1], pos=[49, 3], smiles='COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC')\n"
     ]
    }
   ],
   "source": [
    "filtered_torch_data_list = [d.clone() for d in torch_data_list if d is not None]\n",
    "print(\n",
    "    f\"Number of items in filtered_torch_data_list: {len(filtered_torch_data_list)} / {len(torch_data_list)}\"\n",
    ")  # still retaining original torch_data_list for reference to df later\n",
    "print(f\"filtered_torch_data_list[0]: {filtered_torch_data_list[0]}\")\n",
    "\n",
    "new_filtered_torch_data_list = []\n",
    "\n",
    "# only include targets with at least n_threshold non-nan values\n",
    "for d in filtered_torch_data_list:\n",
    "    d.y = d.y[valid_column_indices]\n",
    "    if not torch.isnan(d.y).all():\n",
    "        new_filtered_torch_data_list.append(d)\n",
    "\n",
    "print(\n",
    "    f\"Number of items in new_filtered_torch_data_list: {len(new_filtered_torch_data_list)} / {len(filtered_torch_data_list)}\"\n",
    ")\n",
    "filtered_torch_data_list = new_filtered_torch_data_list\n",
    "\n",
    "split_idx = int(0.8 * len(filtered_torch_data_list))\n",
    "\n",
    "filtered_torch_data_list_train = filtered_torch_data_list[:split_idx]\n",
    "filtered_torch_data_list_test = filtered_torch_data_list[split_idx:]\n",
    "\n",
    "print(filtered_torch_data_list_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfVKAQr1hQoV"
   },
   "source": [
    "### Loading ZINC Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCS_tzY_hQoV"
   },
   "source": [
    "Data used for pre-training: https://www.kaggle.com/datasets/basu369victor/zinc250k?resource=download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 6015,
     "status": "ok",
     "timestamp": 1740305016027,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "hPickcJxhQoV",
    "outputId": "dd489357-3fc2-4954-eff1-baa046547999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretraining_df = pd.read_csv(PATH_DATA / \"250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "\n",
    "pretraining_df.head()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "pretraining_df.iloc[:, [2]].plot.kde()\n",
    "plt.xlim(0, 1)\n",
    "plt.xticks(ticks=np.arange(0, 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXzTFSeUhQoV"
   },
   "source": [
    "### Creating 3D Molecular Graph Data from ZINC Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121637,
     "status": "ok",
     "timestamp": 1740305247679,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "WR1FQEtshQoV",
    "outputId": "8415d350-9fd1-48a3-9924-1c816efc8110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretraining_torch_data_list from pickle file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[44, 9], edge_index=[2, 92], edge_attr=[92, 5], y=[1], pos=[44, 3], smiles='CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n",
       "')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(PATH_DATA / \"pretraining_torch_data_list.pkl\"):\n",
    "    pretraining_torch_data_list = pickle.load(\n",
    "        open(PATH_DATA / \"pretraining_torch_data_list.pkl\", \"rb\")\n",
    "    )\n",
    "    print(\"Loaded pretraining_torch_data_list from pickle file\")\n",
    "else:\n",
    "    pretraining_torch_data_list = []\n",
    "    for i, row in enumerate(pretraining_df.itertuples(index=False)):\n",
    "        if i % 10 == 0:\n",
    "            pct_complete = i / len(pretraining_df) * 100\n",
    "            sys.stdout.write(f\"\\r{pct_complete:.2f}% complete\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        pretraining_torch_data_list.append(\n",
    "            create_torch_data(\n",
    "                row.smiles,\n",
    "                torch.tensor(\n",
    "                    [row.qed], dtype=torch.float\n",
    "                ),  # use QED as target, representing \"drug-likeness\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"pretraining_torch_data_list.pkl\"\n",
    "\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(pretraining_torch_data_list, f)\n",
    "\n",
    "    print(f\"Saved pretraining_torch_data_list to {pickle_file_path}\")\n",
    "\n",
    "pretraining_torch_data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JX8z8mrhQoW"
   },
   "source": [
    "Remove None objects from the ZINC data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21800,
     "status": "ok",
     "timestamp": 1740305431470,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "FoObyIZQhQoW",
    "outputId": "2c281d36-73f6-4926-b1e6-4751b9a80c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in filtered_pretraining_torch_data_list: 249425 / 249455\n"
     ]
    }
   ],
   "source": [
    "filtered_pretraining_torch_data_list = [\n",
    "    d.clone() for d in pretraining_torch_data_list if d is not None\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Number of items in filtered_pretraining_torch_data_list: {len(filtered_pretraining_torch_data_list)} / {len(pretraining_torch_data_list)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPVwASxvhQoW"
   },
   "source": [
    "### Create ZINC subset for hyperparam tuning\n",
    "\n",
    "Create a new list with the first 10k samples of the ZINC dataset for hyperparam tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6041,
     "status": "ok",
     "timestamp": 1740305437513,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "XeOLW7_6hQoW",
    "outputId": "e014fc70-a466-46eb-b13f-415dad087b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded filtered_pretraining_torch_data_list_10k from pickle file\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\"):\n",
    "    filtered_pretraining_torch_data_list_10k = pickle.load(\n",
    "        open(PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\", \"rb\")\n",
    "    )\n",
    "    print(\"Loaded filtered_pretraining_torch_data_list_10k from pickle file\")\n",
    "else:\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(filtered_pretraining_torch_data_list)\n",
    "\n",
    "    filtered_pretraining_torch_data_list_10k = filtered_pretraining_torch_data_list[\n",
    "        :10000\n",
    "    ]\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\"\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(filtered_pretraining_torch_data_list_10k, f)\n",
    "        print(f\"Saved filtered_pretraining_torch_data_list_10k to {pickle_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vDOpQmFhQoW"
   },
   "source": [
    "---\n",
    "\n",
    "## Model Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXYo_QiqhQoW"
   },
   "source": [
    "### Naive Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740305437516,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "EzwGqdrhhQoW"
   },
   "outputs": [],
   "source": [
    "class MeanBaseline:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        self.mean_ = np.nanmean(y, axis=0)\n",
    "\n",
    "    def predict(self, n):\n",
    "        return np.tile(self.mean_, (n, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvehcFMGhQoW"
   },
   "source": [
    "### SeroGCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740305437522,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "f9C_6NOzhQoW",
    "outputId": "e5c22bbc-5602-49ba-cc36-8e42d7e99494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features: 9, targets: 1, edge attributes: 5\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_in = filtered_torch_data_list_train[0].x.shape[1]\n",
    "n_out = len(valid_column_indices)\n",
    "n_edge_attr = filtered_torch_data_list_train[0].edge_attr.shape[1]\n",
    "\n",
    "print(f\"Node features: {n_in}, targets: {n_out}, edge attributes: {n_edge_attr}\")\n",
    "\n",
    "\n",
    "class SeroGCN(torch.nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(SeroGCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(n_in, n_hidden)\n",
    "        self.conv2 = GCNConv(n_hidden, n_hidden)\n",
    "        self.fc = Linear(n_hidden, n_out)\n",
    "        self.sigma = 1.0  # distance weighting parameter\n",
    "\n",
    "    def forward(self, mol_batch) -> torch.Tensor:\n",
    "        x, pos, edge_index, edge_attr = (\n",
    "            mol_batch.x,\n",
    "            mol_batch.pos,\n",
    "            mol_batch.edge_index,\n",
    "            mol_batch.edge_attr,\n",
    "        )\n",
    "\n",
    "        row, col = edge_index\n",
    "        eucl_edge_dist = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "        weight_distance = torch.exp(\n",
    "            -(eucl_edge_dist**2) / (2 * self.sigma**2)\n",
    "        )  # Gaussian distance weighting\n",
    "\n",
    "        # message passing with diustance and angle weights\n",
    "        x = self.conv1(x, edge_index, edge_weight=weight_distance)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight=weight_distance)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # global pooling for graph-level representation\n",
    "        x = global_mean_pool(x, mol_batch.batch)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiVYy5b9hQoX"
   },
   "source": [
    "---\n",
    "\n",
    "## Training Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-epVrheQhQoX"
   },
   "outputs": [],
   "source": [
    "# def masked_mse_loss(pred, target):\n",
    "#     # mask of non-nan targets\n",
    "#     mask = ~torch.isnan(target)\n",
    "#     if mask.sum() == 0:\n",
    "#         # return 0 loss, so that it doesn't affect the gradient\n",
    "#         return torch.tensor(0.0, requires_grad=True, device=target.device)\n",
    "#     # squared error for entries that are valid\n",
    "#     loss = (pred[mask] - target[mask]) ** 2\n",
    "#     return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740305437523,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "u-SuA9MehQoX"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    epochs: int,\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(\n",
    "                out, data.y.view(-1, n_out)\n",
    "            )  # make sure that even if there's only one target var, it's still a 2D tensor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pct_complete = 100 * (i + 1) / len(train_loader)\n",
    "            sys.stdout.write(\n",
    "                f\"\\rEpoch {epoch+1}/{epochs} - {pct_complete:.2f}% complete\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        train_loss_avg = epoch_loss / len(train_loader)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_data = val_data.to(device)\n",
    "                val_out = model(val_data)\n",
    "                val_loss = criterion(val_out, val_data.y.view(-1, n_out))\n",
    "                val_epoch_loss += val_loss.item()\n",
    "        val_loss_avg = val_epoch_loss / len(val_loader)\n",
    "        end_epoch = time.time()\n",
    "\n",
    "        print(\n",
    "            f\"\\nEpoch {epoch+1} completed. Train Loss = {train_loss_avg:.4f} | Val Loss = {val_loss_avg:.4f}. Time taken: {end_epoch - start_epoch:.2f}s\"\n",
    "        )\n",
    "        train_losses.append(train_loss_avg)\n",
    "        val_losses.append(val_loss_avg)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740314582365,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "k5vqfLNAhQoY"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "def k_fold_cv(\n",
    "    initialized_model,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    dataset,\n",
    "    k=5,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    "    fit_final_model=False,\n",
    "):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{k} ---\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model_tmp = copy.deepcopy(initialized_model)\n",
    "        optimizer_tmp = Optimizer(model_tmp.parameters(), lr=lr)\n",
    "\n",
    "        train_losses, val_losses = fit(\n",
    "            model_tmp, train_loader, val_loader, optimizer_tmp, criterion, epochs\n",
    "        )\n",
    "\n",
    "        fold_train_losses.append(train_losses)\n",
    "        fold_val_losses.append(val_losses)\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} completed. Final train loss: {train_losses[-1]:.4f} | Final val loss: {val_losses[-1]:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- K-Fold CV completed ---\")\n",
    "    print(\n",
    "        f\"Average final train loss: {sum([l[-1] for l in fold_train_losses]) / k:.4f}\"\n",
    "    )\n",
    "    print(f\"Average final val loss: {sum([l[-1] for l in fold_val_losses]) / k:.4f}\")\n",
    "\n",
    "    if fit_final_model:\n",
    "        print(\"\\nFitting final model on entire dataset\")\n",
    "        optimizer_final = Optimizer(initialized_model.parameters(), lr=lr)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        fit(initialized_model, data_loader, data_loader, optimizer_final, criterion, epochs)\n",
    "\n",
    "    return fold_train_losses, fold_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740314588555,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "TouwAhcIhQoY"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "hyperparam_grid = {\n",
    "    # \"lr\": [0.01, 0.001, 0.0001],\n",
    "    \"lr\": [0.01],\n",
    "    # \"batch_size\": [16, 32, 64],\n",
    "    # \"n_hidden\": [32, 64, 128],\n",
    "    \"n_hidden\": [64],\n",
    "    # \"epochs\": [10, 20, 30],\n",
    "    \"epochs\": [30],\n",
    "}\n",
    "\n",
    "\n",
    "def nested_cv(\n",
    "    Model,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    hyperparam_grid,\n",
    "    dataset,\n",
    "    k_outer=5,\n",
    "    k_inner=5,\n",
    "):\n",
    "    # list of one dict per parameter combination\n",
    "    param_combinations = [\n",
    "        dict(zip(hyperparam_grid.keys(), values))\n",
    "        for values in product(*hyperparam_grid.values())\n",
    "    ]\n",
    "    n_combinations = len(param_combinations)\n",
    "\n",
    "    # risk estimate for each outer fold and each hyperparam combo\n",
    "    R_ests = np.zeros((k_outer, n_combinations))\n",
    "\n",
    "    if k_outer > 1:\n",
    "      outer_kf = KFold(n_splits=k_outer, shuffle=True, random_state=42)\n",
    "    else: # for compute reasons\n",
    "      class DummyKFold:\n",
    "        def split(self, X):\n",
    "            yield X, X\n",
    "      outer_kf = DummyKFold()\n",
    "    dataset_indices = np.arange(len(dataset))\n",
    "\n",
    "    for i, (outer_train_idx, outer_val_idx) in enumerate(\n",
    "        outer_kf.split(dataset_indices)\n",
    "    ):\n",
    "        print(f\"\\n--- Outer Fold {i+1}/{k_outer} ---\")\n",
    "\n",
    "        outer_train_dataset = Subset(dataset, outer_train_idx)\n",
    "        outer_val_dataset = Subset(dataset, outer_val_idx)\n",
    "\n",
    "        # per hyperparam combo, perform inner k_fold_cv\n",
    "        for j, params in enumerate(param_combinations):\n",
    "            model = Model(params[\"n_hidden\"]).to(device)\n",
    "\n",
    "            # Run k_fold_cv on the outer training dataset.\n",
    "            _, fold_val_losses = k_fold_cv(\n",
    "                initialized_model=model,\n",
    "                Optimizer=Optimizer,\n",
    "                criterion=criterion,\n",
    "                dataset=outer_train_dataset,\n",
    "                k=k_inner,\n",
    "                epochs=params[\"epochs\"],\n",
    "                # batch_size=params[\"batch_size\"],\n",
    "                batch_size=64, # hard-coded for compute reasons\n",
    "                lr=params[\"lr\"],\n",
    "            )\n",
    "            # average val risk over inner folds\n",
    "            final_losses = [losses[-1] for losses in fold_val_losses]\n",
    "            R_est = np.mean(final_losses)\n",
    "            R_ests[i, j] = R_est\n",
    "            print(\n",
    "                f\"Outer fold {i+1}, param set {j+1}/{n_combinations}: Risk = {R_est:.4f}\"\n",
    "            )\n",
    "\n",
    "    # average risk per hyperparam combination over outer folds\n",
    "    R_ests_params = np.mean(R_ests, axis=0)\n",
    "    best_idx = np.argmin(R_ests_params)\n",
    "    best_params = param_combinations[best_idx]\n",
    "\n",
    "    print(\n",
    "        f\"\\nSelected best hyperparameters (avg risk {R_ests_params[best_idx]:.4f}): {best_params}\"\n",
    "    )\n",
    "\n",
    "    # train final model on full dataset\n",
    "    model_final = Model(best_params[\"n_hidden\"]).to(device)\n",
    "    _, final_val_losses = k_fold_cv(\n",
    "        initialized_model=model_final,\n",
    "        Optimizer=Optimizer,\n",
    "        criterion=criterion,\n",
    "        dataset=dataset,\n",
    "        k=k_inner,\n",
    "        epochs=best_params[\"epochs\"],\n",
    "        # batch_size=params[\"batch_size\"],\n",
    "        batch_size=64, # hard-coded for compute reasons\n",
    "        lr=best_params[\"lr\"],\n",
    "        fit_final_model=True,\n",
    "    )\n",
    "    final_R_est = np.mean([losses[-1] for losses in final_val_losses])\n",
    "    print(f\"Final model empirical risk estimate on full dataset: {final_R_est:.4f}\")\n",
    "\n",
    "    return model_final, best_params, final_R_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUKhw2PrhQoY"
   },
   "source": [
    "---\n",
    "\n",
    "## Training & Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBl2khqehQoY"
   },
   "source": [
    "### Naive Baseline: Average Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUIVMVd6hQoY",
    "outputId": "60b1f76a-7e0e-4445-972b-0facfa1df702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per target: [1.1797696]\n"
     ]
    }
   ],
   "source": [
    "split_idx_baseline = int(0.8 * len(filtered_torch_data_list_train))\n",
    "\n",
    "y_train_baseline = [\n",
    "    d.y.numpy() for d in filtered_torch_data_list_train[:split_idx_baseline]\n",
    "]\n",
    "y_val_baseline = [\n",
    "    d.y.numpy() for d in filtered_torch_data_list_train[split_idx_baseline:]\n",
    "]\n",
    "\n",
    "naive_baseline = MeanBaseline()\n",
    "naive_baseline.fit(y_train_baseline)\n",
    "naive_baseline_predictions = naive_baseline.predict(len(y_val_baseline))\n",
    "\n",
    "# compute mse\n",
    "mse_per_target = np.nanmean((y_val_baseline - naive_baseline_predictions) ** 2, axis=0)\n",
    "print(f\"MSE per target: {mse_per_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvgld7xIhQoY"
   },
   "source": [
    "### Baseline: Random Forest with 2D Descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nmBUWPuhQoY",
    "outputId": "4590e7aa-8cdf-4bf5-dbb6-fbfdf34528a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/My Drive/Repositories/serotonin-3d-gnn/.venv/lib/python3.13/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val MSE: 1.1166799623190877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# tried a bunch of descriptor functions from Descriptors._descList – these are the ones that did NOT crash the kernel ...\n",
    "safe_descriptors = [\n",
    "    \"MolWt\",\n",
    "    \"MolLogP\",\n",
    "    \"MolMR\",\n",
    "    \"NumValenceElectrons\",\n",
    "    \"NumRadicalElectrons\",\n",
    "    \"HeavyAtomCount\",\n",
    "    \"NHOHCount\",\n",
    "    \"NOCount\",\n",
    "    \"RingCount\",\n",
    "    \"FractionCSP3\",\n",
    "    \"TPSA\",\n",
    "    \"NumHDonors\",\n",
    "    \"NumHAcceptors\",\n",
    "    \"NumRotatableBonds\",\n",
    "    \"HallKierAlpha\",\n",
    "    \"Kappa1\",\n",
    "    \"Kappa2\",\n",
    "    \"Kappa3\",\n",
    "    \"Chi0\",\n",
    "    \"Chi1\",\n",
    "    \"fr_Al_COO\",\n",
    "    \"fr_Al_OH\",\n",
    "    \"fr_Ar_N\",\n",
    "    \"fr_C_O\",\n",
    "    \"fr_NH1\",\n",
    "    \"fr_NH2\",\n",
    "]\n",
    "\n",
    "descriptor_functions = {name: getattr(Descriptors, name) for name in safe_descriptors}\n",
    "\n",
    "\n",
    "# extract a fixed-length feature vector from the graph data, as input to RF model\n",
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    desc_values = []\n",
    "    for _, func in descriptor_functions.items():\n",
    "        try:\n",
    "            desc_values.append(func(mol))\n",
    "        except:\n",
    "            print(f\"Error computing descriptor {func}\")\n",
    "    return np.array(desc_values)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for data in filtered_torch_data_list_train:\n",
    "    features = compute_descriptors(data.smiles)\n",
    "    if features is None:\n",
    "        continue\n",
    "    X.append(features)\n",
    "    target_val = data.y.cpu().numpy() if data.y.numel() > 0 else np.nan\n",
    "    y.append(target_val)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "split_idx_rf = int(0.8 * len(filtered_torch_data_list_train))\n",
    "X_train, X_val = X[:split_idx_rf], X[split_idx_rf:]\n",
    "y_train, y_val = y[:split_idx_rf], y[split_idx_rf:]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(\"Val MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyInMxaihQoZ"
   },
   "source": [
    "### Approach 1: SeroGCN without Pretraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOo8Rdh9hQoZ"
   },
   "outputs": [],
   "source": [
    "sero_gcn_final, best_params_sero_gcn, final_R_est_sero_gcn = nested_cv(\n",
    "    SeroGCN,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    filtered_torch_data_list_train,\n",
    "    k_outer=1, # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(sero_gcn_final.state_dict(), PATH_WEIGHTS / \"sero_gcn_final_weights.pth\")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_sero_gcn\": best_params_sero_gcn,\n",
    "            \"final_R_est_sero_gcn\": final_R_est_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqGa2vpxhQoZ"
   },
   "source": [
    "### Approach 2: SeroGCN with Pretraining on ZINC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqooqV7zhQoZ"
   },
   "source": [
    "#### Pretraining: Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 573416,
     "status": "ok",
     "timestamp": 1740315168031,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "fepVtdrzhQoZ",
    "outputId": "5ad19d8e-2388-4d1a-d3fb-5d2930ae74a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outer Fold 1/1 ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0582 | Val Loss = 0.0175. Time taken: 2.55s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0188 | Val Loss = 0.0166. Time taken: 1.89s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0184 | Val Loss = 0.0182. Time taken: 1.42s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0187 | Val Loss = 0.0165. Time taken: 1.49s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0177 | Val Loss = 0.0165. Time taken: 1.44s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0182 | Val Loss = 0.0173. Time taken: 1.49s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0183 | Val Loss = 0.0163. Time taken: 1.49s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0181 | Val Loss = 0.0168. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0178 | Val Loss = 0.0164. Time taken: 1.58s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0180 | Val Loss = 0.0173. Time taken: 1.86s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0176 | Val Loss = 0.0161. Time taken: 1.73s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0174 | Val Loss = 0.0160. Time taken: 1.44s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0167. Time taken: 1.49s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0184 | Val Loss = 0.0163. Time taken: 1.47s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0159. Time taken: 1.53s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0179 | Val Loss = 0.0158. Time taken: 1.42s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0176 | Val Loss = 0.0158. Time taken: 1.50s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0171 | Val Loss = 0.0165. Time taken: 1.83s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0167 | Val Loss = 0.0158. Time taken: 1.91s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0165 | Val Loss = 0.0173. Time taken: 1.47s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0164 | Val Loss = 0.0155. Time taken: 1.46s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0165 | Val Loss = 0.0153. Time taken: 1.46s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0167 | Val Loss = 0.0163. Time taken: 1.43s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0159 | Val Loss = 0.0170. Time taken: 1.46s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0160 | Val Loss = 0.0153. Time taken: 1.44s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.61s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0163 | Val Loss = 0.0159. Time taken: 1.89s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0160 | Val Loss = 0.0152. Time taken: 1.77s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0159 | Val Loss = 0.0155. Time taken: 1.47s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0159 | Val Loss = 0.0161. Time taken: 1.45s\n",
      "Fold 1 completed. Final train loss: 0.0159 | Final val loss: 0.0161\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0548 | Val Loss = 0.0195. Time taken: 1.46s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0177 | Val Loss = 0.0185. Time taken: 1.51s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0177 | Val Loss = 0.0192. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0176 | Val Loss = 0.0185. Time taken: 1.45s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0179 | Val Loss = 0.0182. Time taken: 1.90s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0181 | Val Loss = 0.0252. Time taken: 1.87s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0178 | Val Loss = 0.0182. Time taken: 1.47s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0175 | Val Loss = 0.0197. Time taken: 1.45s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0178 | Val Loss = 0.0193. Time taken: 1.50s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0181. Time taken: 1.48s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0179. Time taken: 1.46s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0177 | Val Loss = 0.0180. Time taken: 1.46s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0182. Time taken: 1.63s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0170 | Val Loss = 0.0178. Time taken: 1.93s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0171 | Val Loss = 0.0181. Time taken: 1.74s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0169 | Val Loss = 0.0176. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0170 | Val Loss = 0.0179. Time taken: 1.46s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0177 | Val Loss = 0.0201. Time taken: 1.52s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 1.46s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 1.49s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0163 | Val Loss = 0.0171. Time taken: 1.44s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0162 | Val Loss = 0.0167. Time taken: 1.86s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0162 | Val Loss = 0.0175. Time taken: 1.97s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0164 | Val Loss = 0.0166. Time taken: 1.48s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0158 | Val Loss = 0.0175. Time taken: 1.56s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0157 | Val Loss = 0.0165. Time taken: 1.48s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0157 | Val Loss = 0.0165. Time taken: 1.49s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0157 | Val Loss = 0.0163. Time taken: 2.09s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0155 | Val Loss = 0.0161. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0168. Time taken: 1.89s\n",
      "Fold 2 completed. Final train loss: 0.0157 | Final val loss: 0.0168\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0572 | Val Loss = 0.0190. Time taken: 1.91s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0182 | Val Loss = 0.0179. Time taken: 1.50s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0180. Time taken: 1.56s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0179 | Val Loss = 0.0183. Time taken: 1.50s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0176 | Val Loss = 0.0181. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0182 | Val Loss = 0.0182. Time taken: 1.51s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0184 | Val Loss = 0.0186. Time taken: 1.51s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0188 | Val Loss = 0.0227. Time taken: 1.70s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0180 | Val Loss = 0.0173. Time taken: 1.88s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0175 | Val Loss = 0.0191. Time taken: 1.67s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0175 | Val Loss = 0.0170. Time taken: 1.49s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0177 | Val Loss = 0.0242. Time taken: 1.54s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0180 | Val Loss = 0.0174. Time taken: 1.47s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0175. Time taken: 1.51s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0178 | Val Loss = 0.0173. Time taken: 1.48s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0175 | Val Loss = 0.0181. Time taken: 1.50s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0179 | Val Loss = 0.0173. Time taken: 1.93s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0173 | Val Loss = 0.0187. Time taken: 1.87s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0173 | Val Loss = 0.0178. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0169 | Val Loss = 0.0170. Time taken: 1.56s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0170 | Val Loss = 0.0172. Time taken: 1.47s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0174 | Val Loss = 0.0172. Time taken: 1.52s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0171 | Val Loss = 0.0166. Time taken: 1.49s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0167 | Val Loss = 0.0172. Time taken: 3.06s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0162 | Val Loss = 0.0160. Time taken: 1.86s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0166 | Val Loss = 0.0163. Time taken: 1.72s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0160 | Val Loss = 0.0159. Time taken: 1.49s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0157 | Val Loss = 0.0155. Time taken: 1.57s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0156 | Val Loss = 0.0153. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0160. Time taken: 1.51s\n",
      "Fold 3 completed. Final train loss: 0.0157 | Final val loss: 0.0160\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0550 | Val Loss = 0.0171. Time taken: 1.52s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0186 | Val Loss = 0.0178. Time taken: 1.53s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0195 | Val Loss = 0.0169. Time taken: 1.95s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.87s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0186 | Val Loss = 0.0192. Time taken: 1.57s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0185 | Val Loss = 0.0162. Time taken: 1.53s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0186 | Val Loss = 0.0162. Time taken: 1.48s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0186 | Val Loss = 0.0161. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0179 | Val Loss = 0.0186. Time taken: 1.45s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0185 | Val Loss = 0.0160. Time taken: 1.52s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0182 | Val Loss = 0.0183. Time taken: 1.81s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0179 | Val Loss = 0.0159. Time taken: 1.91s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0176 | Val Loss = 0.0162. Time taken: 1.67s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0177 | Val Loss = 0.0170. Time taken: 1.54s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0160. Time taken: 1.48s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0174 | Val Loss = 0.0157. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0173 | Val Loss = 0.0156. Time taken: 1.57s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0171 | Val Loss = 0.0154. Time taken: 1.53s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0175 | Val Loss = 0.0165. Time taken: 1.67s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0170 | Val Loss = 0.0156. Time taken: 1.98s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0171 | Val Loss = 0.0155. Time taken: 1.77s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0169 | Val Loss = 0.0148. Time taken: 1.59s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0167 | Val Loss = 0.0146. Time taken: 1.45s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0164 | Val Loss = 0.0147. Time taken: 1.55s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0163 | Val Loss = 0.0145. Time taken: 1.47s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0166 | Val Loss = 0.0146. Time taken: 1.56s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0162 | Val Loss = 0.0147. Time taken: 1.56s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0161 | Val Loss = 0.0144. Time taken: 1.89s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0159 | Val Loss = 0.0151. Time taken: 1.96s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0161 | Val Loss = 0.0142. Time taken: 1.56s\n",
      "Fold 4 completed. Final train loss: 0.0161 | Final val loss: 0.0142\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0627 | Val Loss = 0.0188. Time taken: 1.55s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0183 | Val Loss = 0.0186. Time taken: 1.56s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0184. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0188. Time taken: 1.55s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0183 | Val Loss = 0.0186. Time taken: 1.49s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0183 | Val Loss = 0.0209. Time taken: 1.82s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0178 | Val Loss = 0.0182. Time taken: 1.97s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0174 | Val Loss = 0.0185. Time taken: 1.69s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0181. Time taken: 1.46s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0181 | Val Loss = 0.0224. Time taken: 1.51s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0179 | Val Loss = 0.0193. Time taken: 1.46s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0174 | Val Loss = 0.0181. Time taken: 1.57s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0176 | Val Loss = 0.0198. Time taken: 1.45s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0188. Time taken: 1.53s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0169 | Val Loss = 0.0177. Time taken: 2.03s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0175 | Val Loss = 0.0178. Time taken: 1.85s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0167 | Val Loss = 0.0177. Time taken: 1.52s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0173 | Val Loss = 0.0179. Time taken: 1.52s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0166 | Val Loss = 0.0179. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0166 | Val Loss = 0.0173. Time taken: 1.51s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0163 | Val Loss = 0.0179. Time taken: 1.53s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0166 | Val Loss = 0.0173. Time taken: 1.51s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0164 | Val Loss = 0.0168. Time taken: 1.86s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0169 | Val Loss = 0.0172. Time taken: 1.82s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0161 | Val Loss = 0.0168. Time taken: 1.66s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0159 | Val Loss = 0.0166. Time taken: 1.54s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0158 | Val Loss = 0.0163. Time taken: 1.53s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0158 | Val Loss = 0.0164. Time taken: 1.56s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0157 | Val Loss = 0.0191. Time taken: 1.53s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0172. Time taken: 1.51s\n",
      "Fold 5 completed. Final train loss: 0.0157 | Final val loss: 0.0172\n",
      "\n",
      "--- K-Fold CV completed ---\n",
      "Average final train loss: 0.0158\n",
      "Average final val loss: 0.0161\n",
      "Outer fold 1, param set 1/1: Risk = 0.0161\n",
      "\n",
      "Selected best hyperparameters (avg risk 0.0161): {'lr': 0.01, 'n_hidden': 64, 'epochs': 30}\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0452 | Val Loss = 0.0168. Time taken: 1.68s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0187 | Val Loss = 0.0177. Time taken: 1.85s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0182 | Val Loss = 0.0171. Time taken: 1.88s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0183 | Val Loss = 0.0169. Time taken: 1.50s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0182 | Val Loss = 0.0175. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0189 | Val Loss = 0.0211. Time taken: 1.56s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0172 | Val Loss = 0.0160. Time taken: 1.58s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0170 | Val Loss = 0.0216. Time taken: 1.53s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0175 | Val Loss = 0.0161. Time taken: 1.54s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0171. Time taken: 2.02s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0170 | Val Loss = 0.0169. Time taken: 1.89s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0163 | Val Loss = 0.0157. Time taken: 1.55s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0161 | Val Loss = 0.0154. Time taken: 1.55s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.52s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.59s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0162 | Val Loss = 0.0163. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0158 | Val Loss = 0.0160. Time taken: 1.52s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0156 | Val Loss = 0.0151. Time taken: 1.84s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0155 | Val Loss = 0.0152. Time taken: 1.83s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0159 | Val Loss = 0.0155. Time taken: 1.76s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0156 | Val Loss = 0.0158. Time taken: 1.54s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0156 | Val Loss = 0.0150. Time taken: 1.50s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0153 | Val Loss = 0.0151. Time taken: 1.50s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0153 | Val Loss = 0.0153. Time taken: 1.53s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0157. Time taken: 1.56s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0155 | Val Loss = 0.0147. Time taken: 1.48s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0149 | Val Loss = 0.0149. Time taken: 2.01s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0148. Time taken: 1.92s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0151 | Val Loss = 0.0156. Time taken: 1.59s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0150 | Val Loss = 0.0147. Time taken: 1.51s\n",
      "Fold 1 completed. Final train loss: 0.0150 | Final val loss: 0.0147\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0443 | Val Loss = 0.0190. Time taken: 1.64s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0181 | Val Loss = 0.0206. Time taken: 1.50s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0177 | Val Loss = 0.0194. Time taken: 1.54s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0175 | Val Loss = 0.0183. Time taken: 1.61s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0185 | Val Loss = 0.0182. Time taken: 1.77s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0174 | Val Loss = 0.0190. Time taken: 1.96s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0180. Time taken: 1.74s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0184 | Val Loss = 0.0192. Time taken: 1.51s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0174 | Val Loss = 0.0191. Time taken: 1.54s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0235. Time taken: 1.55s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0171 | Val Loss = 0.0176. Time taken: 1.53s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0169 | Val Loss = 0.0177. Time taken: 1.53s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0175 | Val Loss = 0.0178. Time taken: 1.72s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0166 | Val Loss = 0.0171. Time taken: 1.96s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0170. Time taken: 1.88s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0160 | Val Loss = 0.0167. Time taken: 1.60s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0160 | Val Loss = 0.0168. Time taken: 1.49s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0157 | Val Loss = 0.0163. Time taken: 1.49s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0157 | Val Loss = 0.0174. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0155 | Val Loss = 0.0176. Time taken: 1.58s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0154 | Val Loss = 0.0158. Time taken: 1.45s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0156 | Val Loss = 0.0162. Time taken: 1.92s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0152 | Val Loss = 0.0158. Time taken: 1.88s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0156 | Val Loss = 0.0160. Time taken: 1.59s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0158. Time taken: 1.52s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0152 | Val Loss = 0.0164. Time taken: 1.51s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0151 | Val Loss = 0.0162. Time taken: 1.51s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0155. Time taken: 1.56s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0149 | Val Loss = 0.0167. Time taken: 1.45s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0151 | Val Loss = 0.0161. Time taken: 1.64s\n",
      "Fold 2 completed. Final train loss: 0.0151 | Final val loss: 0.0161\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0458 | Val Loss = 0.0192. Time taken: 1.99s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0182 | Val Loss = 0.0187. Time taken: 1.80s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0179 | Val Loss = 0.0176. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0174. Time taken: 1.56s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0179 | Val Loss = 0.0175. Time taken: 1.49s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0179 | Val Loss = 0.0172. Time taken: 1.50s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0171. Time taken: 1.52s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0176 | Val Loss = 0.0170. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0176. Time taken: 1.90s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0173 | Val Loss = 0.0184. Time taken: 1.88s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0175. Time taken: 1.64s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0173 | Val Loss = 0.0170. Time taken: 1.48s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0171 | Val Loss = 0.0167. Time taken: 1.53s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0169 | Val Loss = 0.0167. Time taken: 1.49s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0165 | Val Loss = 0.0164. Time taken: 1.46s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0171 | Val Loss = 0.0162. Time taken: 1.55s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0165 | Val Loss = 0.0158. Time taken: 1.54s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0161 | Val Loss = 0.0162. Time taken: 1.96s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0161 | Val Loss = 0.0171. Time taken: 1.91s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0160 | Val Loss = 0.0164. Time taken: 1.50s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0155 | Val Loss = 0.0152. Time taken: 1.54s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0155 | Val Loss = 0.0153. Time taken: 1.50s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0156 | Val Loss = 0.0153. Time taken: 1.51s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0152 | Val Loss = 0.0163. Time taken: 1.54s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0154 | Val Loss = 0.0152. Time taken: 1.50s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0157 | Val Loss = 0.0151. Time taken: 1.78s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0152 | Val Loss = 0.0149. Time taken: 1.91s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0154 | Val Loss = 0.0150. Time taken: 1.75s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0153 | Val Loss = 0.0159. Time taken: 1.54s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0151 | Val Loss = 0.0152. Time taken: 1.51s\n",
      "Fold 3 completed. Final train loss: 0.0151 | Final val loss: 0.0152\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0467 | Val Loss = 0.0169. Time taken: 1.51s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0185 | Val Loss = 0.0164. Time taken: 1.54s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.47s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0182 | Val Loss = 0.0163. Time taken: 1.57s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.92s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0189 | Val Loss = 0.0161. Time taken: 1.75s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0179 | Val Loss = 0.0177. Time taken: 1.67s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0178 | Val Loss = 0.0158. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0161. Time taken: 1.55s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0180 | Val Loss = 0.0161. Time taken: 1.51s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0161. Time taken: 1.48s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0170 | Val Loss = 0.0156. Time taken: 1.57s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0179 | Val Loss = 0.0155. Time taken: 1.61s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0152. Time taken: 1.90s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0172 | Val Loss = 0.0167. Time taken: 1.90s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0170 | Val Loss = 0.0151. Time taken: 1.59s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0169 | Val Loss = 0.0157. Time taken: 1.48s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0167 | Val Loss = 0.0147. Time taken: 1.56s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0165 | Val Loss = 0.0177. Time taken: 1.51s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0167 | Val Loss = 0.0149. Time taken: 1.50s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0165 | Val Loss = 0.0144. Time taken: 1.50s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0161 | Val Loss = 0.0143. Time taken: 1.75s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0159 | Val Loss = 0.0142. Time taken: 1.92s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0158 | Val Loss = 0.0141. Time taken: 1.85s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0157 | Val Loss = 0.0141. Time taken: 1.49s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0156 | Val Loss = 0.0141. Time taken: 1.64s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0157 | Val Loss = 0.0153. Time taken: 1.54s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0156 | Val Loss = 0.0142. Time taken: 1.58s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0156 | Val Loss = 0.0141. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0154 | Val Loss = 0.0139. Time taken: 1.58s\n",
      "Fold 4 completed. Final train loss: 0.0154 | Final val loss: 0.0139\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0477 | Val Loss = 0.0187. Time taken: 1.85s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0181 | Val Loss = 0.0195. Time taken: 1.80s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0176 | Val Loss = 0.0188. Time taken: 1.59s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0189. Time taken: 1.60s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0181 | Val Loss = 0.0191. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0175 | Val Loss = 0.0186. Time taken: 1.57s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0193. Time taken: 1.57s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0177 | Val Loss = 0.0179. Time taken: 1.58s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0173 | Val Loss = 0.0178. Time taken: 1.70s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0170 | Val Loss = 0.0181. Time taken: 1.92s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0166 | Val Loss = 0.0186. Time taken: 1.87s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0170 | Val Loss = 0.0187. Time taken: 1.51s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0171 | Val Loss = 0.0193. Time taken: 1.57s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0167 | Val Loss = 0.0176. Time taken: 1.49s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0165 | Val Loss = 0.0179. Time taken: 1.57s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0170 | Val Loss = 0.0180. Time taken: 1.47s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0161 | Val Loss = 0.0181. Time taken: 1.55s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0164 | Val Loss = 0.0168. Time taken: 1.70s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0159 | Val Loss = 0.0179. Time taken: 1.89s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0161 | Val Loss = 0.0178. Time taken: 1.81s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0159 | Val Loss = 0.0166. Time taken: 1.56s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0154 | Val Loss = 0.0168. Time taken: 1.46s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0153 | Val Loss = 0.0174. Time taken: 1.63s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0155 | Val Loss = 0.0165. Time taken: 1.52s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0160. Time taken: 1.62s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0151 | Val Loss = 0.0164. Time taken: 1.53s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0150 | Val Loss = 0.0158. Time taken: 2.10s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0158. Time taken: 1.94s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0150 | Val Loss = 0.0161. Time taken: 1.58s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0152 | Val Loss = 0.0160. Time taken: 1.56s\n",
      "Fold 5 completed. Final train loss: 0.0152 | Final val loss: 0.0160\n",
      "\n",
      "--- K-Fold CV completed ---\n",
      "Average final train loss: 0.0151\n",
      "Average final val loss: 0.0152\n",
      "\n",
      "Fitting final model on entire dataset\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0412 | Val Loss = 0.0177. Time taken: 2.64s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0179 | Val Loss = 0.0181. Time taken: 2.68s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0192. Time taken: 3.18s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0179 | Val Loss = 0.0188. Time taken: 3.11s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0178 | Val Loss = 0.0204. Time taken: 2.68s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0174 | Val Loss = 0.0178. Time taken: 2.64s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0173 | Val Loss = 0.0167. Time taken: 2.76s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 3.28s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0173 | Val Loss = 0.0169. Time taken: 2.91s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0175 | Val Loss = 0.0179. Time taken: 2.72s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0172 | Val Loss = 0.0172. Time taken: 2.72s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0172 | Val Loss = 0.0165. Time taken: 2.67s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0161. Time taken: 3.35s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0164 | Val Loss = 0.0164. Time taken: 2.88s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0162 | Val Loss = 0.0196. Time taken: 2.71s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0161 | Val Loss = 0.0155. Time taken: 2.67s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0157 | Val Loss = 0.0154. Time taken: 2.92s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0158 | Val Loss = 0.0150. Time taken: 3.39s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0156 | Val Loss = 0.0151. Time taken: 2.68s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0153 | Val Loss = 0.0149. Time taken: 2.71s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0153 | Val Loss = 0.0161. Time taken: 2.72s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0153 | Val Loss = 0.0153. Time taken: 3.14s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0152 | Val Loss = 0.0148. Time taken: 3.12s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0152 | Val Loss = 0.0151. Time taken: 2.76s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0149. Time taken: 2.77s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0150 | Val Loss = 0.0149. Time taken: 2.66s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0150 | Val Loss = 0.0147. Time taken: 3.26s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0149 | Val Loss = 0.0150. Time taken: 2.97s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0148 | Val Loss = 0.0145. Time taken: 2.66s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0149 | Val Loss = 0.0143. Time taken: 2.74s\n",
      "Final model empirical risk estimate on full dataset: 0.0152\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    pretrained_sero_gcn,\n",
    "    best_params_pretrained_sero_gcn,\n",
    "    final_R_est_pretrained_sero_gcn,\n",
    ") = nested_cv(\n",
    "    SeroGCN,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    filtered_pretraining_torch_data_list_10k,\n",
    "    k_outer=1, # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_R_est_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV86lS77hQoZ"
   },
   "source": [
    "#### (Pretraining: Full ZINC with Locked Hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBTj2oQfhQoZ"
   },
   "source": [
    "#### Fine-tuning on Serotonine Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1740315773552,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "_3qGyoEMU09K",
    "outputId": "1039f17b-8a96-4c74-88e6-58209f77d4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeroGCN does not exist – train it first\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\"\n",
    "\n",
    "if os.path.exists(pickle_file_path) and not pretrained_sero_gcn:\n",
    "  print(\"Loading pretrained SeroGCN from weights file\")\n",
    "  pretrained_sero_gcn = torch.load(pickle_file_path, map_location=device)\n",
    "  print(\"Loaded pretrained SeroGCN from weights file\")\n",
    "else:\n",
    "  print(\"SeroGCN does not exist – train it first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX_8Qr17hQoZ"
   },
   "outputs": [],
   "source": [
    "_, final_val_losses_pretrained_sero_gcn = k_fold_cv(\n",
    "    initialized_model=pretrained_sero_gcn,\n",
    "    Optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss(),\n",
    "    dataset=filtered_torch_data_list_train,\n",
    "    k=5,\n",
    "    epochs=best_params_pretrained_sero_gcn[\"epochs\"],\n",
    "    batch_size=best_params_pretrained_sero_gcn[\"batch_size\"],\n",
    "    lr=best_params_pretrained_sero_gcn[\"lr\"],\n",
    "    fit_final_model=True,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_final_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero_final.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_val_losses_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxB4ngu_hQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Test Set Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvTRLNdrhQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
