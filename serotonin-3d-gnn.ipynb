{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jiKdt3EYQ6d"
   },
   "source": [
    "# Serotonin 3D GNN Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gswc-LH5YWga"
   },
   "source": [
    "This project builds upon research done by Łapińska et al. (2024): https://doi.org/10.3390/pharmaceutics16030349\n",
    "\n",
    "Data used: https://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_35/\n",
    "\n",
    "Move the unpacked chembl_35_sqlite.tar.gz file into the data/ dir.\n",
    "\n",
    "The research linked above presents two Quantitative Structure-Activity Relationship (QSAR) models to predict serotonergic binding affinity and selectivity, respectively, using Mordred molecular 2D descriptors. Specifically, one model classifies compounds binarily as \"active\" or \"inactive\", with a cutoff of pKi = 7. Another model does multiclass classification to predict the serotonergic selectivity of compounds previously classified as \"active\".\n",
    "\n",
    "I am following a similar approach, but using 3D molecular graph representations instead of 2D molecular descriptors as input modality and using only the ChEMBL database, not ZINC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGK0LMuRYC6g"
   },
   "source": [
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugvkdqJgYMum"
   },
   "source": [
    "### Configuration & Google Drive/Colab Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26308,
     "status": "ok",
     "timestamp": 1740843537391,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "q2XchrWsWuIk",
    "outputId": "b9401ce7-35c4-453a-bfe0-9660263add1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"{'Running in Colab' if IN_COLAB else 'Running locally'}\")\n",
    "\n",
    "PATH_NOTEBOOK = (\n",
    "    Path(\"/content/drive/MyDrive/Colab Notebooks/serotonin-3d-gnn.ipynb\")\n",
    "    if IN_COLAB\n",
    "    else Path(\n",
    "        \"/Users/paul/Library/CloudStorage/GoogleDrive-unoutsch@gmail.com/My Drive/Colab Notebooks/serotonin-3d-gnn.ipynb\"\n",
    "    )\n",
    ")\n",
    "PATH_REPO = (\n",
    "    Path(\"/content/drive/MyDrive/Repositories/serotonin-3d-gnn\")\n",
    "    if IN_COLAB\n",
    "    else Path.cwd()\n",
    ")\n",
    "PATH_DATA = PATH_REPO / \"data_fixed\"\n",
    "PATH_WEIGHTS = PATH_REPO / \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko5Es7NyYw7W"
   },
   "source": [
    "### Installing Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93450,
     "status": "ok",
     "timestamp": 1740843631183,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "sPtfbBFEYwKR",
    "outputId": "c172c072-cca4-413c-97df-26eb14398f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: rdkit in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 4)) (2024.9.5)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: torch-geometric in ./.venv/lib/python3.13/site-packages (from -r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 3)) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.13/site-packages (from torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.11.12)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./.venv/lib/python3.13/site-packages (from torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (7.0.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->torch-geometric->-r /Users/paul/My Drive/Repositories/serotonin-3d-gnn/requirements.txt (line 8)) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --requirement \"$PATH_REPO/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpNxNxd3UG04"
   },
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25567,
     "status": "ok",
     "timestamp": 1740843656763,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "6qaxG6KzSQbs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdchem, Descriptors, rdMolDescriptors, rdMolTransforms\n",
    "import shutil\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyOFFWimQtGD"
   },
   "source": [
    "### Syncing this file between Colab and local Git repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7qVn7CnR7FK"
   },
   "source": [
    "Make sure the paths exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1740830095025,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "-AEKpQQaQ5U4",
    "outputId": "11b7fa39-b306-42ea-ddde-d4e55844bc95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied notebook to Google Drive.\n"
     ]
    }
   ],
   "source": [
    "def copy_notebook():\n",
    "    if IN_COLAB:\n",
    "        shutil.copyfile(PATH_NOTEBOOK, PATH_REPO / \"serotonin-3d-gnn.ipynb\")\n",
    "        print(\"Copied notebook to repo.\")\n",
    "    else:\n",
    "        shutil.copyfile(PATH_REPO / \"serotonin-3d-gnn.ipynb\", PATH_NOTEBOOK)\n",
    "        print(\"Copied notebook to Google Drive.\")\n",
    "\n",
    "\n",
    "copy_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxQZohBJhQoT"
   },
   "source": [
    "### Setting Torch Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1740843656797,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "YXkqUkBKhQoT",
    "outputId": "e65451db-cb27-4d56-a09d-3138c8bee6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7iFshPsYhff"
   },
   "source": [
    "---\n",
    "\n",
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEEdENl6NzpP"
   },
   "source": [
    "### Loading and Preprocessing Serotonin Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-wRU6qqhQoU"
   },
   "source": [
    "If the pickled torch_data_list already exists, load it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 25879,
     "status": "ok",
     "timestamp": 1740843682677,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "1yBrNIjphQoU",
    "outputId": "d71c3c40-b4ea-4197-a1ec-d978533651e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_6_2799.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1d_481.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_4_338.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_7_2317.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1b_466.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2b_833.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_1a_3086.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2a_2353.csv', '/Users/paul/My Drive/Repositories/serotonin-3d-gnn/data_fixed/targets/serotonin_2c_1385.csv']\n",
      "{'Serotonin 1a (5-HT1a) receptor': 0, 'Serotonin 1b (5-HT1b) receptor': 1, 'Serotonin 1d (5-HT1d) receptor': 2, 'Serotonin 2a (5-HT2a) receptor': 3, 'Serotonin 2b (5-HT2b) receptor': 4, 'Serotonin 2c (5-HT2c) receptor': 5, 'Serotonin 4 (5-HT4) receptor': 6, 'Serotonin 6 (5-HT6) receptor': 7, 'Serotonin 7 (5-HT7) receptor': 8}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pchembl_value</th>\n",
       "      <th>target_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14058.000000</td>\n",
       "      <td>14058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.319273</td>\n",
       "      <td>4.189856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.167407</td>\n",
       "      <td>2.950111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.470000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.150000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.850000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pchembl_value     target_id\n",
       "count   14058.000000  14058.000000\n",
       "mean        7.319273      4.189856\n",
       "std         1.167407      2.950111\n",
       "min         4.000000      0.000000\n",
       "25%         6.470000      1.000000\n",
       "50%         7.300000      4.000000\n",
       "75%         8.150000      7.000000\n",
       "max        10.850000      8.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob(os.path.join(PATH_DATA / \"targets\" / \"*.csv\"))\n",
    "print(csv_files)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(\n",
    "        file, delimiter=\";\", usecols=[\"Smiles\", \"pChEMBL Value\", \"Target Name\"]\n",
    "    )\n",
    "    df.columns = [\"smiles\", \"pchembl_value\", \"target_name\"]\n",
    "    data_list.append(df)\n",
    "\n",
    "merged_df = pd.concat(data_list, ignore_index=True)\n",
    "merged_df[\"target_name\"] = merged_df[\"target_name\"].astype(\"category\")\n",
    "merged_df[\"target_id\"] = merged_df[\"target_name\"].cat.codes\n",
    "\n",
    "target_name_to_id = dict(zip(merged_df[\"target_name\"].cat.categories, range(len(merged_df[\"target_name\"].cat.categories))))\n",
    "target_id_to_name = {v: k for k, v in target_name_to_id.items()}\n",
    "print(target_name_to_id)\n",
    "\n",
    "merged_df.to_csv(os.path.join(PATH_DATA, \"merged_serotonin_data.csv\"), index=False)\n",
    "\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = os.path.join(PATH_DATA, \"merged_serotonin_data_processed.pkl\")\n",
    "\n",
    "if os.path.exists(pickle_file_path):\n",
    "    print(\"Loading processed data...\")\n",
    "    with open(pickle_file_path, \"rb\") as f:\n",
    "        merged_serotonin_data_processed = pickle.load(f)\n",
    "else:\n",
    "    merged_serotonin_data_processed = None\n",
    "    print(\"Will create new processed data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQlehqYVhQoU"
   },
   "source": [
    "### Creating 3D Molecular Graph Data from Serotonin Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1740843684888,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "63VicadqVXW3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_serotonin_data_processed[0] Data(x=[65, 10], edge_index=[2, 136], edge_attr=[136, 5], y=6.619999885559082, pos=[65, 3], target_id=7, smiles='Cl.O=S1(=O)c2cccc3cccc(c23)N1CCCCCCN1CCN(c2cccc(Cl)c2Cl)CC1', mol_features=[1, 8])\n"
     ]
    }
   ],
   "source": [
    "periodic_table = rdchem.GetPeriodicTable()\n",
    "\n",
    "ATOM_PROPERTIES = {\n",
    "    atomic_num: [\n",
    "        periodic_table.GetAtomicWeight(atomic_num),\n",
    "        periodic_table.GetRvdw(atomic_num),\n",
    "        periodic_table.GetDefaultValence(atomic_num),\n",
    "    ]\n",
    "    for atomic_num in range(1, 119)  # all elements in periodic table\n",
    "}\n",
    "\n",
    "BOND_TYPES = [\n",
    "    Chem.rdchem.BondType.SINGLE,\n",
    "    Chem.rdchem.BondType.AROMATIC,\n",
    "    Chem.rdchem.BondType.DOUBLE,\n",
    "    Chem.rdchem.BondType.TRIPLE,\n",
    "]\n",
    "\n",
    "\n",
    "def create_torch_data(smiles: str, target_value: torch.Tensor, target_id) -> Data:\n",
    "    # getting RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # add explicit hydrogen atoms to the molecule (are not included in the SMILES string) so that its 3D structure is complete\n",
    "    mol = Chem.AddHs(mol)\n",
    "    Chem.SanitizeMol(mol)\n",
    "\n",
    "    # EmbedMolecule positions atoms of mol in 3D space stochastically; if it fails (returning -1) return None\n",
    "    if AllChem.EmbedMolecule(mol, randomSeed=42) == -1:\n",
    "        return None\n",
    "\n",
    "    # optimize the 3D structure using Universal Force Field (UFF) to lower mol's energy\n",
    "    status = AllChem.UFFOptimizeMolecule(mol)\n",
    "    if status == -1:\n",
    "        print(f\"UFF optimization failed for molecule: {smiles}\")\n",
    "        return None\n",
    "    AllChem.UFFOptimizeMolecule(mol)\n",
    "\n",
    "    # conformer contains 3D coordinates for mol's atoms\n",
    "    conformer = mol.GetConformer()\n",
    "\n",
    "    # molecule-level features\n",
    "    mol_features = [\n",
    "        Descriptors.ExactMolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        rdMolDescriptors.CalcNumAromaticRings(mol),\n",
    "        rdMolDescriptors.CalcNumBridgeheadAtoms(mol),\n",
    "        rdMolDescriptors.CalcNumRotatableBonds(mol),\n",
    "        rdMolDescriptors.CalcNumHBD(mol),\n",
    "        rdMolDescriptors.CalcNumHBA(mol),\n",
    "    ]\n",
    "\n",
    "    # atom-level features and 3D positions\n",
    "    atom_features, positions = [], []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        atomic_mass, vdw_radius, valence = ATOM_PROPERTIES.get(\n",
    "            atomic_num, [0.0, 0.0, 0]\n",
    "        )\n",
    "\n",
    "        features = [\n",
    "            atomic_mass,\n",
    "            vdw_radius,\n",
    "            valence,\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetDegree(),\n",
    "            int(atom.IsInRing()),\n",
    "        ] + [\n",
    "            1.0 if atom.GetHybridization() == h else 0.0\n",
    "            for h in (\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        atom_features.append(features)\n",
    "\n",
    "        pos = conformer.GetAtomPosition(atom.GetIdx())\n",
    "        positions.append([pos.x, pos.y, pos.z])\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    pos = torch.tensor(positions, dtype=torch.float)\n",
    "\n",
    "    # bonds between atoms – indices of connected atoms as well as types and conjugation\n",
    "    edge_index, edge_attr = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        # indices of bonded atoms\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "\n",
    "        # one-hot encode bond type\n",
    "        bond_type = bond.GetBondType()\n",
    "        bond_type_one_hot = [1.0 if bond_type == b else 0.0 for b in BOND_TYPES]\n",
    "\n",
    "        # is_conjugated = 1.0 if bond.GetIsConjugated() else 0.0\n",
    "        bond_length = rdMolTransforms.GetBondLength(conformer, i, j)\n",
    "\n",
    "        bond_feat = bond_type_one_hot + [bond_length]\n",
    "\n",
    "        # adding bond to both nodes\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "        edge_attr += [bond_feat, bond_feat]\n",
    "\n",
    "    # transform to PyTorch tensors\n",
    "    # edge_index tensor is transposed to fit torch_geometric's expected shape (2, number_of_edges).\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    mol_features = torch.tensor(mol_features, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "    # graph as PyTorch Geometric Data object\n",
    "    # x: atom features, [atomic number, degree, formal charge, hybridization]\n",
    "    # pos: 3D positions of atoms, [x, y, z]\n",
    "    # edge_index: connectivity indices between atoms, [[i, j], [j, i]]\n",
    "    # edge_attr: features per bond, [[bond type, conjugation], [bond type, conjugation]]\n",
    "    return Data(\n",
    "        x=x,\n",
    "        pos=pos,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=target_value,\n",
    "        target_id=target_id,\n",
    "        smiles=smiles,\n",
    "        mol_features=mol_features,\n",
    "    )\n",
    "\n",
    "\n",
    "# if not merged_serotonin_data_processed:\n",
    "merged_serotonin_data_processed = []\n",
    "\n",
    "for i, row in enumerate(merged_df.itertuples()):\n",
    "    pct_complete = 100 * i / len(merged_df)\n",
    "    sys.stdout.write(f\"\\r{pct_complete:.2f}% complete\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    data_obj = create_torch_data(\n",
    "        row.smiles,\n",
    "        torch.tensor(row.pchembl_value, dtype=torch.float),\n",
    "        row.target_id,\n",
    "    )\n",
    "\n",
    "    if data_obj:\n",
    "        merged_serotonin_data_processed.append(data_obj)\n",
    "\n",
    "pickle_file_path = PATH_DATA / \"merged_serotonin_data_processed.pkl\"\n",
    "\n",
    "with open(pickle_file_path, \"wb\") as f:\n",
    "    pickle.dump(merged_serotonin_data_processed, f)\n",
    "\n",
    "print(f\"Saved merged_serotonin_data_processed to {pickle_file_path}\")\n",
    "print(f\"merged_serotonin_data_processed[0] {merged_serotonin_data_processed[1100]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW4epGYehQoV"
   },
   "source": [
    "### Splitting Serotonin Data into Train/Test (and Don't Touch the Test Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5177,
     "status": "ok",
     "timestamp": 1740843690067,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "W95-P-6whQoV",
    "outputId": "ded440ed-ad17-4ed5-f7b7-252928dcd1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in filtered_merged_serotonin_data_processed: 14053 / 14053\n",
      "filtered_merged_serotonin_data_processed[0]: Data(x=[41, 10], edge_index=[2, 84], edge_attr=[84, 5], y=7.46999979019165, pos=[41, 3], target_id=7, smiles='CCN/C(=N\\S(=O)(=O)c1ccccc1)N1CC(CC)C=N1', mol_features=[1, 8])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_name_to_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     13\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(filtered_merged_serotonin_data_processed)\n\u001b[0;32m---> 15\u001b[0m target_id \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_name_to_id\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSerotonin 2a (5-HT2a) receptor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m split_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_merged_serotonin_data_processed))\n\u001b[1;32m     18\u001b[0m filtered_merged_serotonin_data_processed_train \u001b[38;5;241m=\u001b[39m filtered_merged_serotonin_data_processed[:split_idx]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_name_to_id' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_merged_serotonin_data_processed = [\n",
    "    d.clone() for d in merged_serotonin_data_processed if d is not None\n",
    "]\n",
    "print(\n",
    "    f\"Number of items in filtered_merged_serotonin_data_processed: {len(filtered_merged_serotonin_data_processed)} / {len(merged_serotonin_data_processed)}\"\n",
    ")  # still retaining original torch_data_list for reference to df later\n",
    "print(\n",
    "    f\"filtered_merged_serotonin_data_processed[0]: {filtered_merged_serotonin_data_processed[0]}\"\n",
    ")\n",
    "\n",
    "# shuffle the data\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(filtered_merged_serotonin_data_processed)\n",
    "\n",
    "target_id = target_name_to_id[\"Serotonin 2a (5-HT2a) receptor\"]\n",
    "split_idx = int(0.8 * len(filtered_merged_serotonin_data_processed))\n",
    "\n",
    "filtered_merged_serotonin_data_processed_train = filtered_merged_serotonin_data_processed[:split_idx]\n",
    "filtered_merged_serotonin_data_processed_test = filtered_merged_serotonin_data_processed[split_idx:]\n",
    "\n",
    "y_train = [d.y.cpu().numpy() for d in filtered_merged_serotonin_data_processed_train if d.y.numel() > 0 and d.target_id == target_id]\n",
    "sigma_train = np.nanstd(y_train)\n",
    "\n",
    "print(filtered_merged_serotonin_data_processed_train[0])\n",
    "\n",
    "print(\"Standard deviation of training set:\", sigma_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfVKAQr1hQoV"
   },
   "source": [
    "### Loading ZINC Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCS_tzY_hQoV"
   },
   "source": [
    "Data used for pre-training: https://www.kaggle.com/datasets/basu369victor/zinc250k?resource=download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 3502,
     "status": "ok",
     "timestamp": 1740843693568,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "hPickcJxhQoV",
    "outputId": "03cd916d-41e8-46be-9bd9-3bbc25ec11e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of qed in ZINC: 0.1395650745629226\n"
     ]
    }
   ],
   "source": [
    "pretraining_df = pd.read_csv(PATH_DATA / \"250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "\n",
    "data_column = pretraining_df.iloc[:, 2]\n",
    "pretraining_df_sigma = data_column.std()\n",
    "\n",
    "num_bins = 10\n",
    "\n",
    "bin_edges = np.arange(0, 1.1, 0.1)\n",
    "counts, _ = np.histogram(data_column, bins=bin_edges)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(\n",
    "    bin_centers,\n",
    "    counts,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 0.9,\n",
    "    alpha=0.7,\n",
    "    color=\"b\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"qed\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xticks(bin_edges)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Standard deviation of qed in ZINC: {pretraining_df_sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXzTFSeUhQoV"
   },
   "source": [
    "### Creating 3D Molecular Graph Data from ZINC Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135582,
     "status": "ok",
     "timestamp": 1740843913893,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "WR1FQEtshQoV",
    "outputId": "0cefbd20-2295-4ea2-c3df-38e7b7a8f525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretraining_torch_data_list from pickle file\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[44, 9], edge_index=[2, 92], edge_attr=[92, 5], y=[1], pos=[44, 3], smiles='CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n",
       "')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(PATH_DATA / \"pretraining_torch_data_list.pkl\"):\n",
    "    print(\"Loading pretraining_torch_data_list from pickle file\")\n",
    "    pretraining_torch_data_list = pickle.load(\n",
    "        open(PATH_DATA / \"pretraining_torch_data_list.pkl\", \"rb\")\n",
    "    )\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Creating pretraining_torch_data_list\")\n",
    "    pretraining_torch_data_list = []\n",
    "    for i, row in enumerate(pretraining_df.itertuples(index=False)):\n",
    "        if i % 10 == 0:\n",
    "            pct_complete = i / len(pretraining_df) * 100\n",
    "            sys.stdout.write(f\"\\r{pct_complete:.2f}% complete\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        pretraining_torch_data_list.append(\n",
    "            create_torch_data(\n",
    "                row.smiles,\n",
    "                torch.tensor(\n",
    "                    [row.qed], dtype=torch.float\n",
    "                ),  # use QED as target, representing \"drug-likeness\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"pretraining_torch_data_list.pkl\"\n",
    "\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(pretraining_torch_data_list, f)\n",
    "\n",
    "    print(f\"Saved pretraining_torch_data_list to {pickle_file_path}\")\n",
    "\n",
    "pretraining_torch_data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JX8z8mrhQoW"
   },
   "source": [
    "Remove None objects from the ZINC data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18434,
     "status": "ok",
     "timestamp": 1740843932327,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "FoObyIZQhQoW",
    "outputId": "26b2f6c1-42c4-405a-f50e-2a9400ef60b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in filtered_pretraining_torch_data_list: 249425 / 249455\n"
     ]
    }
   ],
   "source": [
    "filtered_pretraining_torch_data_list = [\n",
    "    d.clone() for d in pretraining_torch_data_list if d is not None\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Number of items in filtered_pretraining_torch_data_list: {len(filtered_pretraining_torch_data_list)} / {len(pretraining_torch_data_list)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPVwASxvhQoW"
   },
   "source": [
    "### Create ZINC subset for hyperparam tuning\n",
    "\n",
    "Create a new list with the first 10k samples of the ZINC dataset for hyperparam tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5021,
     "status": "ok",
     "timestamp": 1740843937346,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "XeOLW7_6hQoW",
    "outputId": "79b88440-ae2b-44df-95d6-e090ec626815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded filtered_pretraining_torch_data_list_10k from pickle file\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\"):\n",
    "    filtered_pretraining_torch_data_list_10k = pickle.load(\n",
    "        open(PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\", \"rb\")\n",
    "    )\n",
    "    print(\"Loaded filtered_pretraining_torch_data_list_10k from pickle file\")\n",
    "else:\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(filtered_pretraining_torch_data_list)\n",
    "\n",
    "    filtered_pretraining_torch_data_list_10k = filtered_pretraining_torch_data_list[\n",
    "        :10000\n",
    "    ]\n",
    "\n",
    "    pickle_file_path = PATH_DATA / \"filtered_pretraining_torch_data_list_10k.pkl\"\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(filtered_pretraining_torch_data_list_10k, f)\n",
    "        print(f\"Saved filtered_pretraining_torch_data_list_10k to {pickle_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vDOpQmFhQoW"
   },
   "source": [
    "---\n",
    "\n",
    "## Model Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXYo_QiqhQoW"
   },
   "source": [
    "### Naive Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzwGqdrhhQoW"
   },
   "outputs": [],
   "source": [
    "class MeanBaseline:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        self.mean_ = np.nanmean(y, axis=0)\n",
    "\n",
    "    def predict(self, n):\n",
    "        return np.tile(self.mean_, (n, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvehcFMGhQoW"
   },
   "source": [
    "### SeroGCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740843937379,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "f9C_6NOzhQoW",
    "outputId": "023ca835-21b6-4af2-98d8-2b3f8d27732b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features: 9, targets: 1, edge attributes: 5\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "n_in = filtered_torch_data_list_train[0].x.shape[1]\n",
    "n_out = len(valid_column_indices)\n",
    "n_edge_attr = filtered_torch_data_list_train[0].edge_attr.shape[1]\n",
    "\n",
    "print(f\"Node features: {n_in}, targets: {n_out}, edge attributes: {n_edge_attr}\")\n",
    "\n",
    "\n",
    "class SeroGCN(torch.nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(SeroGCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(n_in, n_hidden)\n",
    "        self.conv2 = GCNConv(n_hidden, n_hidden)\n",
    "        self.fc = Linear(n_hidden, n_out)\n",
    "        self.sigma = 1.0  # distance weighting parameter\n",
    "\n",
    "    def forward(self, mol_batch) -> torch.Tensor:\n",
    "        x, pos, edge_index, edge_attr = (\n",
    "            mol_batch.x,\n",
    "            mol_batch.pos,\n",
    "            mol_batch.edge_index,\n",
    "            mol_batch.edge_attr,\n",
    "        )\n",
    "\n",
    "        row, col = edge_index\n",
    "        eucl_edge_dist = torch.norm(pos[row] - pos[col], p=2, dim=1)\n",
    "        weight_distance = torch.exp(\n",
    "            -(eucl_edge_dist**2) / (2 * self.sigma**2)\n",
    "        )  # Gaussian distance weighting\n",
    "\n",
    "        # message passing with diustance and angle weights\n",
    "        x = self.conv1(x, edge_index, edge_weight=weight_distance)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight=weight_distance)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # global pooling for graph-level representation\n",
    "        x = global_mean_pool(x, mol_batch.batch)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiVYy5b9hQoX"
   },
   "source": [
    "---\n",
    "\n",
    "## Training Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-epVrheQhQoX"
   },
   "outputs": [],
   "source": [
    "# def masked_mse_loss(pred, target):\n",
    "#     # mask of non-nan targets\n",
    "#     mask = ~torch.isnan(target)\n",
    "#     if mask.sum() == 0:\n",
    "#         # return 0 loss, so that it doesn't affect the gradient\n",
    "#         return torch.tensor(0.0, requires_grad=True, device=target.device)\n",
    "#     # squared error for entries that are valid\n",
    "#     loss = (pred[mask] - target[mask]) ** 2\n",
    "#     return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740843937381,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "u-SuA9MehQoX"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion,\n",
    "    epochs: int,\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        start_epoch = time.time()\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(\n",
    "                out, data.y.view(-1, n_out)\n",
    "            )  # make sure that even if there's only one target var, it's still a 2D tensor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            pct_complete = 100 * (i + 1) / len(train_loader)\n",
    "            sys.stdout.write(\n",
    "                f\"\\rEpoch {epoch+1}/{epochs} - {pct_complete:.2f}% complete\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        train_loss_avg = epoch_loss / len(train_loader)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_data = val_data.to(device)\n",
    "                val_out = model(val_data)\n",
    "                val_loss = criterion(val_out, val_data.y.view(-1, n_out))\n",
    "                val_epoch_loss += val_loss.item()\n",
    "        val_loss_avg = val_epoch_loss / len(val_loader)\n",
    "        end_epoch = time.time()\n",
    "\n",
    "        print(\n",
    "            f\"\\nEpoch {epoch+1} completed. Train Loss = {train_loss_avg:.4f} | Val Loss = {val_loss_avg:.4f}. Time taken: {end_epoch - start_epoch:.2f}s\"\n",
    "        )\n",
    "        train_losses.append(train_loss_avg)\n",
    "        val_losses.append(val_loss_avg)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1740843937746,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "k5vqfLNAhQoY"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "def k_fold_cv(\n",
    "    initialized_model,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    dataset,\n",
    "    k=5,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    "    fit_final_model=False,\n",
    "):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{k} ---\")\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model_tmp = copy.deepcopy(initialized_model)\n",
    "        optimizer_tmp = Optimizer(model_tmp.parameters(), lr=lr)\n",
    "\n",
    "        train_losses, val_losses = fit(\n",
    "            model_tmp, train_loader, val_loader, optimizer_tmp, criterion, epochs\n",
    "        )\n",
    "\n",
    "        fold_train_losses.append(train_losses)\n",
    "        fold_val_losses.append(val_losses)\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} completed. Final train loss: {train_losses[-1]:.4f} | Final val loss: {val_losses[-1]:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- K-Fold CV completed ---\")\n",
    "    print(\n",
    "        f\"Average final train loss: {sum([l[-1] for l in fold_train_losses]) / k:.4f}\"\n",
    "    )\n",
    "    print(f\"Average final val loss: {sum([l[-1] for l in fold_val_losses]) / k:.4f}\")\n",
    "\n",
    "    if fit_final_model:\n",
    "        print(\"\\nFitting final model on entire dataset\")\n",
    "        optimizer_final = Optimizer(initialized_model.parameters(), lr=lr)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        fit(\n",
    "            initialized_model,\n",
    "            data_loader,\n",
    "            data_loader,\n",
    "            optimizer_final,\n",
    "            criterion,\n",
    "            epochs,\n",
    "        )\n",
    "\n",
    "    return fold_train_losses, fold_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1740843937789,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "TouwAhcIhQoY"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "hyperparam_grid = {\n",
    "    # \"lr\": [0.01, 0.001, 0.0001],\n",
    "    \"lr\": [0.01],\n",
    "    # \"batch_size\": [16, 32, 64],\n",
    "    # \"n_hidden\": [32, 64, 128],\n",
    "    \"n_hidden\": [64],\n",
    "    # \"epochs\": [10, 20, 30],\n",
    "    \"epochs\": [30],\n",
    "}\n",
    "\n",
    "\n",
    "def nested_cv(\n",
    "    Model,\n",
    "    Optimizer,\n",
    "    criterion,\n",
    "    hyperparam_grid,\n",
    "    dataset,\n",
    "    k_outer=5,\n",
    "    k_inner=5,\n",
    "):\n",
    "    # list of one dict per parameter combination\n",
    "    param_combinations = [\n",
    "        dict(zip(hyperparam_grid.keys(), values))\n",
    "        for values in product(*hyperparam_grid.values())\n",
    "    ]\n",
    "    n_combinations = len(param_combinations)\n",
    "\n",
    "    # risk estimate for each outer fold and each hyperparam combo\n",
    "    R_ests = np.zeros((k_outer, n_combinations))\n",
    "\n",
    "    if k_outer > 1:\n",
    "        outer_kf = KFold(n_splits=k_outer, shuffle=True, random_state=42)\n",
    "    else:  # for compute reasons\n",
    "\n",
    "        class DummyKFold:\n",
    "            def split(self, X):\n",
    "                yield X, X\n",
    "\n",
    "        outer_kf = DummyKFold()\n",
    "    dataset_indices = np.arange(len(dataset))\n",
    "\n",
    "    for i, (outer_train_idx, outer_val_idx) in enumerate(\n",
    "        outer_kf.split(dataset_indices)\n",
    "    ):\n",
    "        print(f\"\\n--- Outer Fold {i+1}/{k_outer} ---\")\n",
    "\n",
    "        outer_train_dataset = Subset(dataset, outer_train_idx)\n",
    "        outer_val_dataset = Subset(dataset, outer_val_idx)\n",
    "\n",
    "        # per hyperparam combo, perform inner k_fold_cv\n",
    "        for j, params in enumerate(param_combinations):\n",
    "            model = Model(params[\"n_hidden\"]).to(device)\n",
    "\n",
    "            # Run k_fold_cv on the outer training dataset.\n",
    "            _, fold_val_losses = k_fold_cv(\n",
    "                initialized_model=model,\n",
    "                Optimizer=Optimizer,\n",
    "                criterion=criterion,\n",
    "                dataset=outer_train_dataset,\n",
    "                k=k_inner,\n",
    "                epochs=params[\"epochs\"],\n",
    "                # batch_size=params[\"batch_size\"],\n",
    "                batch_size=64,  # hard-coded for compute reasons\n",
    "                lr=params[\"lr\"],\n",
    "            )\n",
    "            # average val risk over inner folds\n",
    "            final_losses = [losses[-1] for losses in fold_val_losses]\n",
    "            R_est = np.mean(final_losses)\n",
    "            R_ests[i, j] = R_est\n",
    "            print(\n",
    "                f\"Outer fold {i+1}, param set {j+1}/{n_combinations}: Risk = {R_est:.4f}\"\n",
    "            )\n",
    "\n",
    "    # average risk per hyperparam combination over outer folds\n",
    "    R_ests_params = np.mean(R_ests, axis=0)\n",
    "    best_idx = np.argmin(R_ests_params)\n",
    "    best_params = param_combinations[best_idx]\n",
    "\n",
    "    print(\n",
    "        f\"\\nSelected best hyperparameters (avg risk {R_ests_params[best_idx]:.4f}): {best_params}\"\n",
    "    )\n",
    "\n",
    "    # train final model on full dataset\n",
    "    model_final = Model(best_params[\"n_hidden\"]).to(device)\n",
    "    _, final_val_losses = k_fold_cv(\n",
    "        initialized_model=model_final,\n",
    "        Optimizer=Optimizer,\n",
    "        criterion=criterion,\n",
    "        dataset=dataset,\n",
    "        k=k_inner,\n",
    "        epochs=best_params[\"epochs\"],\n",
    "        # batch_size=params[\"batch_size\"],\n",
    "        batch_size=64,  # hard-coded for compute reasons\n",
    "        lr=best_params[\"lr\"],\n",
    "        fit_final_model=True,\n",
    "    )\n",
    "    final_R_est = np.mean([losses[-1] for losses in final_val_losses])\n",
    "    print(f\"Final model empirical risk estimate on full dataset: {final_R_est:.4f}\")\n",
    "\n",
    "    return model_final, best_params, final_R_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUKhw2PrhQoY"
   },
   "source": [
    "---\n",
    "\n",
    "## Training & Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBl2khqehQoY"
   },
   "source": [
    "### Naive Baseline: Average Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUIVMVd6hQoY",
    "outputId": "60b1f76a-7e0e-4445-972b-0facfa1df702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE per target: [1.1797696]\n"
     ]
    }
   ],
   "source": [
    "split_idx_baseline = int(0.8 * len(filtered_torch_data_list_train))\n",
    "\n",
    "y_train_baseline = [\n",
    "    d.y.numpy() for d in filtered_torch_data_list_train[:split_idx_baseline]\n",
    "]\n",
    "y_val_baseline = [\n",
    "    d.y.numpy() for d in filtered_torch_data_list_train[split_idx_baseline:]\n",
    "]\n",
    "\n",
    "naive_baseline = MeanBaseline()\n",
    "naive_baseline.fit(y_train_baseline)\n",
    "naive_baseline_predictions = naive_baseline.predict(len(y_val_baseline))\n",
    "\n",
    "# compute mse\n",
    "mse_per_target = np.nanmean((y_val_baseline - naive_baseline_predictions) ** 2, axis=0)\n",
    "print(f\"MSE per target: {mse_per_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvgld7xIhQoY"
   },
   "source": [
    "### Baseline: Random Forest with 2D/3D Descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nmBUWPuhQoY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:55:03] UFFTYPER: Unrecognized charge state for atom: 12\n",
      "[15:55:03] UFFTYPER: Unrecognized charge state for atom: 12\n",
      "[15:57:22] Interrupted, cancelling conformer generation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Embedding cancelled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c01faf1debc6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_torch_data_list_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-c01faf1debc6>\u001b[0m in \u001b[0;36mcompute_descriptors\u001b[0;34m(smiles)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Generate 3D conformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddHs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mETKDG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Skip if 3D generation fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mAllChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUFFOptimizeMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Optimize conformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Embedding cancelled"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# tried a bunch of descriptor functions from Descriptors._descList – these are the ones that did NOT crash the kernel ...\n",
    "safe_descriptors = [\n",
    "    \"MolWt\",\n",
    "    \"MolLogP\",\n",
    "    \"MolMR\",\n",
    "    \"NumValenceElectrons\",\n",
    "    \"NumRadicalElectrons\",\n",
    "    \"HeavyAtomCount\",\n",
    "    \"NHOHCount\",\n",
    "    \"NOCount\",\n",
    "    \"RingCount\",\n",
    "    \"FractionCSP3\",\n",
    "    \"TPSA\",\n",
    "    \"NumHDonors\",\n",
    "    \"NumHAcceptors\",\n",
    "    \"NumRotatableBonds\",\n",
    "    \"HallKierAlpha\",\n",
    "    \"Kappa1\",\n",
    "    \"Kappa2\",\n",
    "    \"Kappa3\",\n",
    "    \"Chi0\",\n",
    "    \"Chi1\",\n",
    "    \"fr_Al_COO\",\n",
    "    \"fr_Al_OH\",\n",
    "    \"fr_Ar_N\",\n",
    "    \"fr_C_O\",\n",
    "    \"fr_NH1\",\n",
    "    \"fr_NH2\",\n",
    "]\n",
    "\n",
    "descriptor_functions = {name: getattr(Descriptors, name) for name in safe_descriptors}\n",
    "\n",
    "\n",
    "# extract a fixed-length feature vector from the graph data, as input to RF model\n",
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    desc_values = []\n",
    "    for _, func in descriptor_functions.items():\n",
    "        try:\n",
    "            desc_values.append(func(mol))\n",
    "        except:\n",
    "            print(f\"Error computing descriptor {func}\")\n",
    "    return np.array(desc_values)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for data in filtered_torch_data_list_train:\n",
    "    features = compute_descriptors(data.smiles)\n",
    "    if features is None:\n",
    "        continue\n",
    "    X.append(features)\n",
    "    target_val = data.y.cpu().numpy() if data.y.numel() > 0 else np.nan\n",
    "    y.append(target_val)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "split_idx_rf = int(0.8 * len(filtered_torch_data_list_train))\n",
    "X_train, X_val = X[:split_idx_rf], X[split_idx_rf:]\n",
    "y_train, y_val = y[:split_idx_rf], y[split_idx_rf:]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(\"Val MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyInMxaihQoZ"
   },
   "source": [
    "### Approach 1: SeroGCN without Pretraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOo8Rdh9hQoZ"
   },
   "outputs": [],
   "source": [
    "sero_gcn_final, best_params_sero_gcn, final_R_est_sero_gcn = nested_cv(\n",
    "    SeroGCN,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    filtered_torch_data_list_train,\n",
    "    k_outer=1,  # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(sero_gcn_final.state_dict(), PATH_WEIGHTS / \"sero_gcn_final_weights.pth\")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_sero_gcn\": best_params_sero_gcn,\n",
    "            \"final_R_est_sero_gcn\": final_R_est_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqGa2vpxhQoZ"
   },
   "source": [
    "### Approach 2: SeroGCN with Pretraining on ZINC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqooqV7zhQoZ"
   },
   "source": [
    "#### Pretraining: Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 573416,
     "status": "ok",
     "timestamp": 1740315168031,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "fepVtdrzhQoZ",
    "outputId": "5ad19d8e-2388-4d1a-d3fb-5d2930ae74a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Outer Fold 1/1 ---\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0582 | Val Loss = 0.0175. Time taken: 2.55s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0188 | Val Loss = 0.0166. Time taken: 1.89s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0184 | Val Loss = 0.0182. Time taken: 1.42s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0187 | Val Loss = 0.0165. Time taken: 1.49s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0177 | Val Loss = 0.0165. Time taken: 1.44s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0182 | Val Loss = 0.0173. Time taken: 1.49s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0183 | Val Loss = 0.0163. Time taken: 1.49s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0181 | Val Loss = 0.0168. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0178 | Val Loss = 0.0164. Time taken: 1.58s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0180 | Val Loss = 0.0173. Time taken: 1.86s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0176 | Val Loss = 0.0161. Time taken: 1.73s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0174 | Val Loss = 0.0160. Time taken: 1.44s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0167. Time taken: 1.49s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0184 | Val Loss = 0.0163. Time taken: 1.47s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0159. Time taken: 1.53s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0179 | Val Loss = 0.0158. Time taken: 1.42s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0176 | Val Loss = 0.0158. Time taken: 1.50s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0171 | Val Loss = 0.0165. Time taken: 1.83s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0167 | Val Loss = 0.0158. Time taken: 1.91s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0165 | Val Loss = 0.0173. Time taken: 1.47s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0164 | Val Loss = 0.0155. Time taken: 1.46s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0165 | Val Loss = 0.0153. Time taken: 1.46s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0167 | Val Loss = 0.0163. Time taken: 1.43s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0159 | Val Loss = 0.0170. Time taken: 1.46s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0160 | Val Loss = 0.0153. Time taken: 1.44s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.61s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0163 | Val Loss = 0.0159. Time taken: 1.89s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0160 | Val Loss = 0.0152. Time taken: 1.77s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0159 | Val Loss = 0.0155. Time taken: 1.47s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0159 | Val Loss = 0.0161. Time taken: 1.45s\n",
      "Fold 1 completed. Final train loss: 0.0159 | Final val loss: 0.0161\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0548 | Val Loss = 0.0195. Time taken: 1.46s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0177 | Val Loss = 0.0185. Time taken: 1.51s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0177 | Val Loss = 0.0192. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0176 | Val Loss = 0.0185. Time taken: 1.45s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0179 | Val Loss = 0.0182. Time taken: 1.90s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0181 | Val Loss = 0.0252. Time taken: 1.87s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0178 | Val Loss = 0.0182. Time taken: 1.47s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0175 | Val Loss = 0.0197. Time taken: 1.45s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0178 | Val Loss = 0.0193. Time taken: 1.50s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0181. Time taken: 1.48s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0179. Time taken: 1.46s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0177 | Val Loss = 0.0180. Time taken: 1.46s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0182. Time taken: 1.63s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0170 | Val Loss = 0.0178. Time taken: 1.93s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0171 | Val Loss = 0.0181. Time taken: 1.74s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0169 | Val Loss = 0.0176. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0170 | Val Loss = 0.0179. Time taken: 1.46s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0177 | Val Loss = 0.0201. Time taken: 1.52s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 1.46s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 1.49s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0163 | Val Loss = 0.0171. Time taken: 1.44s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0162 | Val Loss = 0.0167. Time taken: 1.86s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0162 | Val Loss = 0.0175. Time taken: 1.97s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0164 | Val Loss = 0.0166. Time taken: 1.48s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0158 | Val Loss = 0.0175. Time taken: 1.56s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0157 | Val Loss = 0.0165. Time taken: 1.48s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0157 | Val Loss = 0.0165. Time taken: 1.49s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0157 | Val Loss = 0.0163. Time taken: 2.09s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0155 | Val Loss = 0.0161. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0168. Time taken: 1.89s\n",
      "Fold 2 completed. Final train loss: 0.0157 | Final val loss: 0.0168\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0572 | Val Loss = 0.0190. Time taken: 1.91s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0182 | Val Loss = 0.0179. Time taken: 1.50s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0180. Time taken: 1.56s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0179 | Val Loss = 0.0183. Time taken: 1.50s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0176 | Val Loss = 0.0181. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0182 | Val Loss = 0.0182. Time taken: 1.51s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0184 | Val Loss = 0.0186. Time taken: 1.51s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0188 | Val Loss = 0.0227. Time taken: 1.70s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0180 | Val Loss = 0.0173. Time taken: 1.88s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0175 | Val Loss = 0.0191. Time taken: 1.67s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0175 | Val Loss = 0.0170. Time taken: 1.49s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0177 | Val Loss = 0.0242. Time taken: 1.54s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0180 | Val Loss = 0.0174. Time taken: 1.47s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0175. Time taken: 1.51s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0178 | Val Loss = 0.0173. Time taken: 1.48s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0175 | Val Loss = 0.0181. Time taken: 1.50s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0179 | Val Loss = 0.0173. Time taken: 1.93s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0173 | Val Loss = 0.0187. Time taken: 1.87s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0173 | Val Loss = 0.0178. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0169 | Val Loss = 0.0170. Time taken: 1.56s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0170 | Val Loss = 0.0172. Time taken: 1.47s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0174 | Val Loss = 0.0172. Time taken: 1.52s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0171 | Val Loss = 0.0166. Time taken: 1.49s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0167 | Val Loss = 0.0172. Time taken: 3.06s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0162 | Val Loss = 0.0160. Time taken: 1.86s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0166 | Val Loss = 0.0163. Time taken: 1.72s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0160 | Val Loss = 0.0159. Time taken: 1.49s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0157 | Val Loss = 0.0155. Time taken: 1.57s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0156 | Val Loss = 0.0153. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0160. Time taken: 1.51s\n",
      "Fold 3 completed. Final train loss: 0.0157 | Final val loss: 0.0160\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0550 | Val Loss = 0.0171. Time taken: 1.52s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0186 | Val Loss = 0.0178. Time taken: 1.53s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0195 | Val Loss = 0.0169. Time taken: 1.95s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.87s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0186 | Val Loss = 0.0192. Time taken: 1.57s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0185 | Val Loss = 0.0162. Time taken: 1.53s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0186 | Val Loss = 0.0162. Time taken: 1.48s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0186 | Val Loss = 0.0161. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0179 | Val Loss = 0.0186. Time taken: 1.45s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0185 | Val Loss = 0.0160. Time taken: 1.52s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0182 | Val Loss = 0.0183. Time taken: 1.81s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0179 | Val Loss = 0.0159. Time taken: 1.91s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0176 | Val Loss = 0.0162. Time taken: 1.67s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0177 | Val Loss = 0.0170. Time taken: 1.54s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0160. Time taken: 1.48s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0174 | Val Loss = 0.0157. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0173 | Val Loss = 0.0156. Time taken: 1.57s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0171 | Val Loss = 0.0154. Time taken: 1.53s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0175 | Val Loss = 0.0165. Time taken: 1.67s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0170 | Val Loss = 0.0156. Time taken: 1.98s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0171 | Val Loss = 0.0155. Time taken: 1.77s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0169 | Val Loss = 0.0148. Time taken: 1.59s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0167 | Val Loss = 0.0146. Time taken: 1.45s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0164 | Val Loss = 0.0147. Time taken: 1.55s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0163 | Val Loss = 0.0145. Time taken: 1.47s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0166 | Val Loss = 0.0146. Time taken: 1.56s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0162 | Val Loss = 0.0147. Time taken: 1.56s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0161 | Val Loss = 0.0144. Time taken: 1.89s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0159 | Val Loss = 0.0151. Time taken: 1.96s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0161 | Val Loss = 0.0142. Time taken: 1.56s\n",
      "Fold 4 completed. Final train loss: 0.0161 | Final val loss: 0.0142\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0627 | Val Loss = 0.0188. Time taken: 1.55s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0183 | Val Loss = 0.0186. Time taken: 1.56s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0184. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0188. Time taken: 1.55s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0183 | Val Loss = 0.0186. Time taken: 1.49s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0183 | Val Loss = 0.0209. Time taken: 1.82s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0178 | Val Loss = 0.0182. Time taken: 1.97s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0174 | Val Loss = 0.0185. Time taken: 1.69s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0181. Time taken: 1.46s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0181 | Val Loss = 0.0224. Time taken: 1.51s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0179 | Val Loss = 0.0193. Time taken: 1.46s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0174 | Val Loss = 0.0181. Time taken: 1.57s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0176 | Val Loss = 0.0198. Time taken: 1.45s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0188. Time taken: 1.53s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0169 | Val Loss = 0.0177. Time taken: 2.03s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0175 | Val Loss = 0.0178. Time taken: 1.85s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0167 | Val Loss = 0.0177. Time taken: 1.52s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0173 | Val Loss = 0.0179. Time taken: 1.52s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0166 | Val Loss = 0.0179. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0166 | Val Loss = 0.0173. Time taken: 1.51s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0163 | Val Loss = 0.0179. Time taken: 1.53s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0166 | Val Loss = 0.0173. Time taken: 1.51s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0164 | Val Loss = 0.0168. Time taken: 1.86s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0169 | Val Loss = 0.0172. Time taken: 1.82s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0161 | Val Loss = 0.0168. Time taken: 1.66s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0159 | Val Loss = 0.0166. Time taken: 1.54s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0158 | Val Loss = 0.0163. Time taken: 1.53s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0158 | Val Loss = 0.0164. Time taken: 1.56s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0157 | Val Loss = 0.0191. Time taken: 1.53s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0157 | Val Loss = 0.0172. Time taken: 1.51s\n",
      "Fold 5 completed. Final train loss: 0.0157 | Final val loss: 0.0172\n",
      "\n",
      "--- K-Fold CV completed ---\n",
      "Average final train loss: 0.0158\n",
      "Average final val loss: 0.0161\n",
      "Outer fold 1, param set 1/1: Risk = 0.0161\n",
      "\n",
      "Selected best hyperparameters (avg risk 0.0161): {'lr': 0.01, 'n_hidden': 64, 'epochs': 30}\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0452 | Val Loss = 0.0168. Time taken: 1.68s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0187 | Val Loss = 0.0177. Time taken: 1.85s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0182 | Val Loss = 0.0171. Time taken: 1.88s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0183 | Val Loss = 0.0169. Time taken: 1.50s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0182 | Val Loss = 0.0175. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0189 | Val Loss = 0.0211. Time taken: 1.56s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0172 | Val Loss = 0.0160. Time taken: 1.58s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0170 | Val Loss = 0.0216. Time taken: 1.53s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0175 | Val Loss = 0.0161. Time taken: 1.54s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0171. Time taken: 2.02s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0170 | Val Loss = 0.0169. Time taken: 1.89s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0163 | Val Loss = 0.0157. Time taken: 1.55s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0161 | Val Loss = 0.0154. Time taken: 1.55s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.52s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0162 | Val Loss = 0.0154. Time taken: 1.59s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0162 | Val Loss = 0.0163. Time taken: 1.48s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0158 | Val Loss = 0.0160. Time taken: 1.52s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0156 | Val Loss = 0.0151. Time taken: 1.84s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0155 | Val Loss = 0.0152. Time taken: 1.83s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0159 | Val Loss = 0.0155. Time taken: 1.76s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0156 | Val Loss = 0.0158. Time taken: 1.54s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0156 | Val Loss = 0.0150. Time taken: 1.50s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0153 | Val Loss = 0.0151. Time taken: 1.50s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0153 | Val Loss = 0.0153. Time taken: 1.53s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0157. Time taken: 1.56s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0155 | Val Loss = 0.0147. Time taken: 1.48s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0149 | Val Loss = 0.0149. Time taken: 2.01s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0148. Time taken: 1.92s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0151 | Val Loss = 0.0156. Time taken: 1.59s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0150 | Val Loss = 0.0147. Time taken: 1.51s\n",
      "Fold 1 completed. Final train loss: 0.0150 | Final val loss: 0.0147\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0443 | Val Loss = 0.0190. Time taken: 1.64s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0181 | Val Loss = 0.0206. Time taken: 1.50s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0177 | Val Loss = 0.0194. Time taken: 1.54s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0175 | Val Loss = 0.0183. Time taken: 1.61s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0185 | Val Loss = 0.0182. Time taken: 1.77s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0174 | Val Loss = 0.0190. Time taken: 1.96s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0180. Time taken: 1.74s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0184 | Val Loss = 0.0192. Time taken: 1.51s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0174 | Val Loss = 0.0191. Time taken: 1.54s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0174 | Val Loss = 0.0235. Time taken: 1.55s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0171 | Val Loss = 0.0176. Time taken: 1.53s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0169 | Val Loss = 0.0177. Time taken: 1.53s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0175 | Val Loss = 0.0178. Time taken: 1.72s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0166 | Val Loss = 0.0171. Time taken: 1.96s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0173 | Val Loss = 0.0170. Time taken: 1.88s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0160 | Val Loss = 0.0167. Time taken: 1.60s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0160 | Val Loss = 0.0168. Time taken: 1.49s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0157 | Val Loss = 0.0163. Time taken: 1.49s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0157 | Val Loss = 0.0174. Time taken: 1.49s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0155 | Val Loss = 0.0176. Time taken: 1.58s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0154 | Val Loss = 0.0158. Time taken: 1.45s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0156 | Val Loss = 0.0162. Time taken: 1.92s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0152 | Val Loss = 0.0158. Time taken: 1.88s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0156 | Val Loss = 0.0160. Time taken: 1.59s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0158. Time taken: 1.52s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0152 | Val Loss = 0.0164. Time taken: 1.51s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0151 | Val Loss = 0.0162. Time taken: 1.51s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0155. Time taken: 1.56s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0149 | Val Loss = 0.0167. Time taken: 1.45s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0151 | Val Loss = 0.0161. Time taken: 1.64s\n",
      "Fold 2 completed. Final train loss: 0.0151 | Final val loss: 0.0161\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0458 | Val Loss = 0.0192. Time taken: 1.99s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0182 | Val Loss = 0.0187. Time taken: 1.80s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0179 | Val Loss = 0.0176. Time taken: 1.51s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0174. Time taken: 1.56s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0179 | Val Loss = 0.0175. Time taken: 1.49s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0179 | Val Loss = 0.0172. Time taken: 1.50s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0171. Time taken: 1.52s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0176 | Val Loss = 0.0170. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0176. Time taken: 1.90s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0173 | Val Loss = 0.0184. Time taken: 1.88s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0175. Time taken: 1.64s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0173 | Val Loss = 0.0170. Time taken: 1.48s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0171 | Val Loss = 0.0167. Time taken: 1.53s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0169 | Val Loss = 0.0167. Time taken: 1.49s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0165 | Val Loss = 0.0164. Time taken: 1.46s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0171 | Val Loss = 0.0162. Time taken: 1.55s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0165 | Val Loss = 0.0158. Time taken: 1.54s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0161 | Val Loss = 0.0162. Time taken: 1.96s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0161 | Val Loss = 0.0171. Time taken: 1.91s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0160 | Val Loss = 0.0164. Time taken: 1.50s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0155 | Val Loss = 0.0152. Time taken: 1.54s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0155 | Val Loss = 0.0153. Time taken: 1.50s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0156 | Val Loss = 0.0153. Time taken: 1.51s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0152 | Val Loss = 0.0163. Time taken: 1.54s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0154 | Val Loss = 0.0152. Time taken: 1.50s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0157 | Val Loss = 0.0151. Time taken: 1.78s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0152 | Val Loss = 0.0149. Time taken: 1.91s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0154 | Val Loss = 0.0150. Time taken: 1.75s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0153 | Val Loss = 0.0159. Time taken: 1.54s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0151 | Val Loss = 0.0152. Time taken: 1.51s\n",
      "Fold 3 completed. Final train loss: 0.0151 | Final val loss: 0.0152\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0467 | Val Loss = 0.0169. Time taken: 1.51s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0185 | Val Loss = 0.0164. Time taken: 1.54s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.47s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0182 | Val Loss = 0.0163. Time taken: 1.57s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0185 | Val Loss = 0.0163. Time taken: 1.92s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0189 | Val Loss = 0.0161. Time taken: 1.75s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0179 | Val Loss = 0.0177. Time taken: 1.67s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0178 | Val Loss = 0.0158. Time taken: 1.52s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0176 | Val Loss = 0.0161. Time taken: 1.55s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0180 | Val Loss = 0.0161. Time taken: 1.51s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0177 | Val Loss = 0.0161. Time taken: 1.48s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0170 | Val Loss = 0.0156. Time taken: 1.57s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0179 | Val Loss = 0.0155. Time taken: 1.61s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0172 | Val Loss = 0.0152. Time taken: 1.90s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0172 | Val Loss = 0.0167. Time taken: 1.90s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0170 | Val Loss = 0.0151. Time taken: 1.59s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0169 | Val Loss = 0.0157. Time taken: 1.48s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0167 | Val Loss = 0.0147. Time taken: 1.56s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0165 | Val Loss = 0.0177. Time taken: 1.51s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0167 | Val Loss = 0.0149. Time taken: 1.50s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0165 | Val Loss = 0.0144. Time taken: 1.50s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0161 | Val Loss = 0.0143. Time taken: 1.75s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0159 | Val Loss = 0.0142. Time taken: 1.92s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0158 | Val Loss = 0.0141. Time taken: 1.85s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0157 | Val Loss = 0.0141. Time taken: 1.49s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0156 | Val Loss = 0.0141. Time taken: 1.64s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0157 | Val Loss = 0.0153. Time taken: 1.54s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0156 | Val Loss = 0.0142. Time taken: 1.58s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0156 | Val Loss = 0.0141. Time taken: 1.51s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0154 | Val Loss = 0.0139. Time taken: 1.58s\n",
      "Fold 4 completed. Final train loss: 0.0154 | Final val loss: 0.0139\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0477 | Val Loss = 0.0187. Time taken: 1.85s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0181 | Val Loss = 0.0195. Time taken: 1.80s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0176 | Val Loss = 0.0188. Time taken: 1.59s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0180 | Val Loss = 0.0189. Time taken: 1.60s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0181 | Val Loss = 0.0191. Time taken: 1.50s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0175 | Val Loss = 0.0186. Time taken: 1.57s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0175 | Val Loss = 0.0193. Time taken: 1.57s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0177 | Val Loss = 0.0179. Time taken: 1.58s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0173 | Val Loss = 0.0178. Time taken: 1.70s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0170 | Val Loss = 0.0181. Time taken: 1.92s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0166 | Val Loss = 0.0186. Time taken: 1.87s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0170 | Val Loss = 0.0187. Time taken: 1.51s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0171 | Val Loss = 0.0193. Time taken: 1.57s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0167 | Val Loss = 0.0176. Time taken: 1.49s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0165 | Val Loss = 0.0179. Time taken: 1.57s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0170 | Val Loss = 0.0180. Time taken: 1.47s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0161 | Val Loss = 0.0181. Time taken: 1.55s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0164 | Val Loss = 0.0168. Time taken: 1.70s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0159 | Val Loss = 0.0179. Time taken: 1.89s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0161 | Val Loss = 0.0178. Time taken: 1.81s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0159 | Val Loss = 0.0166. Time taken: 1.56s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0154 | Val Loss = 0.0168. Time taken: 1.46s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0153 | Val Loss = 0.0174. Time taken: 1.63s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0155 | Val Loss = 0.0165. Time taken: 1.52s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0160. Time taken: 1.62s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0151 | Val Loss = 0.0164. Time taken: 1.53s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0150 | Val Loss = 0.0158. Time taken: 2.10s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0151 | Val Loss = 0.0158. Time taken: 1.94s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0150 | Val Loss = 0.0161. Time taken: 1.58s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0152 | Val Loss = 0.0160. Time taken: 1.56s\n",
      "Fold 5 completed. Final train loss: 0.0152 | Final val loss: 0.0160\n",
      "\n",
      "--- K-Fold CV completed ---\n",
      "Average final train loss: 0.0151\n",
      "Average final val loss: 0.0152\n",
      "\n",
      "Fitting final model on entire dataset\n",
      "Epoch 1/30 - 100.00% complete\n",
      "Epoch 1 completed. Train Loss = 0.0412 | Val Loss = 0.0177. Time taken: 2.64s\n",
      "Epoch 2/30 - 100.00% complete\n",
      "Epoch 2 completed. Train Loss = 0.0179 | Val Loss = 0.0181. Time taken: 2.68s\n",
      "Epoch 3/30 - 100.00% complete\n",
      "Epoch 3 completed. Train Loss = 0.0180 | Val Loss = 0.0192. Time taken: 3.18s\n",
      "Epoch 4/30 - 100.00% complete\n",
      "Epoch 4 completed. Train Loss = 0.0179 | Val Loss = 0.0188. Time taken: 3.11s\n",
      "Epoch 5/30 - 100.00% complete\n",
      "Epoch 5 completed. Train Loss = 0.0178 | Val Loss = 0.0204. Time taken: 2.68s\n",
      "Epoch 6/30 - 100.00% complete\n",
      "Epoch 6 completed. Train Loss = 0.0174 | Val Loss = 0.0178. Time taken: 2.64s\n",
      "Epoch 7/30 - 100.00% complete\n",
      "Epoch 7 completed. Train Loss = 0.0173 | Val Loss = 0.0167. Time taken: 2.76s\n",
      "Epoch 8/30 - 100.00% complete\n",
      "Epoch 8 completed. Train Loss = 0.0171 | Val Loss = 0.0175. Time taken: 3.28s\n",
      "Epoch 9/30 - 100.00% complete\n",
      "Epoch 9 completed. Train Loss = 0.0173 | Val Loss = 0.0169. Time taken: 2.91s\n",
      "Epoch 10/30 - 100.00% complete\n",
      "Epoch 10 completed. Train Loss = 0.0175 | Val Loss = 0.0179. Time taken: 2.72s\n",
      "Epoch 11/30 - 100.00% complete\n",
      "Epoch 11 completed. Train Loss = 0.0172 | Val Loss = 0.0172. Time taken: 2.72s\n",
      "Epoch 12/30 - 100.00% complete\n",
      "Epoch 12 completed. Train Loss = 0.0172 | Val Loss = 0.0165. Time taken: 2.67s\n",
      "Epoch 13/30 - 100.00% complete\n",
      "Epoch 13 completed. Train Loss = 0.0174 | Val Loss = 0.0161. Time taken: 3.35s\n",
      "Epoch 14/30 - 100.00% complete\n",
      "Epoch 14 completed. Train Loss = 0.0164 | Val Loss = 0.0164. Time taken: 2.88s\n",
      "Epoch 15/30 - 100.00% complete\n",
      "Epoch 15 completed. Train Loss = 0.0162 | Val Loss = 0.0196. Time taken: 2.71s\n",
      "Epoch 16/30 - 100.00% complete\n",
      "Epoch 16 completed. Train Loss = 0.0161 | Val Loss = 0.0155. Time taken: 2.67s\n",
      "Epoch 17/30 - 100.00% complete\n",
      "Epoch 17 completed. Train Loss = 0.0157 | Val Loss = 0.0154. Time taken: 2.92s\n",
      "Epoch 18/30 - 100.00% complete\n",
      "Epoch 18 completed. Train Loss = 0.0158 | Val Loss = 0.0150. Time taken: 3.39s\n",
      "Epoch 19/30 - 100.00% complete\n",
      "Epoch 19 completed. Train Loss = 0.0156 | Val Loss = 0.0151. Time taken: 2.68s\n",
      "Epoch 20/30 - 100.00% complete\n",
      "Epoch 20 completed. Train Loss = 0.0153 | Val Loss = 0.0149. Time taken: 2.71s\n",
      "Epoch 21/30 - 100.00% complete\n",
      "Epoch 21 completed. Train Loss = 0.0153 | Val Loss = 0.0161. Time taken: 2.72s\n",
      "Epoch 22/30 - 100.00% complete\n",
      "Epoch 22 completed. Train Loss = 0.0153 | Val Loss = 0.0153. Time taken: 3.14s\n",
      "Epoch 23/30 - 100.00% complete\n",
      "Epoch 23 completed. Train Loss = 0.0152 | Val Loss = 0.0148. Time taken: 3.12s\n",
      "Epoch 24/30 - 100.00% complete\n",
      "Epoch 24 completed. Train Loss = 0.0152 | Val Loss = 0.0151. Time taken: 2.76s\n",
      "Epoch 25/30 - 100.00% complete\n",
      "Epoch 25 completed. Train Loss = 0.0153 | Val Loss = 0.0149. Time taken: 2.77s\n",
      "Epoch 26/30 - 100.00% complete\n",
      "Epoch 26 completed. Train Loss = 0.0150 | Val Loss = 0.0149. Time taken: 2.66s\n",
      "Epoch 27/30 - 100.00% complete\n",
      "Epoch 27 completed. Train Loss = 0.0150 | Val Loss = 0.0147. Time taken: 3.26s\n",
      "Epoch 28/30 - 100.00% complete\n",
      "Epoch 28 completed. Train Loss = 0.0149 | Val Loss = 0.0150. Time taken: 2.97s\n",
      "Epoch 29/30 - 100.00% complete\n",
      "Epoch 29 completed. Train Loss = 0.0148 | Val Loss = 0.0145. Time taken: 2.66s\n",
      "Epoch 30/30 - 100.00% complete\n",
      "Epoch 30 completed. Train Loss = 0.0149 | Val Loss = 0.0143. Time taken: 2.74s\n",
      "Final model empirical risk estimate on full dataset: 0.0152\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    pretrained_sero_gcn,\n",
    "    best_params_pretrained_sero_gcn,\n",
    "    final_R_est_pretrained_sero_gcn,\n",
    ") = nested_cv(\n",
    "    SeroGCN,\n",
    "    torch.optim.Adam,\n",
    "    torch.nn.MSELoss(),\n",
    "    hyperparam_grid,\n",
    "    filtered_pretraining_torch_data_list_10k,\n",
    "    k_outer=1,  # compute reasons\n",
    "    k_inner=5,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_R_est_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV86lS77hQoZ"
   },
   "source": [
    "#### (Pretraining: Full ZINC with Locked Hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBTj2oQfhQoZ"
   },
   "source": [
    "#### Fine-tuning on Serotonine Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1740315773552,
     "user": {
      "displayName": "Paul Utsch",
      "userId": "03470855315435454824"
     },
     "user_tz": -60
    },
    "id": "_3qGyoEMU09K",
    "outputId": "1039f17b-8a96-4c74-88e6-58209f77d4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeroGCN does not exist – train it first\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = PATH_WEIGHTS / \"pretrained_sero_gcn_pretrained_weights.pth\"\n",
    "\n",
    "if os.path.exists(pickle_file_path) and not pretrained_sero_gcn:\n",
    "    print(\"Loading pretrained SeroGCN from weights file\")\n",
    "    pretrained_sero_gcn = torch.load(pickle_file_path, map_location=device)\n",
    "    print(\"Loaded pretrained SeroGCN from weights file\")\n",
    "else:\n",
    "    print(\"SeroGCN does not exist – train it first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iX_8Qr17hQoZ"
   },
   "outputs": [],
   "source": [
    "_, final_val_losses_pretrained_sero_gcn = k_fold_cv(\n",
    "    initialized_model=pretrained_sero_gcn,\n",
    "    Optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.MSELoss(),\n",
    "    dataset=filtered_torch_data_list_train,\n",
    "    k=5,\n",
    "    epochs=best_params_pretrained_sero_gcn[\"epochs\"],\n",
    "    batch_size=best_params_pretrained_sero_gcn[\"batch_size\"],\n",
    "    lr=best_params_pretrained_sero_gcn[\"lr\"],\n",
    "    fit_final_model=True,\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    pretrained_sero_gcn.state_dict(),\n",
    "    PATH_WEIGHTS / \"pretrained_sero_gcn_final_weights.pth\",\n",
    ")\n",
    "\n",
    "with open(PATH_WEIGHTS / \"best_params_pretrained_sero_final.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_pretrained_sero_gcn\": best_params_pretrained_sero_gcn,\n",
    "            \"final_R_est_pretrained_sero_gcn\": final_val_losses_pretrained_sero_gcn,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxB4ngu_hQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Test Set Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvTRLNdrhQoZ"
   },
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
